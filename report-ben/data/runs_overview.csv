name,id,state,created_at,config,summary
absurd-darkness-1,rzu7my7u,crashed,2025-11-23T14:59:13Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': None, 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/models/apertus8B_sft_lora', 'rope_theta': 12000000, 'save_steps': 500, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 8, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 16, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['down_proj', 'q_proj', 'v_proj', 'o_proj', 'k_proj', 'up_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0.03, 'warmup_steps': 0.03, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0002, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 288, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_safetensors': True, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'cosine_with_min_lr', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': {'min_lr_rate': 0.1}, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 254.730220418, '_step': 92, '_timestamp': 1763910208.7011518, '_wandb': {'runtime': 254}, 'train/epoch': 0.17448405253283303, 'train/global_step': 93, 'train/grad_norm': 0.04260525107383728, 'train/learning_rate': 0.00019057186466732816, 'train/loss': 0.8572, 'train/mean_token_accuracy': 0.7826907634735107, 'train/num_tokens': 14385168}"
apertus8B-sft-lora,3dga3f02,finished,2025-11-23T15:06:43Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': None, 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/models/apertus8B_sft_lora', 'rope_theta': 12000000, 'save_steps': 500, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 8, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 16, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['q_proj', 'down_proj', 'v_proj', 'k_proj', 'o_proj', 'up_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0.03, 'warmup_steps': 0.03, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0002, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 288, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_safetensors': True, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'cosine_with_min_lr', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': {'min_lr_rate': 0.1}, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8073261120, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 1234, '_step': 533, '_timestamp': 1763911633.8477676, '_wandb': {'runtime': 1234}, 'total_flos': 5795241376736084000, 'train/epoch': 1, 'train/global_step': 533, 'train/grad_norm': 0.07438544929027557, 'train/learning_rate': 2.0001661612828905e-05, 'train/loss': 0.814, 'train/mean_token_accuracy': 0.7895311713218689, 'train/num_tokens': 82519579, 'train_loss': 0.880256566388522, 'train_runtime': 1231.3204, 'train_samples_per_second': 55.402, 'train_steps_per_second': 0.433}"
comic-wave-3,lxg637kh,crashed,2025-11-23T15:14:43Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': None, 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/models/apertus70B_sft_lora', 'rope_theta': 12000000, 'save_steps': 500, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 8, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 16, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['o_proj', 'q_proj', 'v_proj', 'down_proj', 'k_proj', 'up_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0.03, 'warmup_steps': 0.03, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0002, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 288, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_safetensors': True, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'cosine_with_min_lr', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': {'min_lr_rate': 0.1}, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 1, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 112.254511319, '_step': 14, '_timestamp': 1763910996.33567, '_wandb': {'runtime': 112}, 'train/epoch': 0.007035647279549718, 'train/global_step': 15, 'train/grad_norm': 0.7508177757263184, 'train/learning_rate': 4.375e-05, 'train/loss': 1.537, 'train/mean_token_accuracy': 0.6663141250610352, 'train/num_tokens': 574608}"
avid-sunset-4,pbjo2527,crashed,2025-11-23T15:20:21Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': None, 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/models/apertus70B_sft_lora', 'rope_theta': 12000000, 'save_steps': 500, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 8, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 16, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['q_proj', 'o_proj', 'up_proj', 'v_proj', 'k_proj', 'down_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0.03, 'warmup_steps': 0.03, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0002, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 288, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_safetensors': True, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'cosine_with_min_lr', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': {'min_lr_rate': 0.1}, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 334.032799464, '_step': 18, '_timestamp': 1763911556.2045076, '_wandb': {'runtime': 334}, 'train/epoch': 0.03564727954971857, 'train/global_step': 19, 'train/grad_norm': 0.29715606570243835, 'train/learning_rate': 0.00019999335361003904, 'train/loss': 0.8354, 'train/mean_token_accuracy': 0.7907658815383911, 'train/num_tokens': 2899112}"
apertus70B-sft-lora,dbcirxkk,finished,2025-11-23T15:29:43Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': None, 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/models/apertus70B_sft_lora', 'rope_theta': 12000000, 'save_steps': 500, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 8, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 16, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['up_proj', 'k_proj', 'down_proj', 'o_proj', 'v_proj', 'q_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0.03, 'warmup_steps': 0.03, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0002, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 288, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_safetensors': True, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'cosine_with_min_lr', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': {'min_lr_rate': 0.1}, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 5240, '_step': 267, '_timestamp': 1763916985.3316348, '_wandb': {'runtime': 5240}, 'total_flos': 34358088630796290, 'train/epoch': 1, 'train/global_step': 267, 'train/grad_norm': 0.04651593789458275, 'train/learning_rate': 2.0006672175806197e-05, 'train/loss': 0.7309, 'train/mean_token_accuracy': 0.8012294173240662, 'train/num_tokens': 82681884, 'train_loss': 0.7760357959440138, 'train_runtime': 5203.7734, 'train_samples_per_second': 13.109, 'train_steps_per_second': 0.051}"
gallant-plant-6,rms3j1bk,finished,2025-11-23T22:26:11Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': None, 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/models/apertus70B_sft_lora_tests', 'rope_theta': 12000000, 'save_steps': 500, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 8, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 16, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['o_proj', 'down_proj', 'up_proj', 'v_proj', 'q_proj', 'k_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0.03, 'warmup_steps': 0.03, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0002, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 288, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_safetensors': True, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'cosine_with_min_lr', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': {'min_lr_rate': 0.1}, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 490, '_step': 63, '_timestamp': 1763937240.1399548, '_wandb': {'runtime': 490}, 'total_flos': 273835758714880, 'train/epoch': 1, 'train/global_step': 63, 'train/grad_norm': 0.20604945719242096, 'train/learning_rate': 2.0119331910365256e-05, 'train/loss': 0.9234, 'train/mean_token_accuracy': 0.7303005456924438, 'train/num_tokens': 574139, 'train_loss': 1.0119637042757064, 'train_runtime': 470.4444, 'train_samples_per_second': 2.126, 'train_steps_per_second': 0.134}"
snowy-dew-10,d8o3xixf,finished,2025-11-24T18:13:06Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': True, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': None, 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 10, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/peft_apertus/models/apertus70B_sft_lora_tests', 'rope_theta': 12000000, 'save_steps': 500, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 8, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 16, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['o_proj', 'up_proj', 'v_proj', 'k_proj', 'down_proj', 'q_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0.03, 'warmup_steps': 0.03, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'steps', 'learning_rate': 0.0002, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 288, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_safetensors': True, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'cosine_with_min_lr', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': {'min_lr_rate': 0.1}, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 4, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 549, '_step': 62, '_timestamp': 1764008508.1977785, '_wandb': {'runtime': 549}, 'eval/loss': 0.8756487369537354, 'eval/mean_token_accuracy': 0.7517167755535671, 'eval/num_tokens': 453402, 'eval/runtime': 14.2401, 'eval/samples_per_second': 7.022, 'eval/steps_per_second': 0.492, 'total_flos': 243138075033600, 'train/epoch': 1, 'train/global_step': 57, 'train/grad_norm': 0.21264027059078217, 'train/learning_rate': 2.0146780646647795e-05, 'train/loss': 0.8381, 'train/mean_token_accuracy': 0.7524491548538208, 'train/num_tokens': 519069, 'train_loss': 1.0362156995555811, 'train_runtime': 523.3609, 'train_samples_per_second': 1.72, 'train_steps_per_second': 0.109}"
apertus8B-sft-full,yzoa1lh6,finished,2025-12-11T22:20:32Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': None, 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/models/apertus8B_sft_tests8', 'save_steps': 500, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0.03, 'warmup_steps': 0.03, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 2e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 288, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'cosine_with_min_lr', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': {'min_lr_rate': 0.1}, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 8, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 5681, '_step': 267, '_timestamp': 1765497306.2744837, '_wandb': {'runtime': 5681}, 'total_flos': 255228247375872, 'train/epoch': 1, 'train/global_step': 267, 'train/grad_norm': 0.30539241433143616, 'train/learning_rate': 2.0006672175806196e-06, 'train/loss': 0.7284177541732788, 'train/mean_token_accuracy': 0.8033139705657959, 'train/num_tokens': 82519579, 'train_loss': 0.8084567200378532, 'train_runtime': 5674.8506, 'train_samples_per_second': 12.021, 'train_steps_per_second': 0.047}"
young-cherry-13,tm5o1yvl,crashed,2025-12-12T01:19:54Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': None, 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/models/apertus70B_sft_tests', 'save_steps': 500, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0.03, 'warmup_steps': 0.03, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 2e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'cosine_with_min_lr', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': {'min_lr_rate': 0.1}, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 23684.979848669, '_step': 265, '_timestamp': 1765526079.5306015, '_wandb': {'runtime': 23684}, 'train/epoch': 0.99812382739212, 'train/global_step': 266, 'train/grad_norm': 0.2614906132221222, 'train/learning_rate': 2.002668771393746e-06, 'train/loss': 0.6733013391494751, 'train/mean_token_accuracy': 0.8142207562923431, 'train/num_tokens': 82370196}"
dataset-analysis-Apertus-8B-Instruct-2509,h3u93myr,finished,2025-12-15T18:15:03Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'name': 'Apertus-8B-Instruct', 'entity': 'lsaie-peft-apertus', 'project': 'LEXam-Evaluation'}, 'subsets': ['mcq_4_choices', 'mcq_8_choices', 'mcq_16_choices', 'mcq_32_choices'], 'model_id': 'swiss-ai/Apertus-8B-Instruct-2509', 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'max_prompt_len': 4096, 'print_miss_every': 50, 'match_choice_regex': '###([A-Z]+)###', 'print_last100_every': 100, 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 8, '_step': 12, '_timestamp': 1765822512.5378976, '_wandb': {'runtime': 8}, 'dataset_stats_summary': {'_latest_artifact_path': 'wandb-client-artifact://fv74jubyc8searzmrq5ewz2sgsuetol9pg6v53wt8jeuazlim5etmbio4e2yk7795pczfv3b0rxzzmbbqqli08l4t6s8g8p2buwbbdt4hdxdtr6qow56u9g9xcxnyyc3:latest/dataset_stats_summary.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://a73kzmbsc8fss6fgp4es066e1bf3h3t2q2tr07fe7ol1fyz9984h5hmb2gz9lhenc3c5cgfggd33s50i7qnc147q492v84wfixlsbix7aseqvt38debqotj2jmdzsakm/dataset_stats_summary.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 9, 'nrows': 4, 'path': 'media/table/dataset_stats_summary_12_21c539d0b5a4e4bbb6f9.table.json', 'sha256': '21c539d0b5a4e4bbb6f960a16f57bf6da3c1ea47afa823c8ea61fe56fdeaabe9', 'size': 454}, 'mcq_16_choices/prompt_length_dist': {'_type': 'histogram'}, 'mcq_16_choices/prompt_length_max': 2272, 'mcq_16_choices/prompt_length_mean': 564.1614785992218, 'mcq_16_choices/prompt_length_median': 531, 'mcq_16_choices/prompt_length_min': 391, 'mcq_16_choices/prompt_length_p95': 755.65, 'mcq_16_choices/prompt_length_p99': 1212.070000000001, 'mcq_16_choices/prompt_length_plot': {'_type': 'image-file', 'format': 'png', 'height': 600, 'path': 'media/images/mcq_16_choices/prompt_length_plot_8_418670e4b70a4696a93f.png', 'sha256': '418670e4b70a4696a93f01b3cc3dce84399e51916830e02bada025aa3ed6061d', 'size': 32716, 'width': 1000}, 'mcq_16_choices/prompt_length_std': 159.41732178459554, 'mcq_32_choices/prompt_length_dist': {'_type': 'histogram'}, 'mcq_32_choices/prompt_length_max': 1161, 'mcq_32_choices/prompt_length_mean': 702.0036363636364, 'mcq_32_choices/prompt_length_median': 678, 'mcq_32_choices/prompt_length_min': 553, 'mcq_32_choices/prompt_length_p95': 858.55, 'mcq_32_choices/prompt_length_p99': 949.61, 'mcq_32_choices/prompt_length_plot': {'_type': 'image-file', 'format': 'png', 'height': 600, 'path': 'media/images/mcq_32_choices/prompt_length_plot_11_159369344c8d0cc092a1.png', 'sha256': '159369344c8d0cc092a185079665c1187ac9d286c715c713a9286a0585c97349', 'size': 33155, 'width': 1000}, 'mcq_32_choices/prompt_length_std': 77.2602684287723, 'mcq_4_choices/prompt_length_dist': {'_type': 'histogram'}, 'mcq_4_choices/prompt_length_max': 2189, 'mcq_4_choices/prompt_length_mean': 485.35045317220545, 'mcq_4_choices/prompt_length_median': 436, 'mcq_4_choices/prompt_length_min': 301, 'mcq_4_choices/prompt_length_p95': 729.3, 'mcq_4_choices/prompt_length_p99': 1408.220000000002, 'mcq_4_choices/prompt_length_plot': {'_type': 'image-file', 'format': 'png', 'height': 600, 'path': 'media/images/mcq_4_choices/prompt_length_plot_2_d3f9bdff1b9c4e227246.png', 'sha256': 'd3f9bdff1b9c4e227246e8a6cd260f79ae9cfacadea11ebacf48739a1c8e8e83', 'size': 36169, 'width': 1000}, 'mcq_4_choices/prompt_length_std': 183.11662164356116, 'mcq_8_choices/prompt_length_dist': {'_type': 'histogram'}, 'mcq_8_choices/prompt_length_max': 2222, 'mcq_8_choices/prompt_length_mean': 501.5946684894053, 'mcq_8_choices/prompt_length_median': 460, 'mcq_8_choices/prompt_length_min': 340, 'mcq_8_choices/prompt_length_p95': 718, 'mcq_8_choices/prompt_length_p99': 1467.8999999999994, 'mcq_8_choices/prompt_length_plot': {'_type': 'image-file', 'format': 'png', 'height': 600, 'path': 'media/images/mcq_8_choices/prompt_length_plot_5_153f868eb7bc6a992741.png', 'sha256': '153f868eb7bc6a99274125aceed6a411e455835f0c6dacf5dff7fa2e179320ef', 'size': 35679, 'width': 1000}, 'mcq_8_choices/prompt_length_std': 174.12933227867822}"
Apertus-70B-Instruct_2025-12-15_19-54-18,cphf2168,finished,2025-12-15T18:54:19Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'name': 'Apertus-70B-Instruct', 'entity': 'lsaie-peft-apertus', 'project': 'LEXam-Evaluation'}, 'devices': ['NVIDIA GH200 120GB', 'NVIDIA GH200 120GB', 'NVIDIA GH200 120GB', 'NVIDIA GH200 120GB'], 'subsets': ['mcq_4_choices', 'mcq_8_choices', 'mcq_16_choices', 'mcq_32_choices'], 'model_id': 'swiss-ai/Apertus-70B-Instruct-2509', 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'match_choice_regex': '###([A-Z]+)###', 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 4608, '_step': 8, '_timestamp': 1765829468.4904356, '_wandb': {'runtime': 4608}, 'init_time_seconds': 141.31141996383667, 'mcq_16_choices/accuracy': 0.13229571984435798, 'mcq_16_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://y4gvy4t5emm079h1d0tins1ywjpnq7vs13raupdau8whx7u5xtk2d3pq0hma8vm1v7du8k7t5qy2p0qvmm9ipr0el1pebkvqg84zdxrh8x5q8m538oavg75yok2z0pb1:latest/mcq_16_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://nd58bbria3qu9cdssbaqaxxjzqzrnyon7d6ui7bgjf5gpsfdwy5n2sv2tjtjhxtvhlu3mfe3qa01n9xw5r8360tgetr5min0xkr2b11kjnx68wpwqx0wjucgk9bugf0j/mcq_16_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 20, 'path': 'media/table/mcq_16_choices/classification_report_6_39295a6159f05456f55b.table.json', 'sha256': '39295a6159f05456f55b937fd9399565aa746be5121d750a47229c6eedc653d1', 'size': 1407}, 'mcq_16_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://24ro4jnvblawjxgyspo13esxk5xsi8u31okag0dagix7omwwqsla2vuix17d2p347oz2qkcap15yl0satb9mwuxmxvn7b92047297pjsepbpjto882c1ll5ptm3p3o3j:latest/mcq_16_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://d8zkixekdm73swcoiwl7g75pywjqa0j61zu1y4a6g39x5f88x2qg0q8v0wy8ncxw6xot20od6mg0smrcg49w4gsf0kzxw56hlky85coffnsgczwn3115o7hn06kc23y1/mcq_16_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 324, 'path': 'media/table/mcq_16_choices/confusion_matrix_table_5_c039c394c9e6478008ee.table.json', 'sha256': 'c039c394c9e6478008eeb33cf082af119e1d36abca2b193c8210aff309dcd968', 'size': 5698}, 'mcq_16_choices/correct': 136, 'mcq_16_choices/generation_time': 1097.97527551651, 'mcq_16_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://w4eccv5etvdnqj4vtgkt5o19zhdqsz6n1u546jnt7bi8vhlpj9ik7s99id1k3i5irdt4zgbm12bkoc2duczngeqbzuw6a9u6ui8ixo1op2kqlkslkb4n4zsh4c9lxwff:latest/mcq_16_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://aafa3f38fe4g16ii4iz9c93ymoxycp41pbhiospn56e4qsqlrq6ndxbrhn6t5n5aeb3txza9cfdwqrihytctx1atkb3sbs15racst3jjc37fnkgft1hpecino3bvij4k/mcq_16_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 18, 'path': 'media/table/mcq_16_choices/pred_distribution_5_2271ced355bec2932728.table.json', 'sha256': '2271ced355bec29327282bd223f5ec774f58df3862044b81e9aa0ffcaf589f2b', 'size': 243}, 'mcq_16_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://4m7yd3a6xw31ctie50ocwnokdnulnc85g9cwg0r8g0mjidhtfjqeh2zy63l1hwg0vtpze85uoe0fcdr4k46b1dqfbroarqvwnxsfn4o188lm6oz712tmndc55xk2lxwl:latest/mcq_16_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://32djp7hh4wslzg37pnet2di28l1bp27uvaoy9bmyn1vim27r41lik8ahtfyk97clnzz8cxjroamwdhflwacul3doh1fnlx7s5sb0x53ij09b0orrm6xez3wed1dqe14w/mcq_16_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1028, 'path': 'media/table/mcq_16_choices/predictions_5_60a938cd15cde9f068b2.table.json', 'sha256': '60a938cd15cde9f068b28fe59ec7c56b66e5f98989343c92f13c1641af640e9f', 'size': 21893129}, 'mcq_16_choices/total': 1028, 'mcq_32_choices/accuracy': 0.038181818181818185, 'mcq_32_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://ssr5xhjerjcn7t8qlvo3aotql13zl82m35cyxr1zsxhj91fpaogpgsd1tomghub2ns65veuxgwis2tb6fttcdx9g4p2imszz3yu1o2kssydff0b3z8736616kv3xmj2n:latest/mcq_32_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://bf6uiliiccz6djdzdty3n12r3rqspvjtblncil4qdpzzn4a7xmgmzymfic9jyr0n8y7yrm7g1kahqhwrm97x5onau1iq7t44yc7je5qsig5zilro04say93j2dpj57jn/mcq_32_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 35, 'path': 'media/table/mcq_32_choices/classification_report_8_48e7660e9c0e8d0132cc.table.json', 'sha256': '48e7660e9c0e8d0132cca7ce549e1205fc4521a3764a5deca7b30ed61cf1f8b7', 'size': 1556}, 'mcq_32_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://5n6914jcxfsdjoqs8o8gi397uongtnm2v5wfggjdzv4wfhv3sm0d1a51rdl9jp9eafzed5h9fcd3ju593mbgl6l46uprgr10xzqkckjf3jpg59rips4joug6wisqqtri:latest/mcq_32_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://4ayc2csa791ogg326x32z4z13m9v5suderafjrxw70fphthl4ed2czz0pe3divc4ooiu5a4d503sfo2y2aimg7hotvsgnrocrzlq3ma4y3n2bapdiqe3hk6wfxnce9rs/mcq_32_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 1089, 'path': 'media/table/mcq_32_choices/confusion_matrix_table_7_4ab43fee52694a67dc95.table.json', 'sha256': '4ab43fee52694a67dc95086949e515717fa76621cfd3b552bfca2687b0697843', 'size': 19183}, 'mcq_32_choices/correct': 21, 'mcq_32_choices/generation_time': 623.512158870697, 'mcq_32_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://93f2hvjhc3lww08zhiqf9vl6dg8r0j81rssyil74kvknzqpmj45u0u0gsbj3mlvldnett3ysvhpoe8g1odvzsjbjiwpuykuj3v2387o93kbohyx1ucv7c54zhf6szakh:latest/mcq_32_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://m7myvs28rhk5flu61qtzwd7wrevm0cqqpxt5sio2njrlhclqdql4w6q0hw5thw0jjxahj4ravfwn5u80zv3cbm3p5vjlkwkyz46izdyggqj8tr6t0i4e0y8qkbu9ea75/mcq_32_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 28, 'path': 'media/table/mcq_32_choices/pred_distribution_7_6e93d26e486e4c9948ba.table.json', 'sha256': '6e93d26e486e4c9948ba3e87219b7044bb8832e720ec2931f291396ff013d269', 'size': 337}, 'mcq_32_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://r09uaosuw6ozau0pcsvky3cfej27z7ui9jkc7358jxthizin2csbptnsrmmaob82mq2mpd1ghheo3vy8qidfa2eca1htg3k00kr2ahu5qz5gy9wgxxe0i0vq0e3ekpsm:latest/mcq_32_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://hi4vig5cuzx96zkbtfmrljjgim5lh5wjp60rsoy2wujmy0jtzuw8q557t7ausaai15rx3f8kep0up6vr69ehgwi4nsquomgn0os40775l26607t8qh9wfe78i5j7lmpb/mcq_32_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 550, 'path': 'media/table/mcq_32_choices/predictions_7_bf7536faab247dda23c1.table.json', 'sha256': 'bf7536faab247dda23c1742412013bba136d479ea0c642aa9cb6775458aa881a', 'size': 12111616}, 'mcq_32_choices/total': 550, 'mcq_4_choices/accuracy': 0.3341389728096677, 'mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://2ka6dts9iaft20ours0hc7waas0rw9drip9es0eypvxq63oq6es9pus14odh5sp3da0139bh1a4ce7fykrytdn5col2ceinyedw8zyc97gni605yxxwk9qc5e3j76a21:latest/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://rvoj3n8zoshcfnk2srmq5u4t4wu5ckk1hkjk31q7lbppv7gtob4r2qgnxguqsezbtdxs0aqrvsx3ibq6n1nh7gv4z2h9cdv4zj4517vdqebt4c3zkion8uvuxv7w64i3/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 8, 'path': 'media/table/mcq_4_choices/classification_report_2_380fda811caef40d271d.table.json', 'sha256': '380fda811caef40d271d75c4cb22a455fdc9de9a9e939a4c90f25278799b7e4c', 'size': 591}, 'mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://5bvn5k8c6861302upkkq0ztai1c35vys40xy7kcbh8p5xivwa0ptijz13g2lu62x7gib9i01j8okrcypabhcbwvdxbzl77cte3ebdwogxrsqjkel6exu6q2h76norgul:latest/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://m4xos9d2y4xyznrdjc2cqlax4e71pxjke697ajqhlcf873np27qqhvmdcl0m2ggz6y1jaagp5kpn3toyvojoawuzlmfr0r5i8iwa94y7gyh8bb9vhm7vcziifzz2dda0/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 36, 'path': 'media/table/mcq_4_choices/confusion_matrix_table_1_46e590abbf0130160034.table.json', 'sha256': '46e590abbf0130160034459e97a0aa4c67d5778deba4faf935e08d495faf9cd7', 'size': 731}, 'mcq_4_choices/correct': 553, 'mcq_4_choices/generation_time': 1366.7024567127228, 'mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://95g8odahoslwi2z2qy3zo2tthnh79t0ddiyet085xmb573pbpq7niay9q2k41d7ve9kghiunol3tvkuuu726le2euljnxf58b97e7mzyrwqh2huk1h2rxarft7h521i4:latest/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://4qpfr2qqvkgqn24sgv8zmkhjucegum6rdxjuqvg5bnbqu0an4gawarxyp5rgz0kl4fo3ohl09fp63a9x74m68pbylu5zy5nm0hyi09wtlb73cz4xf7j3jmx8wkz20las/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 6, 'path': 'media/table/mcq_4_choices/pred_distribution_1_3f02ddbbfed8e15a634a.table.json', 'sha256': '3f02ddbbfed8e15a634a702ff9be27141f01eec50c69784bff1f7c9c365186a9', 'size': 112}, 'mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://u4uf3alfz3ldquqoo64rl5zv548thciqj9xissp3se4y9w4ecscxbb23mojy9agsbn5kujea946o2le03m2b3jo1cvi9jth4nlc61gt3rvmcem6krjldfxyndui0vuex:latest/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://s0op9fe7aw4s3mtmded83ciysisv658vqcmg1nqrzwjguu5hfb1bvfet9iy7uueclmlzfnf8c7c910vcaqwrt9qadpdsmfy6jyo06zcp7ppi9k8x5dcj92tdqkycq602/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/mcq_4_choices/predictions_1_dd671bb2a0ad41ef46f1.table.json', 'sha256': 'dd671bb2a0ad41ef46f121d2b39c799728942464d1f6198f47b51d285ce0ff5b', 'size': 29020514}, 'mcq_4_choices/total': 1655, 'mcq_8_choices/accuracy': 0.20300751879699247, 'mcq_8_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://ibojp1b1r1zbym1q6p33f0bw5siut60sz1jd2rewrwgkpx7jczibq23qu5ej8b4ki3spnebh6zq96n6auu9ply2gyv3yqd8kcq8bc3rsw5noxmy902qosmjfbfv8m5ol:latest/mcq_8_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://1i999r147ziwwn20eiyvmm2y3p96o9uloph5eie6m11viiohmrur0nh7lpkws3g3qp69g2gsar5sqrucd3ghtdaidbsnbys8wtlmsgy1cjsavbt1hk5axkbd3io6m2hm/mcq_8_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 11, 'path': 'media/table/mcq_8_choices/classification_report_4_83886d7f8724a58f63fb.table.json', 'sha256': '83886d7f8724a58f63fbdf9d1d5d19ed16d6a5920aa4be25656d355ba8219949', 'size': 873}, 'mcq_8_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://dd56dexnjuie20rwt7qf2urmfuy9utkvuo9o8qt6jndkqn731rl26ngdoa8d4cnwzhd9cmf2krt2mkykp3wmeay83u9yqihvvxxplcj8s77tbecrlqeudoktg4ki76yb:latest/mcq_8_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://jjidf1ib26sff4nqsxmpl791m48mi22y4d3c532zoydp4bs4noyzdr2pspa5yv09g3h97n4m8gwzldfmouf8akuazbxm4c1k4apyz1marptneeaesewnfflvsc9t5a1n/mcq_8_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 81, 'path': 'media/table/mcq_8_choices/confusion_matrix_table_3_794dce278190049f98aa.table.json', 'sha256': '794dce278190049f98aabba7592ba096caf2839c4f318d56a6452fa191300fc0', 'size': 1529}, 'mcq_8_choices/correct': 297, 'mcq_8_choices/generation_time': 1354.9211330413818, 'mcq_8_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://zla5zy01wmxwvdiaqvpb81vkumbo9u4b2wd8g9z2fngaawci7vukyl8bet4ygtqac465c9pxyqvw8phzxq5104rcgxwqun4an4awx70h0b3sbia81ztyv0n40aospcl5:latest/mcq_8_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://jwdhttno2u0k0pgm5nx0d89eic0g3wki1qmxavcg11euvjeqp7pmbtakq0miyw5q0ovmfn8vtdga28r844w37jmykoaeymdv580g56d7n1wewe58qhl7p7aiex2ye3w4/mcq_8_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 9, 'path': 'media/table/mcq_8_choices/pred_distribution_3_fed95252bcb88f42de22.table.json', 'sha256': 'fed95252bcb88f42de22d3f2e150f207d82388e72a393001eaf46e9b8917a49a', 'size': 146}, 'mcq_8_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://7xxkr2l76mbwbp74n8knqruz7ylbrrmshv94hkoukiayhpo559404mtffeuzvgjte5bff16ohwn87o1meold5g5yg8fax1ypcugjm4qbmvwy81brle5f51ludk740z67:latest/mcq_8_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://xaufd9u255uf27qqjt4ypkgpdvmhu0kamfsz13j13j34sqt3bbp94uzznqkl1yd8cogm2jwdmzzu33uhwamjaashnh0x6puyw0ykpadruldwlh2dtk1sv8kk1zbh0g9f/mcq_8_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1463, 'path': 'media/table/mcq_8_choices/predictions_3_bd187e4f4abc5c28c0e8.table.json', 'sha256': 'bd187e4f4abc5c28c0e8944b3bf6459523cd9c557612305f84071ec0ed8567c6', 'size': 28124409}, 'mcq_8_choices/total': 1463}"
Apertus-8B-Instruct_2025-12-16_15-13-31,sdocardc,finished,2025-12-16T14:13:32Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'name': 'Apertus-8B-Instruct', 'entity': 'lsaie-peft-apertus', 'project': 'LEXam-Evaluation'}, 'devices': ['NVIDIA GH200 120GB', 'NVIDIA GH200 120GB', 'NVIDIA GH200 120GB', 'NVIDIA GH200 120GB'], 'subsets': ['mcq_4_choices', 'mcq_8_choices', 'mcq_16_choices', 'mcq_32_choices'], 'model_id': 'swiss-ai/Apertus-8B-Instruct-2509', 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'match_choice_regex': '###([A-Z]+)###', 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 563, '_step': 8, '_timestamp': 1765894976.2460418, '_wandb': {'runtime': 563}, 'init_time_seconds': 67.63329815864563, 'mcq_16_choices/accuracy': 0.07003891050583658, 'mcq_16_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://b46o5x2u2qy5xyknt01vlpx764k1g17elou46abx8afem1imqcgsorez6futb2mcmlwqoh4f1g0d48xgqvv1s538ocb1k3ah26hcvm1jnj57i7prylam16wqzzb4wi9s:latest/mcq_16_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://u9bli7bympu6mvylk4xx89zupepmc2vi732k2cib6cdrqthb2j2pvsgsn59vre81tbvd2d03dcttn1kqw6jzogpj71nfdor7rqhobidtuq1mhy3vp7nec0inrt0vck09/mcq_16_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 20, 'path': 'media/table/mcq_16_choices/classification_report_6_127f44c5211d2392c143.table.json', 'sha256': '127f44c5211d2392c143b51f459a22435877f609bd67b480be1db3a750698728', 'size': 1364}, 'mcq_16_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://k8xu1qm18iwrrxgquvtw3mykn8pykd3xu6052xa0g7fsa5el9m6j92jxu4ww415i2ym4d9uyldu2lch2sz0cvrxi80asaiagmr5txf02i0oljrxvbf6ssxvltjt3ftgq:latest/mcq_16_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://x9hll8rss7lw82iwfwwa1k0sthdpvw5mg5q5apoc1fc73nsybnaqnlb6ei8p3wdo36vwie1rqscccvk5ogz8vf7pbo9nrvj2b1vduzeu5jizze2p88r3395dpjk6ylt8/mcq_16_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 324, 'path': 'media/table/mcq_16_choices/confusion_matrix_table_5_4cf5eaccf74098ce20a2.table.json', 'sha256': '4cf5eaccf74098ce20a2ded3d7754c90c62d001762932f77ec9a3195132d58c8', 'size': 5696}, 'mcq_16_choices/correct': 72, 'mcq_16_choices/generation_time': 107.73073935508728, 'mcq_16_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://xkgj5c7563e3ki2j9o9bqhpc0vs72sf8s1qinqitbkdnqque9u5vwu86b06h3bonlto97wssjz1pj3l90pw8eakqyzq0xf4vzrwzjy1mgn2zxnpyrnlp1bejp0yipybe:latest/mcq_16_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://7iatstr91ljupspzmtbq4kzaqexdj5h42m3mkdupx4ubeac5t7lpg7krf1g57yu682tcq14zkxujvad5ol9lwim3yn50h3fl054dztkd6ect5uulny6j8b2totxygt2u/mcq_16_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 18, 'path': 'media/table/mcq_16_choices/pred_distribution_5_01ad561258382f7a3705.table.json', 'sha256': '01ad561258382f7a3705f08429d50de50880fef9dd7b57f66742cf521c212e6f', 'size': 238}, 'mcq_16_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://9zt4m7m14wnu1jqwmsos1rv7qg214xtjevo5yetlnwdeyo3xmdscfjzt87hsx5wy3vim2ziiayb6n5yekcr0xruw41h7dtx2zrsii5mggy0jj3bodg5pka6jmkcn71ic:latest/mcq_16_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://6qgj86dway3ed4ti77qkrn48kpcryo6exkhs6fv5mfzm4l57qxzsdaunp6q77mbgf5gzik231p93lq7z2jhcb0nsv5l6zd9n1llwy8g299y0bzl9e49qpnl83gqt8fvw/mcq_16_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1028, 'path': 'media/table/mcq_16_choices/predictions_5_d1acd09bfdd90830d845.table.json', 'sha256': 'd1acd09bfdd90830d84548eebb7c5bb93d6c0cca151f916f1f6582fae0f109b2', 'size': 11625626}, 'mcq_16_choices/total': 1028, 'mcq_32_choices/accuracy': 0.03090909090909091, 'mcq_32_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://g14242gdtg124vnu256w8rm206x4lmlkosuhif5vpzavk3co9ymitvt44xcsklduagvna6jo2opfg0eqgnjq060s7i1q4nbenuau8a1kabnyhmoryrd1c59tn7nj8lmu:latest/mcq_32_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://0wzsnysotfb3jqpiqm8sus22jxvyqrzftyi6nflecv4yamm2vhqxd7u1p9658i9ueufi10aiamycknxee08rl0jwic639yxbwmbq64euhp4qd8sv8mobv6dr30k18emc/mcq_32_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 35, 'path': 'media/table/mcq_32_choices/classification_report_8_3a449c44f644d4c2e5b4.table.json', 'sha256': '3a449c44f644d4c2e5b475d4be64980e4d2faf33d7a1e18d425bed9731ad8bec', 'size': 1395}, 'mcq_32_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://burue7ioum1s3ek8e7ei67foslk8wxqlwlhd887ir4l9abrolboed3akxcatwsmvd5xi6jdgipr6qf0vj2z8d5rf67ix8zj6kwt5syu5cni3qig9i9atdp533ryv2ffz:latest/mcq_32_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://0vtuwy9lgmozuygmdp66qlwqu0alulg5rf10vyfghpyp07mqhy71uqz3njxhmffwkho4tvfe890xq1fwjxpk4f18ypqwei52cxb5x09b8ingxgnls3tfq8m9pe8uef4t/mcq_32_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 1089, 'path': 'media/table/mcq_32_choices/confusion_matrix_table_7_0c669e23dc4232b86d42.table.json', 'sha256': '0c669e23dc4232b86d4242354d975212c2c011e06bf3572bfe39641252225416', 'size': 19171}, 'mcq_32_choices/correct': 17, 'mcq_32_choices/generation_time': 70.65574145317078, 'mcq_32_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://c7wba2qozezpaju7kiyqe9yu018vglzqe9jkfi9tzasu2su4k5cwuqxpn0ntdahy7hcv97teup436gue24miwd6zzgz7b4k708em786oicny14yrtsokyjeh7fvu1cro:latest/mcq_32_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://vgxijwj2sqiz6qjwbd4ka18egy2nb1vcg2h0nxcl7sn236u4197x2v05x1kix9twdrb1tdlhp9xo97i5mvlfmfd1k9dcjbldhuqo747kauvdwv0jfx6xgtqykmv1qjep/mcq_32_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 25, 'path': 'media/table/mcq_32_choices/pred_distribution_7_e8d40834ab383cb41672.table.json', 'sha256': 'e8d40834ab383cb41672af8c53bdd59d04279cc2adb593ad6d125e4baee0a940', 'size': 309}, 'mcq_32_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://d1ypd0arm93tyx25xcy7msvsfaevsjlbenrmf8ys3zvg7shisgn3hv8888svamxkhe86yph2a6xabxw8mbqlvho3cw8rii6n34f4kpa89hq42jofjki1e15l4p3sdiqs:latest/mcq_32_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://rbd8fsoyp844fgq8p0trqug160tglis7ztgaoqijw36m9ulasl2apnpvocet8zw9xlwd3tbfr2f1w48p0e2rtd0tw7ek48id6epeke9pfizk9kcb6bqd0b4ber207w19/mcq_32_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 550, 'path': 'media/table/mcq_32_choices/predictions_7_0a132f46a0165398a13c.table.json', 'sha256': '0a132f46a0165398a13c6d2865875f4fac6eec2808fa89c052ab8a34692b1a3a', 'size': 6639715}, 'mcq_32_choices/total': 550, 'mcq_4_choices/accuracy': 0.27250755287009065, 'mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://gam2afdegoervur20u5excpcx1e6eulh654231pwb56h1bk2y1til7c9iend9u4xsmn9694zw3ycn5t99nzh6u4hm88ef2ymk5pa153aq9sc8zsai6vod3yvmvirmcwv:latest/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://nih0v0jbznidxxywllbiuizhc0m39o6h5aall258m0syjya0qefmi081s8w6re2e35c59krpvxecl0ja3d6qc09mrk5w70lltto1nm2p8pnh68ml10h6junhc89eyigg/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/mcq_4_choices/classification_report_2_f51a5c85c28262ebfac0.table.json', 'sha256': 'f51a5c85c28262ebfac0a46bb29a93d014b48ca135473da93d73f186a15825ed', 'size': 560}, 'mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://em0y8yxu6kt0tr6qbrr4ash4mkt4kxkga0itf19j9v8yycizq7ew6h7m5tn0ckyqz3me1utmx5t5en5876qkfj8wjyb7v5rek4s92ns98ykxbstijk0xa04vax96yqnm:latest/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://923oq02btu5qajun9nv3uuwuhqn131xy8us11fvm0dbg8xe9eh6qvasn09t91xrmas9b8f2bnxnfxjd3ybbd1g8oxli999rm8uk6bqybugau33773uhh76fbgaet9ko0/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/mcq_4_choices/confusion_matrix_table_1_2f75c9e382aa2bfedc90.table.json', 'sha256': '2f75c9e382aa2bfedc908bc8d59761c8b2a6228130fc54bc3b7f30678660c1b0', 'size': 538}, 'mcq_4_choices/correct': 451, 'mcq_4_choices/generation_time': 127.70233941078186, 'mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://mh35b8uoc63vdqrhj043j3ecofr4kavycpaf0grrcu2un6dd6t9u7vd63j1z8wiefqu7f5kc0ajgnfxigzobu203iq5kn87ebbhjh5beni8oeejsqz1y1j8dy8timuhi:latest/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://uf8td5sh8w2zq3mtj9qt145nsu4kecucybl29imwh7v36jekuu6bkn438ubmhpaxg00spnyh6swxgxkz84soh07dg3t8rpdxwxxpo7zl0nglpvd6xp80i0njqipckxtf/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 5, 'path': 'media/table/mcq_4_choices/pred_distribution_1_7cfaa564e048d17be8bb.table.json', 'sha256': '7cfaa564e048d17be8bb47bfbd0538995511c76820d0c5d691fb031bc45f30cd', 'size': 102}, 'mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://cjbt2qta90vjpni8a2q4v6f34h1h811h6p2vu6ocah6o609tahvpywobnxq4l13xysmvpc7bx3kq3w8phj1yu4lyv6ihx799ivhxwcrjuk5xswxb9wl54fetek5hutn0:latest/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://v7m28ang4p77ox4pq6tbb4mjo16hxxej2u5u7r2wcdmpcu2d72j04hrjzp68gjue2kw9lcczrcwjay3q3s221chc59ouopves9a06b295meuvy2iqy9vjzome3ef8v88/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/mcq_4_choices/predictions_1_99bc26f778f8da9389f0.table.json', 'sha256': '99bc26f778f8da9389f0c06ec3c601db56ebf1aa884ed936b2c3228800064dd1', 'size': 15818342}, 'mcq_4_choices/total': 1655, 'mcq_8_choices/accuracy': 0.17634996582365003, 'mcq_8_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://33uv466uoc91hvwrhpuf9926fnl35otbqcvi077hvp5n1wdl4gmkt606ru8wfjkpmkys80yg15ksur9hfin1meixn9oif6ff1apxz4tuhk17af2h39v3jxax9mndy4wc:latest/mcq_8_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://zbkjwgmygynoeqpyfh9th7rhubdvqnrzeg7liejz73k8ugkd1r0ujk9pfcqx666nksu2ft92zz7k4xvxx8183gn0d7zno7heqx0zzd7vc0tgcfro4qwucyn4cnb6w6mf/mcq_8_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 12, 'path': 'media/table/mcq_8_choices/classification_report_4_897b0004d2986efbc074.table.json', 'sha256': '897b0004d2986efbc074f0f04cf7bcdd71c1e88e69dda8e1dec8d4fa4c7a3119', 'size': 896}, 'mcq_8_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://uu0rrxqbrs1k1lt4he6pyivqi6p4cgpd7kkaruxwtk4s6d2ubkxm68tjbiv1svsay45b4qsmm55cl9ppyi35m9tompslnahdq5vtkrk7co6n5jk76v37fvd2pzso1yp6:latest/mcq_8_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://pb93o319uq7i6j9u02xham0dnythxfgf92l1qw54xllfybfwdeeribstpan4n6tw40tjvkff8n4iwqu3wc3m2zpz3cxdell38q9drtpo195u30weqnzgd7yh8rryqxc2/mcq_8_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 100, 'path': 'media/table/mcq_8_choices/confusion_matrix_table_3_4d52a5530c35e0d7928c.table.json', 'sha256': '4d52a5530c35e0d7928cbe9c72aa756f4d2d0df85ac0ba288344c8482e1e7d70', 'size': 1865}, 'mcq_8_choices/correct': 258, 'mcq_8_choices/generation_time': 172.30910897254944, 'mcq_8_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://ps3edl5fj7xda5q763ov4dr14u1fdntcjgiucd3t9hdet1wwykq19wufruikdev5dlnzynadl5ptycwgdueirz4f6kom0lk5h1zedulhi9e51qo2jjcapvxoysvtzn87:latest/mcq_8_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://len63espz8or8bpdpck081il5qrn9yi8vkf5vyxsertbt15wagc6f8wrdb4j6jq0j8brx6r7d21513y5ut4mwsjeqoflmd9py41lmkdde3d14lfec269wiwi9ji2fb2z/mcq_8_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 10, 'path': 'media/table/mcq_8_choices/pred_distribution_3_97f82747694da4b136d7.table.json', 'sha256': '97f82747694da4b136d7a3fcc47af57b105732c3e4e7950050db20f183995fac', 'size': 158}, 'mcq_8_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://lu61af7wsq8bnkkwr1x41gdm1rxqv0i7wpebw30dcojrd93bvurqf3xrh4uozgrhyag2z0cwl6mgka7p69l1tuhq8yyntapv13g1xp8csqhewxkdwgds3de9j225qy2k:latest/mcq_8_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://0xp2bbjmh39leskvcwxxvarqhxhgkh8pce7jd2ooeygyp0xob5hynh6d2d1l0kuwpmpkdr3twfdq7ci9j5hcak2olxqio77s6fhneowb3vomrvvrqqnlid988e011mic/mcq_8_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1463, 'path': 'media/table/mcq_8_choices/predictions_3_2b635b6ed77278c648f6.table.json', 'sha256': '2b635b6ed77278c648f6f0af0e1f9e1af70775c26cdc9bc0995118d0111c5935', 'size': 16399523}, 'mcq_8_choices/total': 1463}"
lr1e-5_r8_lora_8B,z3pft42h,finished,2025-12-16T20:15:06Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r8_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-5_r8_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 8, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['q_proj', 'v_proj', 'o_proj', 'up_proj', 'down_proj', 'k_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8073261120, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3133, '_step': 468, '_timestamp': 1766156600.1984904, '_wandb': {'runtime': 3133}, 'eval/accuracy': 0.7932822492366193, 'total_flos': 5067570127835234000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.08037988096475601, 'train/learning_rate': 1e-05, 'train/loss': 0.8234571218490601, 'train/mean_token_accuracy': 0.7904459834098816, 'train/num_tokens': 72643344, 'train_loss': 0.9959131377156848, 'train_runtime': 3131.355, 'train_samples_per_second': 19.068, 'train_steps_per_second': 0.149}"
lr1e-4_r1_lora_8B,xigqzei7,finished,2025-12-16T20:15:11Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r1_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-4_r1_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 1, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['up_proj', 'v_proj', 'k_proj', 'q_proj', 'o_proj', 'down_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8055828544, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3207, '_step': 468, '_timestamp': 1766156528.9121284, '_wandb': {'runtime': 3207}, 'eval/accuracy': 0.8091260010370456, 'total_flos': 5055848228465934000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.3167077600955963, 'train/learning_rate': 0.0001, 'train/loss': 0.7721115350723267, 'train/mean_token_accuracy': 0.8007049560546875, 'train/num_tokens': 72643344, 'train_loss': 0.8502480977352477, 'train_runtime': 3206.3641, 'train_samples_per_second': 18.622, 'train_steps_per_second': 0.146}"
lr1e-5_r32_lora_8B,dk1ek4k2,finished,2025-12-16T20:15:12Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r32_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-5_r32_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 32, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['k_proj', 'up_proj', 'o_proj', 'q_proj', 'down_proj', 'v_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8133029952, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3075, '_step': 468, '_timestamp': 1766156551.2266042, '_wandb': {'runtime': 3075}, 'eval/accuracy': 0.795241113095581, 'total_flos': 5107759498865410000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.045670703053474426, 'train/learning_rate': 1e-05, 'train/loss': 0.8237111568450928, 'train/mean_token_accuracy': 0.7906030416488647, 'train/num_tokens': 72643344, 'train_loss': 0.9978820876850562, 'train_runtime': 3069.4744, 'train_samples_per_second': 19.453, 'train_steps_per_second': 0.152}"
lr1e-4_r8_lora_8B,v21rparv,finished,2025-12-16T20:15:14Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r8_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-4_r8_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 8, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['q_proj', 'down_proj', 'up_proj', 'o_proj', 'v_proj', 'k_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8073261120, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3086, '_step': 468, '_timestamp': 1766156568.9094431, '_wandb': {'runtime': 3086}, 'eval/accuracy': 0.8090107737512243, 'total_flos': 5067570127835234000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.107964389026165, 'train/learning_rate': 0.0001, 'train/loss': 0.7732788324356079, 'train/mean_token_accuracy': 0.8002148270606995, 'train/num_tokens': 72643344, 'train_loss': 0.8536912842276775, 'train_runtime': 3086.1573, 'train_samples_per_second': 19.347, 'train_steps_per_second': 0.151}"
lr1e-5_r4_lora_8B,q1tzzlp8,finished,2025-12-16T20:15:15Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r4_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-5_r4_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 4, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['v_proj', 'up_proj', 'q_proj', 'down_proj', 'k_proj', 'o_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8063299648, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3183, '_step': 468, '_timestamp': 1766156573.0023265, '_wandb': {'runtime': 3183}, 'eval/accuracy': 0.7956444085959555, 'total_flos': 5060871895482630000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.115815170109272, 'train/learning_rate': 1e-05, 'train/loss': 0.8237081170082092, 'train/mean_token_accuracy': 0.7904069125652313, 'train/num_tokens': 72643344, 'train_loss': 0.9966564422245964, 'train_runtime': 3179.3209, 'train_samples_per_second': 18.78, 'train_steps_per_second': 0.147}"
lr1e-5_r64_lora_8B,3tnilvkx,finished,2025-12-16T20:15:16Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r64_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-5_r64_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 64, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['up_proj', 'k_proj', 'q_proj', 'o_proj', 'down_proj', 'v_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8212721728, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3149, '_step': 467, '_timestamp': 1765919250.5904312, '_wandb': {'runtime': 3149}, 'total_flos': 5161345308294119000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.030925214290618896, 'train/learning_rate': 1e-05, 'train/loss': 0.823474109172821, 'train/mean_token_accuracy': 0.790460854768753, 'train/num_tokens': 72643344, 'train_loss': 0.998046124900434, 'train_runtime': 3135.2116, 'train_samples_per_second': 19.045, 'train_steps_per_second': 0.149}"
lr1e-4_r4_lora_8B,nsgnftr2,finished,2025-12-16T20:15:16Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r4_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-4_r4_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 4, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['v_proj', 'up_proj', 'k_proj', 'o_proj', 'down_proj', 'q_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8063299648, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3167, '_step': 468, '_timestamp': 1766156648.3260024, '_wandb': {'runtime': 3167}, 'eval/accuracy': 0.8025004321023218, 'total_flos': 5060871895482630000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.16849084198474884, 'train/learning_rate': 0.0001, 'train/loss': 0.7731562852859497, 'train/mean_token_accuracy': 0.8001061081886292, 'train/num_tokens': 72643344, 'train_loss': 0.8527364249658278, 'train_runtime': 3165.6754, 'train_samples_per_second': 18.861, 'train_steps_per_second': 0.148}"
lr1e-5_r256_lora_8B,f797iron,finished,2025-12-16T20:15:17Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r256_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-5_r256_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 256, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['o_proj', 'v_proj', 'down_proj', 'up_proj', 'k_proj', 'q_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8690872384, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3276, '_step': 468, '_timestamp': 1766156546.8354402, '_wandb': {'runtime': 3276}, 'eval/accuracy': 0.8008296364579133, 'total_flos': 5482860233585852000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.01690639927983284, 'train/learning_rate': 1e-05, 'train/loss': 0.8242110013961792, 'train/mean_token_accuracy': 0.7904013097286224, 'train/num_tokens': 72643344, 'train_loss': 1.0002775681095408, 'train_runtime': 3270.6523, 'train_samples_per_second': 18.256, 'train_steps_per_second': 0.143}"
lr1e-4_r128_lora_8B,ni6zmwwm,finished,2025-12-16T20:15:17Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r128_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-4_r128_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 128, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['v_proj', 'up_proj', 'o_proj', 'k_proj', 'q_proj', 'down_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8372105280, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3224, '_step': 468, '_timestamp': 1766156639.6489325, '_wandb': {'runtime': 3224}, 'eval/accuracy': 0.8060148643198709, 'total_flos': 5268516935204602000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.03061850368976593, 'train/learning_rate': 0.0001, 'train/loss': 0.7721713781356812, 'train/mean_token_accuracy': 0.8000917732715607, 'train/num_tokens': 72643344, 'train_loss': 0.8535180435190874, 'train_runtime': 3208.6378, 'train_samples_per_second': 18.609, 'train_steps_per_second': 0.146}"
lr1e-4_r2_lora_8B,0f7cxq0h,finished,2025-12-16T20:15:18Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r2_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-4_r2_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 2, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['o_proj', 'down_proj', 'q_proj', 'up_proj', 'v_proj', 'k_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8058318912, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3169, '_step': 468, '_timestamp': 1766156537.95547, '_wandb': {'runtime': 3169}, 'eval/accuracy': 0.8082041827504753, 'total_flos': 5057522780380070000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.33198755979537964, 'train/learning_rate': 0.0001, 'train/loss': 0.772783637046814, 'train/mean_token_accuracy': 0.8004233837127686, 'train/num_tokens': 72643344, 'train_loss': 0.8519827794977634, 'train_runtime': 3169.5719, 'train_samples_per_second': 18.838, 'train_steps_per_second': 0.147}"
lr1e-4_r64_lora_8B,ni6g3xeo,finished,2025-12-16T20:15:18Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r64_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-4_r64_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 64, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['down_proj', 'up_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8212721728, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3147, '_step': 468, '_timestamp': 1766156630.4145117, '_wandb': {'runtime': 3147}, 'eval/accuracy': 0.805842023391139, 'total_flos': 5161345308294119000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.03876970335841179, 'train/learning_rate': 0.0001, 'train/loss': 0.77247154712677, 'train/mean_token_accuracy': 0.7998234629631042, 'train/num_tokens': 72643344, 'train_loss': 0.853467670063901, 'train_runtime': 3139.4975, 'train_samples_per_second': 19.019, 'train_steps_per_second': 0.149}"
lr1e-5_r1_lora_8B,ti9xg0kf,finished,2025-12-16T20:15:18Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r1_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-5_r1_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 1, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['v_proj', 'q_proj', 'down_proj', 'k_proj', 'o_proj', 'up_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8055828544, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3186, '_step': 468, '_timestamp': 1766156613.1858962, '_wandb': {'runtime': 3186}, 'eval/accuracy': 0.7870023621593594, 'total_flos': 5055848228465934000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.2672012448310852, 'train/learning_rate': 1e-05, 'train/loss': 0.818233847618103, 'train/mean_token_accuracy': 0.7910250723361969, 'train/num_tokens': 72643344, 'train_loss': 0.9829016225751512, 'train_runtime': 3183.9, 'train_samples_per_second': 18.753, 'train_steps_per_second': 0.147}"
lr1e-5_r128_lora_8B,fbcwtoru,finished,2025-12-16T20:15:19Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r128_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-5_r128_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 128, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['down_proj', 'k_proj', 'o_proj', 'v_proj', 'q_proj', 'up_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8372105280, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3160, '_step': 468, '_timestamp': 1766156555.6267302, '_wandb': {'runtime': 3160}, 'eval/accuracy': 0.7998502045284324, 'total_flos': 5268516935204602000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.021044062450528145, 'train/learning_rate': 1e-05, 'train/loss': 0.8236039280891418, 'train/mean_token_accuracy': 0.7906514108181, 'train/num_tokens': 72643344, 'train_loss': 0.9989285471607836, 'train_runtime': 3151.926, 'train_samples_per_second': 18.944, 'train_steps_per_second': 0.148}"
lr1e-4_r32_lora_8B,ipu4ezfc,finished,2025-12-16T20:15:20Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r32_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-4_r32_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 32, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['q_proj', 'down_proj', 'up_proj', 'o_proj', 'v_proj', 'k_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8133029952, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3158, '_step': 468, '_timestamp': 1766156608.779828, '_wandb': {'runtime': 3158}, 'eval/accuracy': 0.8099902056807052, 'total_flos': 5107759498865410000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.056845907121896744, 'train/learning_rate': 0.0001, 'train/loss': 0.7724519371986389, 'train/mean_token_accuracy': 0.8003969788551331, 'train/num_tokens': 72643344, 'train_loss': 0.8534800449836943, 'train_runtime': 3150.2286, 'train_samples_per_second': 18.954, 'train_steps_per_second': 0.148}"
lr1e-4_r512_lora_8B,nnf44d13,finished,2025-12-16T20:15:21Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r512_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-4_r512_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 512, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['down_proj', 'q_proj', 'v_proj', 'k_proj', 'o_proj', 'up_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 9328406592, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3495, '_step': 468, '_timestamp': 1766156644.0225377, '_wandb': {'runtime': 3495}, 'eval/accuracy': 0.8082617963933859, 'total_flos': 5911546814779097000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.01631622388958931, 'train/learning_rate': 0.0001, 'train/loss': 0.7735832929611206, 'train/mean_token_accuracy': 0.7999721467494965, 'train/num_tokens': 72643344, 'train_loss': 0.8542151650218432, 'train_runtime': 3483.9455, 'train_samples_per_second': 17.138, 'train_steps_per_second': 0.134}"
lr1e-5_r512_lora_8B,a37q1485,finished,2025-12-16T20:15:22Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r512_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-5_r512_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 512, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['down_proj', 'v_proj', 'k_proj', 'up_proj', 'q_proj', 'o_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 9328406592, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3468, '_step': 468, '_timestamp': 1766156564.5062208, '_wandb': {'runtime': 3468}, 'eval/accuracy': 0.8005991818862707, 'total_flos': 5911546814779097000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.009934136644005775, 'train/learning_rate': 1e-05, 'train/loss': 0.823948860168457, 'train/mean_token_accuracy': 0.7908680140972137, 'train/num_tokens': 72643344, 'train_loss': 1.002242637012449, 'train_runtime': 3456.7998, 'train_samples_per_second': 17.273, 'train_steps_per_second': 0.135}"
lr1e-5_r2_lora_8B,e3tj5fm3,finished,2025-12-16T20:15:22Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r2_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-5_r2_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 2, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['down_proj', 'up_proj', 'k_proj', 'o_proj', 'q_proj', 'v_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8058318912, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3168, '_step': 468, '_timestamp': 1766156604.6288824, '_wandb': {'runtime': 3168}, 'eval/accuracy': 0.7954715676672236, 'total_flos': 5057522780380070000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.17076259851455688, 'train/learning_rate': 1e-05, 'train/loss': 0.8215897679328918, 'train/mean_token_accuracy': 0.7904774248600006, 'train/num_tokens': 72643344, 'train_loss': 0.989653115098941, 'train_runtime': 3167.5831, 'train_samples_per_second': 18.85, 'train_steps_per_second': 0.147}"
lr1e-3_r4_lora_8B,8zjkvazd,finished,2025-12-16T20:15:23Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-3_r4_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-3_r4_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 4, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['q_proj', 'o_proj', 'up_proj', 'v_proj', 'k_proj', 'down_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8063299648, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3188, '_step': 468, '_timestamp': 1766156577.4161432, '_wandb': {'runtime': 3188}, 'eval/accuracy': 0.8203030477617099, 'total_flos': 5060871895482630000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.0773281529545784, 'train/learning_rate': 0.001, 'train/loss': 0.7370131015777588, 'train/mean_token_accuracy': 0.8074201047420502, 'train/num_tokens': 72643344, 'train_loss': 0.8094034904586171, 'train_runtime': 3185.6723, 'train_samples_per_second': 18.743, 'train_steps_per_second': 0.147}"
lr1e-3_r2_lora_8B,askkgrv2,finished,2025-12-16T20:15:25Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-3_r2_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-3_r2_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 2, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['down_proj', 'q_proj', 'up_proj', 'v_proj', 'o_proj', 'k_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8058318912, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3176, '_step': 468, '_timestamp': 1766156626.068695, '_wandb': {'runtime': 3176}, 'eval/accuracy': 0.813389410612433, 'total_flos': 5057522780380070000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.1248731166124344, 'train/learning_rate': 0.001, 'train/loss': 0.7570953369140625, 'train/mean_token_accuracy': 0.8043979406356812, 'train/num_tokens': 72643344, 'train_loss': 0.826716138795816, 'train_runtime': 3171.0357, 'train_samples_per_second': 18.829, 'train_steps_per_second': 0.147}"
lr1e-3_r1_lora_8B,iye7ydcn,finished,2025-12-16T20:15:26Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-3_r1_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-3_r1_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 1, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['k_proj', 'down_proj', 'q_proj', 'v_proj', 'up_proj', 'o_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8055828544, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3198, '_step': 468, '_timestamp': 1766156617.4156528, '_wandb': {'runtime': 3198}, 'eval/accuracy': 0.8211672524053696, 'total_flos': 5055848228465934000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.13218946754932404, 'train/learning_rate': 0.001, 'train/loss': 0.7600173950195312, 'train/mean_token_accuracy': 0.8023380041122437, 'train/num_tokens': 72643344, 'train_loss': 0.8244786688806669, 'train_runtime': 3198.2689, 'train_samples_per_second': 18.669, 'train_steps_per_second': 0.146}"
lr1e-3_r8_lora_8B,6ed584go,finished,2025-12-16T20:15:27Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-3_r8_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-3_r8_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 8, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['k_proj', 'v_proj', 'o_proj', 'q_proj', 'down_proj', 'up_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8073261120, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3139, '_step': 468, '_timestamp': 1766156591.391143, '_wandb': {'runtime': 3139}, 'eval/accuracy': 0.8355130494901193, 'total_flos': 5067570127835234000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.0563790537416935, 'train/learning_rate': 0.001, 'train/loss': 0.7270795702934265, 'train/mean_token_accuracy': 0.8104194104671478, 'train/num_tokens': 72643344, 'train_loss': 0.8039658369548316, 'train_runtime': 3139.3387, 'train_samples_per_second': 19.02, 'train_steps_per_second': 0.149}"
lr1e-3_r16_lora_8B,cssl47wd,finished,2025-12-16T20:15:27Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-3_r16_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-3_r16_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 16, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['k_proj', 'o_proj', 'up_proj', 'q_proj', 'v_proj', 'down_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8093184064, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3161, '_step': 468, '_timestamp': 1766156560.256821, '_wandb': {'runtime': 3161}, 'eval/accuracy': 0.8223195252635824, 'total_flos': 5080966588782346000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.0424332357943058, 'train/learning_rate': 0.001, 'train/loss': 0.7239017486572266, 'train/mean_token_accuracy': 0.8106657862663269, 'train/num_tokens': 72643344, 'train_loss': 0.8031594355050196, 'train_runtime': 3151.9951, 'train_samples_per_second': 18.943, 'train_steps_per_second': 0.148}"
lr1e-3_r32_lora_8B,botfhokj,finished,2025-12-16T20:15:30Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-3_r32_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-3_r32_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 32, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['q_proj', 'up_proj', 'o_proj', 'down_proj', 'k_proj', 'v_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8133029952, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3139, '_step': 468, '_timestamp': 1766156595.768463, '_wandb': {'runtime': 3139}, 'eval/accuracy': 0.8108544103243648, 'total_flos': 5107759498865410000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.031229540705680847, 'train/learning_rate': 0.001, 'train/loss': 0.7146890163421631, 'train/mean_token_accuracy': 0.8128306567668915, 'train/num_tokens': 72643344, 'train_loss': 0.7975400843252717, 'train_runtime': 3136.7606, 'train_samples_per_second': 19.035, 'train_steps_per_second': 0.149}"
lr1e-3_r128_lora_8B,4gmxfpal,finished,2025-12-16T20:15:31Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-3_r128_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-3_r128_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 128, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['v_proj', 'q_proj', 'down_proj', 'o_proj', 'up_proj', 'k_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8372105280, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3192, '_step': 468, '_timestamp': 1766156587.0980475, '_wandb': {'runtime': 3192}, 'eval/accuracy': 0.814196001613182, 'total_flos': 5268516935204602000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.01700824312865734, 'train/learning_rate': 0.001, 'train/loss': 0.7158366441726685, 'train/mean_token_accuracy': 0.8123259842395782, 'train/num_tokens': 72643344, 'train_loss': 0.7989356087668295, 'train_runtime': 3174.5012, 'train_samples_per_second': 18.809, 'train_steps_per_second': 0.147}"
lr1e-3_r64_lora_8B,vqj2i516,finished,2025-12-16T20:15:32Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-3_r64_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-3_r64_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 64, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['v_proj', 'q_proj', 'up_proj', 'down_proj', 'o_proj', 'k_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8212721728, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3154, '_step': 468, '_timestamp': 1766156582.6843576, '_wandb': {'runtime': 3154}, 'eval/accuracy': 0.8327475946304085, 'total_flos': 5161345308294119000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.024082336574792865, 'train/learning_rate': 0.001, 'train/loss': 0.7173119783401489, 'train/mean_token_accuracy': 0.8123779296875, 'train/num_tokens': 72643344, 'train_loss': 0.7999335104954575, 'train_runtime': 3146.4218, 'train_samples_per_second': 18.977, 'train_steps_per_second': 0.148}"
lr1e-4_r256_lora_8B,7b064s8t,finished,2025-12-16T20:15:35Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r256_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-4_r256_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 256, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['q_proj', 'v_proj', 'o_proj', 'up_proj', 'k_proj', 'down_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8690872384, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3279, '_step': 468, '_timestamp': 1766156533.4032674, '_wandb': {'runtime': 3279}, 'eval/accuracy': 0.8057267961053177, 'total_flos': 5482860233585852000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.01923275552690029, 'train/learning_rate': 0.0001, 'train/loss': 0.7729808688163757, 'train/mean_token_accuracy': 0.8000476658344269, 'train/num_tokens': 72643344, 'train_loss': 0.8537691045369019, 'train_runtime': 3275.8747, 'train_samples_per_second': 18.227, 'train_steps_per_second': 0.143}"
lr1e-3_r512_lora_8B,xwguk7ev,finished,2025-12-16T20:15:35Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-3_r512_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-3_r512_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 512, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['v_proj', 'o_proj', 'k_proj', 'up_proj', 'q_proj', 'down_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 9328406592, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3460, '_step': 468, '_timestamp': 1766156635.2217476, '_wandb': {'runtime': 3460}, 'eval/accuracy': 0.8132741833266117, 'total_flos': 5911546814779097000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.008982065133750439, 'train/learning_rate': 0.001, 'train/loss': 0.7159173488616943, 'train/mean_token_accuracy': 0.812481015920639, 'train/num_tokens': 72643344, 'train_loss': 0.7999461658251107, 'train_runtime': 3449.8052, 'train_samples_per_second': 17.308, 'train_steps_per_second': 0.135}"
lr1e-3_r256_lora_8B,ryaimcsy,finished,2025-12-16T20:15:37Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-3_r256_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-3_r256_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 256, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['down_proj', 'k_proj', 'q_proj', 'o_proj', 'v_proj', 'up_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8690872384, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3273, '_step': 468, '_timestamp': 1766156542.7994692, '_wandb': {'runtime': 3273}, 'eval/accuracy': 0.8127556605404159, 'total_flos': 5482860233585852000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.013708415441215038, 'train/learning_rate': 0.001, 'train/loss': 0.7149744629859924, 'train/mean_token_accuracy': 0.8129239082336426, 'train/num_tokens': 72643344, 'train_loss': 0.7984126683731406, 'train_runtime': 3266.4874, 'train_samples_per_second': 18.279, 'train_steps_per_second': 0.143}"
lr1e-4_r16_lora_70B,jem6kon0,finished,2025-12-16T20:22:13Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r16_lora_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_lora/lr1e-4_r16_lora_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 16, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['v_proj', 'o_proj', 'k_proj', 'up_proj', 'q_proj', 'down_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 14302, '_step': 468, '_timestamp': 1766156507.030457, '_wandb': {'runtime': 14302}, 'eval/accuracy': 0.8252002074091145, 'total_flos': 2661198084702208, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.08608264476060867, 'train/learning_rate': 0.0001, 'train/loss': 0.6454293131828308, 'train/mean_token_accuracy': 0.824059784412384, 'train/num_tokens': 72643344, 'train_loss': 0.7241080718581631, 'train_runtime': 14298.392, 'train_samples_per_second': 4.176, 'train_steps_per_second': 0.033}"
lr1e-5_r1_lora_70B,q5zm72qy,finished,2025-12-16T20:22:13Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r1_lora_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_lora/lr1e-5_r1_lora_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 1, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['v_proj', 'o_proj', 'k_proj', 'q_proj', 'up_proj', 'down_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 14548, '_step': 468, '_timestamp': 1766156479.8166106, '_wandb': {'runtime': 14548}, 'eval/accuracy': 0.8014057728870196, 'total_flos': 9155690096492544, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.35364803671836853, 'train/learning_rate': 1e-05, 'train/loss': 0.6770002245903015, 'train/mean_token_accuracy': 0.8163356781005859, 'train/num_tokens': 72643344, 'train_loss': 0.8032881957050054, 'train_runtime': 14544.1361, 'train_samples_per_second': 4.105, 'train_steps_per_second': 0.032}"
lr1e-3_r16_lora_70B,1dfiucva,finished,2025-12-16T20:22:14Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-3_r16_lora_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_lora/lr1e-3_r16_lora_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 16, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['o_proj', 'q_proj', 'k_proj', 'v_proj', 'up_proj', 'down_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 14296, '_step': 468, '_timestamp': 1766156475.3665524, '_wandb': {'runtime': 14296}, 'eval/accuracy': 0.8132741833266117, 'total_flos': 2661198084702208, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.06885164231061935, 'train/learning_rate': 0.001, 'train/loss': 0.6261899471282959, 'train/mean_token_accuracy': 0.8269668221473694, 'train/num_tokens': 72643344, 'train_loss': 0.7341213547953702, 'train_runtime': 14292.3913, 'train_samples_per_second': 4.178, 'train_steps_per_second': 0.033}"
lr1e-5_r64_lora_70B,84sfo06z,finished,2025-12-16T20:22:14Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r64_lora_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_lora/lr1e-5_r64_lora_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 64, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['v_proj', 'up_proj', 'down_proj', 'o_proj', 'k_proj', 'q_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 14458, '_step': 468, '_timestamp': 1766156488.561179, '_wandb': {'runtime': 14458}, 'eval/accuracy': 0.7798582704384398, 'total_flos': 7944852627521536, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.04706856235861778, 'train/learning_rate': 1e-05, 'train/loss': 0.6824322938919067, 'train/mean_token_accuracy': 0.8147206902503967, 'train/num_tokens': 72643344, 'train_loss': 0.8204316150963434, 'train_runtime': 14453.3209, 'train_samples_per_second': 4.131, 'train_steps_per_second': 0.032}"
lr1e-3_r1_lora_70B,jf8jjya7,finished,2025-12-16T20:22:14Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-3_r1_lora_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_lora/lr1e-3_r1_lora_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 1, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['down_proj', 'q_proj', 'o_proj', 'up_proj', 'k_proj', 'v_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 14452, '_step': 468, '_timestamp': 1766156497.8259804, '_wandb': {'runtime': 14452}, 'eval/accuracy': 0, 'total_flos': 9155690096492544, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 23.955236434936523, 'train/learning_rate': 0.001, 'train/loss': 9.991962432861328, 'train/mean_token_accuracy': 0.0330730564892292, 'train/num_tokens': 72643344, 'train_loss': 6.105365156999747, 'train_runtime': 14447.5579, 'train_samples_per_second': 4.133, 'train_steps_per_second': 0.032}"
lr1e-5_r16_lora_70B,52baygb1,finished,2025-12-16T20:22:15Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r16_lora_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_lora/lr1e-5_r16_lora_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 16, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['v_proj', 'q_proj', 'down_proj', 'k_proj', 'o_proj', 'up_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 14263, '_step': 468, '_timestamp': 1766156466.2310786, '_wandb': {'runtime': 14263}, 'eval/accuracy': 0.7744425880048396, 'total_flos': 2661198084702208, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.08442014455795288, 'train/learning_rate': 1e-05, 'train/loss': 0.6820636987686157, 'train/mean_token_accuracy': 0.8150858283042908, 'train/num_tokens': 72643344, 'train_loss': 0.8192252004937901, 'train_runtime': 14258.562, 'train_samples_per_second': 4.188, 'train_steps_per_second': 0.033}"
lr1e-4_r1_lora_70B,c6ypyy03,finished,2025-12-16T20:22:16Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r1_lora_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_lora/lr1e-4_r1_lora_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 1, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['up_proj', 'k_proj', 'v_proj', 'down_proj', 'o_proj', 'q_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 14582, '_step': 468, '_timestamp': 1766156461.8838096, '_wandb': {'runtime': 14582}, 'eval/accuracy': 0.8305582761998042, 'total_flos': 9155690096492544, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.2168840169906616, 'train/learning_rate': 0.0001, 'train/loss': 0.643570065498352, 'train/mean_token_accuracy': 0.8237788677215576, 'train/num_tokens': 72643344, 'train_loss': 0.7192546538928847, 'train_runtime': 14578.7039, 'train_samples_per_second': 4.096, 'train_steps_per_second': 0.032}"
lr1e-3_r64_lora_70B,9a43yigx,finished,2025-12-16T20:22:21Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-3_r64_lora_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_lora/lr1e-3_r64_lora_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 64, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['q_proj', 'down_proj', 'up_proj', 'v_proj', 'o_proj', 'k_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 14417, '_step': 468, '_timestamp': 1766156511.5325975, '_wandb': {'runtime': 14417}, 'eval/accuracy': 0.8081465691075647, 'total_flos': 7944852627521536, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.03721225261688232, 'train/learning_rate': 0.001, 'train/loss': 0.6207031011581421, 'train/mean_token_accuracy': 0.827444314956665, 'train/num_tokens': 72643344, 'train_loss': 0.7101098727873613, 'train_runtime': 14412.588, 'train_samples_per_second': 4.143, 'train_steps_per_second': 0.032}"
lr1e-4_r64_lora_70B,ur4qn8rm,finished,2025-12-16T20:22:22Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r64_lora_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_lora/lr1e-4_r64_lora_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 64, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['down_proj', 'q_proj', 'v_proj', 'o_proj', 'k_proj', 'up_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 14463, '_step': 468, '_timestamp': 1766156484.2684405, '_wandb': {'runtime': 14463}, 'eval/accuracy': 0.8261796393385954, 'total_flos': 7944852627521536, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.03437475115060806, 'train/learning_rate': 0.0001, 'train/loss': 0.6458325386047363, 'train/mean_token_accuracy': 0.8234840035438538, 'train/num_tokens': 72643344, 'train_loss': 0.7250133257606556, 'train_runtime': 14458.2257, 'train_samples_per_second': 4.13, 'train_steps_per_second': 0.032}"
lr1e-5_r512_lora_70B,smjjrk3s,finished,2025-12-16T20:22:34Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r512_lora_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_lora/lr1e-5_r512_lora_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 512, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['v_proj', 'o_proj', 'k_proj', 'up_proj', 'q_proj', 'down_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 15958, '_step': 468, '_timestamp': 1766156502.262623, '_wandb': {'runtime': 15958}, 'eval/accuracy': 0.7509938353402086, 'total_flos': 899979910578176, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.014754800125956535, 'train/learning_rate': 1e-05, 'train/loss': 0.6834889054298401, 'train/mean_token_accuracy': 0.8149032592773438, 'train/num_tokens': 72643344, 'train_loss': 0.8244673233216018, 'train_runtime': 15948.8481, 'train_samples_per_second': 3.744, 'train_steps_per_second': 0.029}"
lr1e-4_r512_lora_70B,754o2ebx,finished,2025-12-16T20:22:39Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r512_lora_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_lora/lr1e-4_r512_lora_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 512, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['k_proj', 'up_proj', 'q_proj', 'o_proj', 'down_proj', 'v_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 15958, '_step': 468, '_timestamp': 1766156493.430637, '_wandb': {'runtime': 15958}, 'eval/accuracy': 0.8241631618367229, 'total_flos': 899979910578176, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.014486526139080524, 'train/learning_rate': 0.0001, 'train/loss': 0.6462831497192383, 'train/mean_token_accuracy': 0.8232311606407166, 'train/num_tokens': 72643344, 'train_loss': 0.7259896982150108, 'train_runtime': 15944.9407, 'train_samples_per_second': 3.745, 'train_steps_per_second': 0.029}"
lr1e-3_r512_lora_70B,cq9jmo76,finished,2025-12-16T20:22:44Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-3_r512_lora_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_lora/lr1e-3_r512_lora_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 512, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['v_proj', 'up_proj', 'down_proj', 'k_proj', 'q_proj', 'o_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 15918, '_step': 468, '_timestamp': 1766156470.9963396, '_wandb': {'runtime': 15918}, 'eval/accuracy': 0.8190355476176758, 'total_flos': 899979910578176, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.009734269231557846, 'train/learning_rate': 0.001, 'train/loss': 0.6216007471084595, 'train/mean_token_accuracy': 0.8279498815536499, 'train/num_tokens': 72643344, 'train_loss': 0.7104972894492956, 'train_runtime': 15900.7672, 'train_samples_per_second': 3.755, 'train_steps_per_second': 0.029}"
lr1e-5_r16_lora_8B,ddld3p6t,finished,2025-12-16T20:34:05Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r16_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-5_r16_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 16, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['up_proj', 'down_proj', 'q_proj', 'v_proj', 'o_proj', 'k_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8093184064, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3146, '_step': 467, '_timestamp': 1765920389.6268103, '_wandb': {'runtime': 3146}, 'total_flos': 5080966588782346000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.05753306671977043, 'train/learning_rate': 1e-05, 'train/loss': 0.8236231803894043, 'train/mean_token_accuracy': 0.7906510531902313, 'train/num_tokens': 72643344, 'train_loss': 0.9977030492441558, 'train_runtime': 3145.2349, 'train_samples_per_second': 18.984, 'train_steps_per_second': 0.148}"
lr1e-4_r16_lora_8B,p78y9pma,finished,2025-12-16T20:41:37Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r16_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_lora/lr1e-4_r16_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 16, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['q_proj', 'v_proj', 'k_proj', 'down_proj', 'o_proj', 'up_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8093184064, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3162, '_step': 468, '_timestamp': 1766156621.5779293, '_wandb': {'runtime': 3162}, 'eval/accuracy': 0.8077432736071902, 'total_flos': 5080966588782346000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.0789356604218483, 'train/learning_rate': 0.0001, 'train/loss': 0.7729888558387756, 'train/mean_token_accuracy': 0.8003848791122437, 'train/num_tokens': 72643344, 'train_loss': 0.8537673919563376, 'train_runtime': 3146.9549, 'train_samples_per_second': 18.974, 'train_steps_per_second': 0.148}"
lr1e-5_r1_full_70B,w9icozko,finished,2025-12-16T22:09:12Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r1_full_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_full/lr1e-5_r1_full_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 4971, '_step': 100, '_timestamp': 1766156442.0480318, '_wandb': {'runtime': 4971}, 'eval/accuracy': 0.8497436192890476, 'train/epoch': 0.21221864951768488, 'train/global_step': 99, 'train/grad_norm': 0.5147104859352112, 'train/learning_rate': 1e-05, 'train/loss': 0.6958988904953003, 'train/mean_token_accuracy': 0.8113762736320496, 'train/num_tokens': 15385692}"
lr1e-4_r1_full_70B,cmf0153c,finished,2025-12-16T22:09:16Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r1_full_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_full/lr1e-4_r1_full_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 4995, '_step': 100, '_timestamp': 1766156414.2352843, '_wandb': {'runtime': 4995}, 'eval/accuracy': 0.808088955464654, 'train/epoch': 0.21221864951768488, 'train/global_step': 99, 'train/grad_norm': 0.3812602460384369, 'train/learning_rate': 0.0001, 'train/loss': 0.8301969766616821, 'train/mean_token_accuracy': 0.7883648574352264, 'train/num_tokens': 15385692}"
lr1e-6_r1_full_70B,03i4meth,finished,2025-12-16T22:09:20Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-6_r1_full_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_full/lr1e-6_r1_full_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-06, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 4915, '_step': 99, '_timestamp': 1766156427.7454376, '_wandb': {'runtime': 4915}, 'eval/accuracy': 0.8241631618367229, 'train/epoch': 0.21221864951768488, 'train/global_step': 99, 'train/grad_norm': 1.660097360610962, 'train/learning_rate': 1e-06, 'train/loss': 0.7198600172996521, 'train/mean_token_accuracy': 0.8060885071754456, 'train/num_tokens': 15385692}"
lr1e-6_r1_full_8B,o9ze1yp9,finished,2025-12-16T23:58:55Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-6_r1_full_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_full/lr1e-6_r1_full_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-06, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8053338176, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 6231, '_step': 468, '_timestamp': 1766156520.3476267, '_wandb': {'runtime': 6231}, 'eval/accuracy': 0.6981621247911506, 'total_flos': 5054173670646219000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 3.1715569496154785, 'train/learning_rate': 1e-06, 'train/loss': 0.7599673271179199, 'train/mean_token_accuracy': 0.8016119003295898, 'train/num_tokens': 72643344, 'train_loss': 0.9131054485125, 'train_runtime': 6224.2798, 'train_samples_per_second': 9.593, 'train_steps_per_second': 0.075}"
lr1e-5_r1_full_8B,h3cwahbu,finished,2025-12-16T23:59:03Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r1_full_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_full/lr1e-5_r1_full_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8053338176, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 6392, '_step': 468, '_timestamp': 1766156524.7058587, '_wandb': {'runtime': 6392}, 'eval/accuracy': 0.810335887538169, 'total_flos': 5054173670646219000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.4843576848506927, 'train/learning_rate': 1e-05, 'train/loss': 0.6757630705833435, 'train/mean_token_accuracy': 0.8173232674598694, 'train/num_tokens': 72643344, 'train_loss': 0.7672716745472566, 'train_runtime': 6378.0604, 'train_samples_per_second': 9.362, 'train_steps_per_second': 0.073}"
lr1e-4_r1_full_8B,444h3ylu,finished,2025-12-16T23:59:04Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r1_full_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_8B_full/lr1e-4_r1_full_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8053338176, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 6431, '_step': 468, '_timestamp': 1766156516.0169792, '_wandb': {'runtime': 6431}, 'eval/accuracy': 0.8140807743273607, 'total_flos': 5054173670646219000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.30253899097442627, 'train/learning_rate': 0.0001, 'train/loss': 0.6200482845306396, 'train/mean_token_accuracy': 0.8299908638000488, 'train/num_tokens': 72643344, 'train_loss': 0.7316433700555397, 'train_runtime': 6405.994, 'train_samples_per_second': 9.321, 'train_steps_per_second': 0.073}"
lr1e-6_r1_full_70B,1i7vlegp,finished,2025-12-17T00:00:39Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-6_r1_full_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_full/lr1e-6_r1_full_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-06, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 2, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 5218, '_step': 100, '_timestamp': 1766156430.9153073, '_wandb': {'runtime': 5218}, 'eval/accuracy': 0.8241631618367229, 'train/epoch': 0.21221864951768488, 'train/global_step': 99, 'train/grad_norm': 0.5749282836914062, 'train/learning_rate': 1e-06, 'train/loss': 0.7202146053314209, 'train/mean_token_accuracy': 0.8068222999572754, 'train/num_tokens': 15385692}"
lr1e-4_r1_full_70B,5546isrv,finished,2025-12-17T00:00:42Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r1_full_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_full/lr1e-4_r1_full_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 2, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 5426, '_step': 100, '_timestamp': 1766156417.3706603, '_wandb': {'runtime': 5426}, 'eval/accuracy': 0.808088955464654, 'train/epoch': 0.21436227224008575, 'train/global_step': 100, 'train/grad_norm': 1.326067566871643, 'train/learning_rate': 0.0001, 'train/loss': 0.8366489410400391, 'train/mean_token_accuracy': 0.7904042601585388, 'train/num_tokens': 15540223}"
lr1e-5_r1_full_70B,mckk3209,finished,2025-12-17T00:00:43Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r1_full_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_full/lr1e-5_r1_full_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 2, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 5345, '_step': 100, '_timestamp': 1766156444.98908, '_wandb': {'runtime': 5345}, 'eval/accuracy': 0.8497436192890476, 'train/epoch': 0.21436227224008575, 'train/global_step': 100, 'train/grad_norm': 0.5869594812393188, 'train/learning_rate': 1e-05, 'train/loss': 0.6740083694458008, 'train/mean_token_accuracy': 0.8188245892524719, 'train/num_tokens': 15540223}"
lr1e-5_r1_full_70B,syq2kdm1,finished,2025-12-17T11:06:05Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r1_full_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_full/lr1e-5_r1_full_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 8, 'per_device_train_batch_size': 1, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 6944, '_step': 100, '_timestamp': 1766156447.951611, '_wandb': {'runtime': 6944}, 'eval/accuracy': 0.8497436192890476, 'train/epoch': 0.21221864951768488, 'train/global_step': 99, 'train/grad_norm': 0.5010513663291931, 'train/learning_rate': 1e-05, 'train/loss': 0.6963419914245605, 'train/mean_token_accuracy': 0.8124719560146332, 'train/num_tokens': 15385692}"
lr1e-6_r1_full_70B,syfx7dme,finished,2025-12-17T11:06:22Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-6_r1_full_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_full/lr1e-6_r1_full_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-06, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 8, 'per_device_train_batch_size': 1, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 6858, '_step': 99, '_timestamp': 1766156433.9816408, '_wandb': {'runtime': 6858}, 'eval/accuracy': 0.8241631618367229, 'train/epoch': 0.21221864951768488, 'train/global_step': 99, 'train/grad_norm': 0.6795209646224976, 'train/learning_rate': 1e-06, 'train/loss': 0.7198607921600342, 'train/mean_token_accuracy': 0.8078399449586868, 'train/num_tokens': 15385692}"
lr1e-4_r1_full_70B,eyrf4qj0,finished,2025-12-17T11:07:11Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r1_full_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_full/lr1e-4_r1_full_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 8, 'per_device_train_batch_size': 1, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 6925, '_step': 100, '_timestamp': 1766156420.185959, '_wandb': {'runtime': 6925}, 'eval/accuracy': 0.808088955464654, 'train/epoch': 0.21221864951768488, 'train/global_step': 99, 'train/grad_norm': 2.677198648452759, 'train/learning_rate': 0.0001, 'train/loss': 0.9724087715148926, 'train/mean_token_accuracy': 0.7650422528386116, 'train/num_tokens': 15385692}"
golden-jazz-130,e9gvlpml,finished,2025-12-17T20:44:49Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': None, 'data_seed': None, 'deepspeed': None, 'eos_token': '<EOS_TOKEN>', 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'loss_type': 'nll', 'max_steps': -1, 'pad_token': '<PAD_TOKEN>', 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/peft_apertus/models/apertus8B_sft_tests8', 'save_steps': 500, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0.03, 'warmup_steps': 0.03, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 2e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'shuffle_dataset': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 1, 'packing_strategy': 'bfd', 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'cosine_with_min_lr', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'chat_template_path': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'pad_to_multiple_of': None, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'assistant_only_loss': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': {'min_lr_rate': 0.1}, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'completion_only_loss': None, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'activation_offloading': False, 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 8, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 106, '_step': 4, '_timestamp': 1766004385.2293882, '_wandb': {'runtime': 106}, 'total_flos': 1909451259904, 'train/entropy': 1.458984375, 'train/epoch': 1, 'train/global_step': 4, 'train/grad_norm': 3.8242506980896, 'train/learning_rate': 6.500000000000003e-06, 'train/loss': 1.3887864351272583, 'train/mean_token_accuracy': 0.6797434389591217, 'train/num_tokens': 582137, 'train_loss': 1.50411656498909, 'train_runtime': 97.5407, 'train_samples_per_second': 10.252, 'train_steps_per_second': 0.041}"
likely-terrain-131,og2mq6va,finished,2025-12-17T20:45:42Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': None, 'data_seed': None, 'deepspeed': None, 'eos_token': '<EOS_TOKEN>', 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'loss_type': 'nll', 'max_steps': -1, 'pad_token': '<PAD_TOKEN>', 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/peft_apertus/models/apertus70B_sft_lora_tests', 'save_steps': 500, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 8, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 16, 'use_bdlora': None, 'use_qalora': False, 'use_rslora': False, 'arrow_config': None, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'peft_version': '0.18.1.dev0@e70542269c4f9668dbf9607ca383333ef7723b48', 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['k_proj', 'up_proj', 'o_proj', 'v_proj', 'down_proj', 'q_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'qalora_group_size': 16, 'target_parameters': None, 'ensure_weight_tying': False, 'layers_to_transform': None, 'alora_invocation_tokens': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0.03, 'warmup_steps': 0.03, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0002, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'shuffle_dataset': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 1, 'packing_strategy': 'bfd', 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'cosine_with_min_lr', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'chat_template_path': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'pad_to_multiple_of': None, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'assistant_only_loss': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': {'min_lr_rate': 0.1}, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'completion_only_loss': None, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'activation_offloading': False, 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 558, '_step': 32, '_timestamp': 1766004881.655201, '_wandb': {'runtime': 558}, 'total_flos': 277504537919488, 'train/entropy': 1.1328125, 'train/epoch': 1, 'train/global_step': 32, 'train/grad_norm': 0.18431852757930756, 'train/learning_rate': 2.046176089472944e-05, 'train/loss': 1.053520441055298, 'train/mean_token_accuracy': 0.7093730568885803, 'train/num_tokens': 582137, 'train_loss': 1.127368062734604, 'train_runtime': 541.0862, 'train_samples_per_second': 1.848, 'train_steps_per_second': 0.059}"
unique-mountain-132,sg7jowki,finished,2025-12-17T20:48:12Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': None, 'data_seed': None, 'deepspeed': None, 'eos_token': '<EOS_TOKEN>', 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'loss_type': 'nll', 'max_steps': -1, 'pad_token': '<PAD_TOKEN>', 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/peft_apertus/models/apertus70B_sft_lora_tests', 'save_steps': 500, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 8, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 16, 'use_bdlora': None, 'use_qalora': False, 'use_rslora': False, 'arrow_config': None, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'peft_version': '0.18.1.dev0@e70542269c4f9668dbf9607ca383333ef7723b48', 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['up_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj', 'down_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'qalora_group_size': 16, 'target_parameters': None, 'ensure_weight_tying': False, 'layers_to_transform': None, 'alora_invocation_tokens': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0.03, 'warmup_steps': 0.03, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0002, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'shuffle_dataset': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 1, 'packing_strategy': 'bfd', 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'cosine_with_min_lr', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'chat_template_path': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'pad_to_multiple_of': None, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'assistant_only_loss': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': {'min_lr_rate': 0.1}, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'completion_only_loss': None, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'activation_offloading': False, 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 157, '_step': 32, '_timestamp': 1766004642.932307, '_wandb': {'runtime': 157}, 'total_flos': 57173213577216, 'train/entropy': 1.2421875, 'train/epoch': 1, 'train/global_step': 32, 'train/grad_norm': 0.1569647341966629, 'train/learning_rate': 2.046176089472944e-05, 'train/loss': 1.19433331489563, 'train/mean_token_accuracy': 0.6900472044944763, 'train/num_tokens': 582137, 'train_loss': 1.2535959295928478, 'train_runtime': 152.0514, 'train_samples_per_second': 6.577, 'train_steps_per_second': 0.21}"
Apertus-8B-Instruct_2025-12-17_23-50-52,jale1k7p,finished,2025-12-17T22:50:54Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'name': 'Apertus-8B-Instruct', 'entity': 'lsaie-peft-apertus', 'project': 'LEXam-Evaluation'}, 'devices': ['NVIDIA GH200 120GB', 'NVIDIA GH200 120GB', 'NVIDIA GH200 120GB', 'NVIDIA GH200 120GB'], 'subsets': ['mcq_4_choices'], 'model_id': 'swiss-ai/Apertus-8B-Instruct-2509', 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'match_choice_regex': '###([A-Z]+)###', 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 201, '_step': 2, '_timestamp': 1766012055.7096307, '_wandb': {'runtime': 201}, 'init_time_seconds': 67.86190581321716, 'mcq_4_choices/accuracy': 0.27069486404833837, 'mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://v2d41l52dj0ors7om73kx5bc7mntu2uzgdgpx8jjkxhpdvdtu87xyjofdj9sed8otylktterzqwjk5895m03d0gbnybwr18w6m7jmx2zwy6uxln8j4boazxvy0i8zzqp:latest/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://si6s9hazkutuf61e233w137441fh91nhuf47lx7njhe12hjmvtlrs1qei85ho5mh4o7ypzqc11c8s66g5ijls43aij2my6yc9ufc6dzj4i460bqtkjncxpiooe84jw8w/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/mcq_4_choices/classification_report_2_ffecb5afe3552b37adec.table.json', 'sha256': 'ffecb5afe3552b37adeceac3dd9458bae2c27ad025b9cd33d95f144a15004114', 'size': 576}, 'mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://5zh7e5e6o9toip7pr66q8ukwnchffn81pyhbqcs6fws6pa6magh9xe94zzsl5nj7nca7di9dpyjdpybofrsyivli9912jm7dhy6uidwvnrjo475yu8f1phf4hsj1nnyz:latest/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://3dcy0vbhgu8lzu4w2u1hmxcii5b8tsgjheikrj9kni59xl97jdnss4whr5oslxaam1jsil718qg4n19afi18ihxgte0ys1gj7gh8gjzvybyghkjs196myrzeg99dje2y/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/mcq_4_choices/confusion_matrix_table_1_df1d58a9fae7e0c15db9.table.json', 'sha256': 'df1d58a9fae7e0c15db95837455b46cfa5b654ffe6a494085d35326f0a4ba396', 'size': 538}, 'mcq_4_choices/correct': 448, 'mcq_4_choices/generation_time': 125.6133713722229, 'mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://ix7rie7psaxy8llmjkfgsew9hwanzhnu8w39aii4t6cnbmsz1xuvpptp3glp7wwotz4a8nkquynls3r7zcrnfngt61097dv37c5k7lv9pltx132essv1t5wlhgowxand:latest/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://o1cgkyoa87owf2xoetv3sbk7jqccumqr702ygsn4w7wu2vfejc71syne2tg3km02b2nt2q1zsqt905xj0598uez04cq7ec9xdn2zbyh0mf5u89umh1yxxggnsvmnetjk/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 5, 'path': 'media/table/mcq_4_choices/pred_distribution_1_e6c32e58964abe51ed51.table.json', 'sha256': 'e6c32e58964abe51ed511e0d33afea689a09c471281c61d7c67d52720f9ba84c', 'size': 102}, 'mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://q1rp73lxxn05oxegerjs6v6p3rag4b1vto5q8bepdl170ucknboj69jnnfcf0y9rjpo5l3340cecge0g5jbdu5jgy64eanq8qij4gwjeth4af8ofhgyczvciyun3g3ec:latest/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://n9vjijzkg7233evy8l61ordu2q3byuc26d92qmf0xgq8oq9t8f5y3qmf5yb3eyqpnvtnl7m0wi567rcsw71mwwb7okxitrn1pzybh4a1fjtq9s8aijy5wldygct6atwg/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/mcq_4_choices/predictions_1_662bee94d3b952ddd258.table.json', 'sha256': '662bee94d3b952ddd2582b23f097d850b1589c42002bdde346badd86b9a37e2d', 'size': 15585156}, 'mcq_4_choices/total': 1655}"
Apertus-70B-Instruct_2025-12-17_23-55-50,wyigic5v,finished,2025-12-17T22:55:52Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'name': 'Apertus-70B-Instruct', 'entity': 'lsaie-peft-apertus', 'project': 'LEXam-Evaluation'}, 'devices': ['NVIDIA GH200 120GB', 'NVIDIA GH200 120GB', 'NVIDIA GH200 120GB', 'NVIDIA GH200 120GB'], 'subsets': ['mcq_4_choices'], 'model_id': 'swiss-ai/Apertus-70B-Instruct-2509', 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'match_choice_regex': '###([A-Z]+)###', 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 1648, '_step': 2, '_timestamp': 1766013801.20109, '_wandb': {'runtime': 1648}, 'init_time_seconds': 169.20671105384827, 'mcq_4_choices/accuracy': 0.33051359516616313, 'mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://qlbixbyff34zmvn1fw6xau6lcgwei1m0a34442evmwmhq01mqdmvi721pfaz267akisgj4gz2pr9hbe3u57c6ersxwi5vrgwle12ki0bhyrg0eucm06no9rhoohc082j:latest/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://3390ob65r26ycclkd19t2bby8ro5eoyny9sy6pr9nbhe4uo5ppy02yi88uqzumt0k6edt6lly21cinumiiv8u7q183uduh41zzmj00u780zo7ejk9o1i3dexxmdnnaqq/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/mcq_4_choices/classification_report_2_30a24e83237361837202.table.json', 'sha256': '30a24e83237361837202bc39da77e2f4e2c58f7e2f887edee4a2b7d12f6c34d3', 'size': 563}, 'mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://lxx9immjxie2f98dj47dt86wtrkkxeekgpnazuscnfxmq90n8clhe9km75uf3qhd17zgwmkou0ijuqcey2h4lhnnogx751vbsszwambcw8et2biczb3bd1w3pv1xl5g9:latest/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://zfxhosidhi2tgc55wb4ix2qi0t1h10a08kd1rt4u8p5bln41ey6gmd7b3qv5m39vpk4njjcv35s26cek649dwhp69g78wdi9abxrnttp6tjtyufbkqv2w3vy9swqz93y/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/mcq_4_choices/confusion_matrix_table_1_805f58a77c819e2346cb.table.json', 'sha256': '805f58a77c819e2346cbb18f8ca912ed685c1ce51c5cdf738f0c9fa197994f0d', 'size': 541}, 'mcq_4_choices/correct': 547, 'mcq_4_choices/generation_time': 1471.6348178386688, 'mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://0jts1iqkq9q7g9zoebw7lowr14hqiqilwef5m90ixkpihxtjz3zx2a59qrrf441wx4br4qmd2s6jgt2k6onq7sjk33nufi9baogry4js0zkj72fx5fi0d3io92gs3qey:latest/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://7lr8l27awfxmkeing4zfqc9zcwt8hipz1girsf84zc0rq2ge68g4lilsodduihatw7wrxnctod7mt4mgvep4awfagg9wg2qih8zlr8kqwyuorfgtk2lsi3lxoqxb4lji/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 5, 'path': 'media/table/mcq_4_choices/pred_distribution_1_c043f1c0614702be6e5d.table.json', 'sha256': 'c043f1c0614702be6e5d009ecf73f65ae036a6ba81347beca67534be792cbf0f', 'size': 102}, 'mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://edsfwga08vgfn1slwxz0mu26vh6jidjw4tmsea2d5frnuyajssvtaadzq4nboq2tmwz4adzvuigsrzeamc51gwovgcz42gd0r8enu7h1v2zutludsimobdd3252tpsdw:latest/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://2uf6holeagrnvdec1xivr5om9i65taad1lf4ow3bwol8erqvjfq5lxz6uismp0mzcdg7i12enyt9uxpy6v0spcqeiepgu07tghiev6b7d17dr8mo3al25ju5zq21y7hy/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/mcq_4_choices/predictions_1_c087c1243bba6fed1438.table.json', 'sha256': 'c087c1243bba6fed14389312480c617eb148c801ddf6f4d8dffbb0c334cedacf', 'size': 29321833}, 'mcq_4_choices/total': 1655}"
lr1e-5_r1_full_70B,wc2arfqk,finished,2025-12-18T09:50:42Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r1_full_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_full/lr1e-5_r1_full_70B', 'save_steps': 5, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 211, '_step': 4, '_timestamp': 1766156451.17618, '_wandb': {'runtime': 211}, 'eval/accuracy': 0.8497436192890476, 'train/epoch': 0.00857449088960343, 'train/global_step': 4, 'train/grad_norm': 7.451578140258789, 'train/learning_rate': 1e-05, 'train/loss': 1.0819237232208252, 'train/mean_token_accuracy': 0.7419025599956512, 'train/num_tokens': 592263}"
lr1e-5_r1_full_70B,n0hnn9s8,finished,2025-12-18T10:15:37Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r1_full_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_full/lr1e-5_r1_full_70B', 'save_steps': 2, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 1655, '_step': 17, '_timestamp': 1766156454.2649431, '_wandb': {'runtime': 1655}, 'eval/accuracy': 0.8497436192890476, 'train/epoch': 0.03644158628081458, 'train/global_step': 17, 'train/grad_norm': 1.7054967880249023, 'train/learning_rate': 1e-05, 'train/loss': 0.7172255516052246, 'train/mean_token_accuracy': 0.8098869025707245, 'train/num_tokens': 2591858}"
lr1e-3_r128_lora_8B_checkpoint-100_2025-12-18_11-18-30,ldqhfusu,finished,2025-12-18T10:18:31Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'entity': 'lsaie-peft-apertus', 'project': 'LEXam-LoRA-Checkpoints'}, 'subsets': ['mcq_4_choices'], 'model_id': 'swiss-ai/Apertus-8B-Instruct-2509', 'run_info': 'lr1e-3_r128_lora_8B/checkpoint-100', 'lora_path': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/results/grid_8B_lora/lr1e-3_r128_lora_8B/checkpoint-100', 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'checkpoint_name': 'checkpoint-100', 'match_choice_regex': '###([A-Z]+)###', 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 278, '_step': 2, '_timestamp': 1766053390.978788, '_wandb': {'runtime': 278}, 'init_time_seconds': 96.13125920295715, 'mcq_4_choices/accuracy': 0.0006042296072507553, 'mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://f01los6o48fco8xf72r7nfiueh42idj5hy8qtm2gl5zdnw1oehywywxgvngvknwgivq49pdyq91txwd8vy7cs6s35zlwynr9la744n7ds42ogkg8swz7jzagk69d57z9:latest/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://fvm3mk51wlhmmpnzofnqiwvlc2osa10i6gsgvs9qh2ekko5jca4b4bfscxz1k1qwqt23jmsrm1f5nws34ecglmyl3vpcjthm8v1d3ixhlypjfb6bxoeho9duamkaeilp/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/mcq_4_choices/classification_report_2_4eea353cf608302035fd.table.json', 'sha256': '4eea353cf608302035fd1149d36c97c51a61b420b86cf56ba134b050a2e4f47e', 'size': 419}, 'mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://0cgwx440or2t3vun0j4u624jfxpca6g3qqq9m4d87db654itt99jr7j42kptl9hoymbia82j8lnp74x380kag59al6245kl67nx1yg5p9jj5jgjihy55clur25m3z06w:latest/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://wjnzbf3nwisjma3ae1dd3thdjoz9mdcitiv2u7fb92ja61bqc045uqu2hyjlqsqhcir9ceanpvz4zn2mbgowe2i3z40e3mrsrtmdaeer759bx96iwas9g94hfl8ardbp/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/mcq_4_choices/confusion_matrix_table_1_063be7f826e0c5a3fa44.table.json', 'sha256': '063be7f826e0c5a3fa44a122871e6d07fb9d6999922053cbbe5e8e231b4441fd', 'size': 525}, 'mcq_4_choices/correct': 1, 'mcq_4_choices/generation_time': 177.6916527748108, 'mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://u81jgotzdejco1r15vsrl4fsb3qswhx43rnmebf4ykc0jmk23xglx87itzsy9yigtzydmuk18xd7rwwktj1u2xnpppogr2nmhwpzeyi4zb3a1f6ijuwfoxeh115u7ie3:latest/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://djyuao0pldfnen4dftj3kw13crun239fnxxb4qaxmoaeef0xuk0c2iu6qt0opofmrjiq7eg5frc4j9yvaf7zxxu9ffbzlpnaddn0nzyqy9jkss5dyfnxzefonz23zjob/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 4, 'path': 'media/table/mcq_4_choices/pred_distribution_1_c70f4cd80fdd23213841.table.json', 'sha256': 'c70f4cd80fdd23213841bd558ccb468e8ecbe285810b7e7d30c1d154a2096769', 'size': 87}, 'mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://ufy3okqdktku85u5jtihkr5ionzva43fn0y4fexsqzo0a7vv13z1ww0s7fcweuqhafolcn9yvczy41ixkvhqk5hcv80n8femgnf3dz42v6jdov2dr1b9t7gco32j73td:latest/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://vc52qct4yvek5iurm199e478gkke5q78qivepzp81oqdtwajykzi98f9mtbolev0sxn68fs0jfq75wnvlay0cnp0tr0ldwluxlsf8b0aelhd3o60f97kks9v9048fk46/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/mcq_4_choices/predictions_1_2d44018608d913132679.table.json', 'sha256': '2d44018608d91313267997038499a5c611db91e142499f0a2417bfd856472090', 'size': 11902618}, 'mcq_4_choices/total': 1655}"
grid_8B_lora_lr1e-4_r512_lora_8B_2025-12-18_11-27-37,ibrsdzua,finished,2025-12-18T10:27:38Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'entity': 'lsaie-peft-apertus', 'project': 'LEXam-LoRA-Checkpoints'}, 'subsets': ['mcq_4_choices'], 'model_id': 'swiss-ai/Apertus-8B-Instruct-2509', 'run_info': 'lr1e-4_r512_lora_8B', 'lora_path': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/results/grid_8B_lora/lr1e-4_r512_lora_8B', 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'checkpoint_name': 'lr1e-4_r512_lora_8B', 'match_choice_regex': '###([A-Z]+)###', 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 785, '_step': 2, '_timestamp': 1766054444.1497126, '_wandb': {'runtime': 785}, 'init_time_seconds': 73.4450900554657, 'mcq_4_choices/accuracy': 0.15226586102719034, 'mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://osudzoij4ggj2zyqdxy3jkh4ur326ixf2zdpgh76k7w5q6xikozxwddd7tilutt9bt2qrmcvor9zv7r469i8s3gbq8txkeotx02h8ydqqu3wmc3mo6de6o70t8akojuk:latest/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ztuygnwygnk4uwbs63ashu0752bhpxadz0glzm56ybc5mm6bx99ousg3xhmov2xwp2noj7jlg1o88bcm6rkobd7uim6ysa3tl4846lyzmvmngbasictpmzxnehnnczy4/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 9, 'path': 'media/table/mcq_4_choices/classification_report_2_f2630f10d5d91f7e5c48.table.json', 'sha256': 'f2630f10d5d91f7e5c481b12069995e2b5a3508e70f362cfb80661e67f162889', 'size': 611}, 'mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://ke65sguofqb3m428ijrhmhc348kiaq194ffkv839pxzhm8dnabugroecs39v1asyjkt516mfwuivjp329iualtkiwne2rvld0gb5dvjqtf6bfa3fstl1d1wfc1gn7jtk:latest/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://9z0y4ow6fy6khvt65ddwof2m5xkymeqqyebzkswbv1opup6werxogsxiwqmner2z5ffqfyez6cvgbjzudz6yys8okj8tn3br0j3gqolk3tmi0k5dxxk3i6e0mzj74wva/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 49, 'path': 'media/table/mcq_4_choices/confusion_matrix_table_1_34d27dee404a3e65f94e.table.json', 'sha256': '34d27dee404a3e65f94e8622a44fb87f81e6310fc4872753cd6c326da871922e', 'size': 957}, 'mcq_4_choices/correct': 252, 'mcq_4_choices/generation_time': 707.214840888977, 'mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://zv4yjpixzf3cnh2mxp7xqiss6gel2vl41obzd7t973ym7gb2ob3trde3vudnqre6ho57s4hcyu1trdr0dq7855dj1r68ztekhr62pw9zmhsnym6cphzkixy1ilanyf31:latest/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://j3lgze4euny25b4indeqej3oqi4q2uf10q99t62qyhvrpbltl67p1k5osyd7mqtj8630pnwdhxxc7mscow2t1mmz4lx9q7zpp4wj4g30si52b0brk3y8002oqx5rrz76/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 7, 'path': 'media/table/mcq_4_choices/pred_distribution_1_dbb6b070c4623f9c44f9.table.json', 'sha256': 'dbb6b070c4623f9c44f94d4edff5b089d281da6706b06bce1ffea7ce1d487732', 'size': 123}, 'mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://9imi5e4x98svrz0qao77a89wrahhulppodzuyy0skuxgqirl25p7tsq66qqwolh1rd9jv0e7ka28mrsxgwdjlhhf9e5g2z6sayq8zmuy7n0ef2uj0cspmf09r0fn0bwy:latest/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://dmiq1h4ykiaauanwyzb3pths1ohr6483atjz6h9v3eie3fw7b0xohtfy94szvwptyln7y97m810wmjigs6tmus3klru9zh5h0ldzsypykmtnz16pwzn6k9oy4pxh35t2/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/mcq_4_choices/predictions_1_ce406c603cc2fd09dad2.table.json', 'sha256': 'ce406c603cc2fd09dad2fed85b7f0c7bdae0de754dd414af9b5e657b7f4417d3', 'size': 32942411}, 'mcq_4_choices/total': 1655}"
lr1e-4_r1_lora_8B_checkpoint-467_2025-12-18_11-46-31,wwnjfyqx,finished,2025-12-18T10:46:33Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'entity': 'lsaie-peft-apertus', 'project': 'LEXam-LoRA-Checkpoints'}, 'subsets': ['mcq_4_choices'], 'model_id': 'swiss-ai/Apertus-8B-Instruct-2509', 'run_info': 'lr1e-4_r1_lora_8B/checkpoint-467', 'lora_path': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/results/grid_8B_lora/lr1e-4_r1_lora_8B/checkpoint-467', 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'checkpoint_name': 'checkpoint-467', 'match_choice_regex': '###([A-Z]+)###', 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 775, '_step': 2, '_timestamp': 1766055568.6706274, '_wandb': {'runtime': 775}, 'init_time_seconds': 72.09793424606323, 'mcq_4_choices/accuracy': 0.16555891238670695, 'mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://43fgk121ewz9ocvq5dpl6sig35l0fqp7iez6zw5zptwejc4fsu3404gjm17qx2o8em7a1kf6wn1iueetm2jzb5kkovloct32k73qpffiib5871bvu2umrzqp8nvsp0rm:latest/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://kyebrm84iudtw5t6lazs0dvvnftiotjy2je9un9kuqwylhub2y9jv4avowita6wmfq3hnzarqaodemzlzrueugv9k0eqq6aaq4ntg7ut7lkg9lxqpk0e4z4ajwq7nez3/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 8, 'path': 'media/table/mcq_4_choices/classification_report_2_24bf9b75cb641b229092.table.json', 'sha256': '24bf9b75cb641b2290920e85e2718a1e0be46401bd37fe352419c9eec61884b8', 'size': 605}, 'mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://1edo9fnlt6djvh4h6x033bp6wfkwhlaqc4smliw61wbmxzqh3gp5brpthejwo17u5ow98j6qi8e485jao9w323ecug9a77j1s6kttxibf599rfhwko2v7h30rbpmdixs:latest/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://2vm78utgbzzrcc4kiy38pjwpcaivlbcw70pkqg8m1j4ef23wvy1j6t5jl5eox60idr30hrt9842pd1sohpcc29yv0oswrtbk999xuu1de4dgoxyga1ze7c1sa0tmaady/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 36, 'path': 'media/table/mcq_4_choices/confusion_matrix_table_1_0d11492ff6f476bc9e58.table.json', 'sha256': '0d11492ff6f476bc9e5894c82bcf87cf4c74b9b31c008e4c24a5e4cffff38242', 'size': 732}, 'mcq_4_choices/correct': 274, 'mcq_4_choices/generation_time': 698.4824502468109, 'mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://d94rk86et330q9fbfza8b52o2h6mn8wt0m8hkuv991yx261c2i9lrdlevp4vw5fc6w4bd5o2agf0meehxs2muswosuuf28naf299x778q353h34wqa10eriinhgg35vi:latest/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://qpo8bv0eh5zfute8inssb2bow7svmynq9n6pe35jh3tdsg72wesocusdtuiwzsjy9e1vn8qrq4ibtn9azeabd16uzt7n6u5w50oatdw0c4hk6gmbhb4gdyij31g4okwa/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 6, 'path': 'media/table/mcq_4_choices/pred_distribution_1_72899c093a33df1932bc.table.json', 'sha256': '72899c093a33df1932bc00993a7abc6fc3015e351452e4907cac92a7e7c9e417', 'size': 113}, 'mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://4xpfsyr62gx4yxet12yrjleckrwjt5bfiidnsnqeen9ncftxw8ijmbc3vhm2ao92fih04493osywk38a16nt9o01b0qods2vk56ojuj4kp24stf6ocoxqrpdj9er67rc:latest/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://popopquscm6hpe8u1zk8x4the96htk54lm1mxeew5a5wcudbsjgj54l480d28vrrfus12em0jpwis8s9jy9aeyhixx9g1vczb7on6e6n1pg2cjd52uhibv06rxn695w2/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/mcq_4_choices/predictions_1_448dcac41c2af611a934.table.json', 'sha256': '448dcac41c2af611a9344fa02f35f05e32010e33677738137f8cb01ac54af994', 'size': 32836391}, 'mcq_4_choices/total': 1655}"
lr1e-6_r1_full_70B,mpw9ftax,finished,2025-12-18T10:50:22Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-6_r1_full_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_full/lr1e-6_r1_full_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-06, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 24002, '_step': 468, '_timestamp': 1766156437.1101353, '_wandb': {'runtime': 24002}, 'eval/accuracy': 0.8241631618367229, 'total_flos': 899979910578176, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.5545912384986877, 'train/learning_rate': 1e-06, 'train/loss': 0.6480538845062256, 'train/mean_token_accuracy': 0.8227818012237549, 'train/num_tokens': 72643344, 'train_loss': 0.7422427797981197, 'train_runtime': 23959.0199, 'train_samples_per_second': 2.492, 'train_steps_per_second': 0.019}"
lr1e-4_r1_full_70B,0brclhjf,finished,2025-12-18T10:50:23Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r1_full_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_full/lr1e-4_r1_full_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 24054, '_step': 468, '_timestamp': 1766156423.209695, '_wandb': {'runtime': 24054}, 'eval/accuracy': 0.808088955464654, 'total_flos': 899979910578176, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.25725480914115906, 'train/learning_rate': 0.0001, 'train/loss': 0.5912473201751709, 'train/mean_token_accuracy': 0.8383843898773193, 'train/num_tokens': 72643344, 'train_loss': 1.0895059016838318, 'train_runtime': 24014.0841, 'train_samples_per_second': 2.486, 'train_steps_per_second': 0.019}"
lr1e-5_r1_full_70B,l25goijn,finished,2025-12-18T12:18:56Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-5_r1_full_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/dmelikidze/LSAIE/project/peft_apertus/results/grid_70B_full/lr1e-5_r1_full_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 1e-05, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 25920, '_step': 468, '_timestamp': 1766156457.359592, '_wandb': {'runtime': 25920}, 'eval/accuracy': 0.8497436192890476, 'total_flos': 899979910578176, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.37919148802757263, 'train/learning_rate': 1e-05, 'train/loss': 0.5821512341499329, 'train/mean_token_accuracy': 0.8388899564743042, 'train/num_tokens': 72643344, 'train_loss': 0.6817826181969244, 'train_runtime': 25882.2131, 'train_samples_per_second': 2.307, 'train_steps_per_second': 0.018}"
lr1e-4_r4_lora_8B_checkpoint-467_2025-12-18_13-35-47,sfgdtw3w,finished,2025-12-18T12:35:48Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'entity': 'lsaie-peft-apertus', 'project': 'LEXam-LoRA-Checkpoints'}, 'subsets': ['mcq_4_choices'], 'model_id': 'swiss-ai/Apertus-8B-Instruct-2509', 'run_info': 'lr1e-4_r4_lora_8B/checkpoint-467', 'lora_path': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/results/grid_8B_lora/lr1e-4_r4_lora_8B/checkpoint-467', 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'checkpoint_name': 'checkpoint-467', 'match_choice_regex': '###([A-Z]+)###', 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 795, '_step': 2, '_timestamp': 1766062144.2069964, '_wandb': {'runtime': 795}, 'init_time_seconds': 73.39299702644348, 'mcq_4_choices/accuracy': 0.0972809667673716, 'mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://vd0r22cm5phclplr94ruvdixct7t20iw3phll8gb01ozca3svjty45qjrikw0ldvj0y9zf3eb1cayx1ge86uegaur1oqhqo49xtuce6f1o1pohsl29yynzsxewz0atxg:latest/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ex2vd63mie9ae92mur7x2s0kcyji7pmj5olatouwi7r44hv2cb7o3n0q7jok55wiry05yx6xhawe7puvg3jdma1rocxmnee87eunzsc8bq6hjlri48uki7sm4jqc1jp0/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 8, 'path': 'media/table/mcq_4_choices/classification_report_2_b34a3054b3d881d01865.table.json', 'sha256': 'b34a3054b3d881d0186572bf1bfdae20fab7e7ef435af8005539011ea464039d', 'size': 607}, 'mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://ojz64l1bzfdaf9f9jy16daa4xxfffq8bmqrmc07p6mtarhgkzhbo3a407x2umw4j330kb7yyiag6b87g8wx48kyjyiv4x8787pjlytxke10q1j179oqt6tdj30c213px:latest/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://50kn3xk3xkota5gn9qwnf6113wq9hskvcizzfmu6fqy1lekjo23gky9ruwgya2n177jf7md31961yib78elr55quaizfk7ljhvuc0ow1yqyby8m2vwiofv8ffhl5k74g/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 36, 'path': 'media/table/mcq_4_choices/confusion_matrix_table_1_ffa2e27af4b048741e22.table.json', 'sha256': 'ffa2e27af4b048741e22c7401f98717bf20c1f4242709a4c0294324d649808b3', 'size': 730}, 'mcq_4_choices/correct': 161, 'mcq_4_choices/generation_time': 717.7816755771637, 'mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://g2wyw0eg2zk9kbwt6fyou31r64yseuuuaj7u9e3zxs4l4b6u3pgn1gnt7pnyrmck77lzit932h1s69r91i6bl9rz4bsdxu2nuvjgtsqypm2by4udnfwnpen75ze04pst:latest/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://143s7u6fi2kd4vz0o0tnzqokx1rghzzjtzgbik066ce1p06rxynm5mx28o2bb80kpwwi3jlxwwyepno2hlncdv0u0fd862aihsxiu6f3augj69vmyr5oqlkxh6qz2xjh/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 6, 'path': 'media/table/mcq_4_choices/pred_distribution_1_3c408a7f23fd2481fc7f.table.json', 'sha256': '3c408a7f23fd2481fc7f8e1ff45f837ca673ee9e42c632ec029425ff1f478131', 'size': 114}, 'mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://mtw4y8rjpa7t120jan4q2gk9hdntihzdy6gl4h2hqsf05x9007jvgd2h6j950vukogly0z9mlctd3xrlnhqj7e7oysvstvyezrvaspz8vrixulsqj4etmti42o2znj2d:latest/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://4jdc6gov5g6wmpo3vxqnabl49xqoixkilgdq0kf2s9fy3qhwn3sftmrcvfiomzvgsi8rdrpgwrkai8eeze7bje06su5q1r197ad3l1z2f1jvq5ebt4b1z0my4cek96xn/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/mcq_4_choices/predictions_1_c360ab0cc3d2b1fb643d.table.json', 'sha256': 'c360ab0cc3d2b1fb643da64492fb119f06109f359b31f834645c13bfca1b7422', 'size': 32668053}, 'mcq_4_choices/total': 1655}"
lr1e-5_r64_lora_70B_checkpoint-467_2025-12-18_14-20-29,2prk25n4,finished,2025-12-18T13:20:31Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'entity': 'lsaie-peft-apertus', 'project': 'LEXam-LoRA-Checkpoints'}, 'subsets': ['mcq_4_choices'], 'model_id': 'swiss-ai/Apertus-70B-Instruct-2509', 'run_info': 'lr1e-5_r64_lora_70B/checkpoint-467', 'lora_path': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/results/grid_70B_lora/lr1e-5_r64_lora_70B/checkpoint-467', 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'checkpoint_name': 'checkpoint-467', 'match_choice_regex': '###([A-Z]+)###', 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 1959, '_step': 2, '_timestamp': 1766065991.289724, '_wandb': {'runtime': 1959}, 'init_time_seconds': 194.51568126678467, 'mcq_4_choices/accuracy': 0.2984894259818731, 'mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://n4zlfe0mplmqkbmwpx1hcr5hf2l8nv2f7omngkmawaqm1mbd46iv877qt8klu9xzc7ptjntgk1cnitm429y7gdabpf9ihwpkmzcb3wnwzns09j2vf59y8o51pyl3dnuy:latest/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://qtrgtit7d8vlul5liocqebd06rmh8kbnfqd00s17kmzsez9zcg8yxvk4uaoag1kqo5f5v8ji4zhxav6czaga39aeanq7v3hi6zicju60plmi38c1aw5718hpyq5j3bjz/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 8, 'path': 'media/table/mcq_4_choices/classification_report_2_f7074c315b882a75076b.table.json', 'sha256': 'f7074c315b882a75076bbee81239cd52938acd04fb8810dc89d7e8103a376db8', 'size': 582}, 'mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://nmg8gh8kcr3iqc29ud8dza2h2s8tsfh85mqyvty4xehvf9clwpn02damu4nqb1kx22u38o1mzdn7qum3798m2656gueulnpg2wqsh6mxv29fndm72ja1tvlagk9or60t:latest/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://u6ekjxg5yj7gw4jj9a5rhbbh1gztu8pgi8h5lpvrq96ci2x13jd7mjpt1blow8enxe5e796ey6r57qbjppba3u1p0qgph77shgjymuyagrybsx4b3vi9ihq065tp2gix/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 36, 'path': 'media/table/mcq_4_choices/confusion_matrix_table_1_b8259d0fbdb8f7b6090e.table.json', 'sha256': 'b8259d0fbdb8f7b6090e8f2cd6f47d8c073b32a7957aabc40785c7cdb2d55019', 'size': 695}, 'mcq_4_choices/correct': 494, 'mcq_4_choices/generation_time': 1756.5552628040314, 'mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://qgvspd5l7nj2oqdet1hp2oc4n2tdda4wnhen6ni3g0o3ifda3j1mamsuzokrxd04ei404vwpp4sx7rw8qvrp6m4dvyws2s896yp2eghp0vs8ya0rrelf5j0hke65aumf:latest/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://90gdnai6b8pzapb1s5lvpbndnlj8r97hkkru5bqaan2ml9jyj0krvrtc6zk3z09m6xlmmz3zl8nbbaariaq7l6jm1ficrl962d1zor787uzndeoxntg6ek6isfkzibnp/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 6, 'path': 'media/table/mcq_4_choices/pred_distribution_1_301efdf246b77bca9154.table.json', 'sha256': '301efdf246b77bca91544f13b318eb0a1740e96ca6b8763a2599188dc72a2ed3', 'size': 108}, 'mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://dfcv50dlf6wwz1c6tkfnahq9w5snyz7ws0g79ww8f2q45rpj738jcmbzcup76v4gbtmjnikhq4xqs6ezxqcpm86i7evh65h83fv2y4g6qmth8frft2htfbtgdsfuplqx:latest/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://p8a8wjlum8043dnwefetz0gjzpho0d9gt79t2uxica1ldgqi1b36g0rg2hxp44sozmez1on6y46trwo2rdfqx9erjygyylu6ruy5tbnxyoatmaqwhj8dfnhdowprxjvz/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/mcq_4_choices/predictions_1_bf06fa95bc91353f98f2.table.json', 'sha256': 'bf06fa95bc91353f98f2fb6326f25df72c583f440fe2f1ba7e9b39ea61c4072c', 'size': 16543906}, 'mcq_4_choices/total': 1655}"
COMPARISON_CONTAINERS_PERFORMANCE,6gt8g0tg,finished,2025-12-18T14:30:55Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': None, 'data_seed': None, 'deepspeed': None, 'eos_token': '<EOS_TOKEN>', 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'loss_type': 'nll', 'max_steps': -1, 'pad_token': '<PAD_TOKEN>', 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/peft_apertus/models/apertus70B_sft_lora_tests', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 8, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_bdlora': None, 'use_qalora': False, 'use_rslora': False, 'arrow_config': None, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'peft_version': '0.18.1.dev0@e70542269c4f9668dbf9607ca383333ef7723b48', 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['k_proj', 'down_proj', 'v_proj', 'o_proj', 'up_proj', 'q_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'qalora_group_size': 16, 'target_parameters': None, 'ensure_weight_tying': False, 'layers_to_transform': None, 'alora_invocation_tokens': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0002, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'shuffle_dataset': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 1, 'packing_strategy': 'bfd', 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'chat_template_path': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'pad_to_multiple_of': None, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'assistant_only_loss': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'completion_only_loss': None, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'activation_offloading': False, 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 4726, '_step': 467, '_timestamp': 1766072980.1376145, '_wandb': {'runtime': 4726}, 'total_flos': 6171647038980096, 'train/entropy': 0.751953125, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.03323523700237274, 'train/learning_rate': 0.0002, 'train/loss': 0.7591160535812378, 'train/mean_token_accuracy': 0.8031163513660431, 'train/num_tokens': 72584018, 'train_loss': 0.8323929418333083, 'train_runtime': 4726.3899, 'train_samples_per_second': 12.633, 'train_steps_per_second': 0.099}"
lr1e-4_r64_nnodes4_lora_8B,okuxwb6e,finished,2025-12-18T15:46:21Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r64_nnodes4_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/peft_apertus/results/grid_8B_lora_time/lr1e-4_r64_nnodes4_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 64, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['v_proj', 'down_proj', 'o_proj', 'up_proj', 'q_proj', 'k_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8212721728, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 1832, '_step': 467, '_timestamp': 1766074608.3716314, '_wandb': {'runtime': 1832}, 'total_flos': 5161345309367861000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.048761650919914246, 'train/learning_rate': 0.0001, 'train/loss': 0.7722458243370056, 'train/mean_token_accuracy': 0.800283670425415, 'train/num_tokens': 72643344, 'train_loss': 0.8531842194736897, 'train_runtime': 1828.5195, 'train_samples_per_second': 32.654, 'train_steps_per_second': 0.255}"
lr1e-4_r64_nnodes1_lora_8B,dqskuxki,finished,2025-12-18T15:49:38Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r64_nnodes1_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/peft_apertus/results/grid_8B_lora_time/lr1e-4_r64_nnodes1_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 64, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['o_proj', 'up_proj', 'v_proj', 'q_proj', 'k_proj', 'down_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8212721728, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 8, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 5522, '_step': 467, '_timestamp': 1766078483.1662724, '_wandb': {'runtime': 5522}, 'total_flos': 5161345319031538000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.03797209262847901, 'train/learning_rate': 0.0001, 'train/loss': 0.772687554359436, 'train/mean_token_accuracy': 0.800133615732193, 'train/num_tokens': 72643344, 'train_loss': 0.8535769806428946, 'train_runtime': 5506.015, 'train_samples_per_second': 10.844, 'train_steps_per_second': 0.085}"
lr1e-4_r64_nnodes8_lora_8B,rn9enbcy,finished,2025-12-18T15:49:42Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r64_nnodes8_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/peft_apertus/results/grid_8B_lora_time/lr1e-4_r64_nnodes8_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 64, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['down_proj', 'up_proj', 'o_proj', 'v_proj', 'k_proj', 'q_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8212721728, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 1143, '_step': 467, '_timestamp': 1766074112.7395573, '_wandb': {'runtime': 1143}, 'total_flos': 5165632118373482000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.06307372450828552, 'train/learning_rate': 0.0001, 'train/loss': 0.7303398251533508, 'train/mean_token_accuracy': 0.8116715550422668, 'train/num_tokens': 72708772, 'train_loss': 0.8533205814994632, 'train_runtime': 1131.4902, 'train_samples_per_second': 52.77, 'train_steps_per_second': 0.413}"
lr1e-4_r64_nnodes2_zero2_lora_8B,wfu1vlem,finished,2025-12-18T15:49:58Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r64_nnodes2_zero2_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/peft_apertus/results/grid_8B_lora_time/lr1e-4_r64_nnodes2_zero2_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 64, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['down_proj', 'v_proj', 'k_proj', 'o_proj', 'up_proj', 'q_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 8212721728, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 3388, '_step': 467, '_timestamp': 1766076383.106639, '_wandb': {'runtime': 3388}, 'total_flos': 5161345308294119000, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.03883812204003334, 'train/learning_rate': 0.0001, 'train/loss': 0.7724992036819458, 'train/mean_token_accuracy': 0.7999628186225891, 'train/num_tokens': 72643344, 'train_loss': 0.8535066395040753, 'train_runtime': 3386.0689, 'train_samples_per_second': 17.634, 'train_steps_per_second': 0.138}"
lr1e-4_r64_nnodes2_zero3_lora_8B,3o1n5auf,finished,2025-12-18T15:50:36Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r64_nnodes2_zero3_lora_8B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/peft_apertus/results/grid_8B_lora_time/lr1e-4_r64_nnodes2_zero3_lora_8B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 4096, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 64, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['o_proj', 'k_proj', 'v_proj', 'down_proj', 'up_proj', 'q_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-8B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 21504, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 32, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 32, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 4028, '_step': 467, '_timestamp': 1766077063.2982843, '_wandb': {'runtime': 4028}, 'total_flos': 3003483728379904, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.03909716755151749, 'train/learning_rate': 0.0001, 'train/loss': 0.772135853767395, 'train/mean_token_accuracy': 0.8000631332397461, 'train/num_tokens': 72643344, 'train_loss': 0.8532671519979931, 'train_runtime': 4027.3611, 'train_samples_per_second': 14.826, 'train_steps_per_second': 0.116}"
lr1e-4_r64_nnodes1_lora_70B,pcjej9oe,crashed,2025-12-18T15:51:48Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r64_nnodes1_lora_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/peft_apertus/results/grid_70B_lora_time/lr1e-4_r64_nnodes1_lora_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 64, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['k_proj', 'q_proj', 'v_proj', 'up_proj', 'o_proj', 'down_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 8, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 42936.712300015, '_step': 450, '_timestamp': 1766116045.758458, '_wandb': {'runtime': 42936}, 'train/epoch': 0.9667738478027867, 'train/global_step': 451, 'train/grad_norm': 0.045697957277297974, 'train/learning_rate': 0.0001, 'train/loss': 0.6616718173027039, 'train/mean_token_accuracy': 0.8203681483864784, 'train/num_tokens': 70220457}"
lr1e-4_r64_nnodes2_lora_70B,pfju9wj6,finished,2025-12-18T15:51:50Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r64_nnodes2_lora_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/peft_apertus/results/grid_70B_lora_time/lr1e-4_r64_nnodes2_lora_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 64, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['k_proj', 'up_proj', 'q_proj', 'down_proj', 'o_proj', 'v_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 25729, '_step': 467, '_timestamp': 1766098833.0459254, '_wandb': {'runtime': 25729}, 'total_flos': 7947800824774656, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.03684446960687637, 'train/learning_rate': 0.0001, 'train/loss': 0.6458077430725098, 'train/mean_token_accuracy': 0.823788583278656, 'train/num_tokens': 72643344, 'train_loss': 0.7254791954089539, 'train_runtime': 25723.7388, 'train_samples_per_second': 2.321, 'train_steps_per_second': 0.018}"
lr1e-4_r64_nnodes8_lora_70B,1riomtup,finished,2025-12-18T15:51:52Z,"{'bf16': True, 'fp16': False, 'fsdp': [], 'seed': 42, 'tf32': None, 'debug': [], 'dtype': 'bfloat16', 'optim': 'adamw_torch', 'prefix': None, 'do_eval': False, 'packing': False, 'project': 'huggingface', 'qk_norm': True, 'use_cpu': False, 'do_train': False, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'mlp_bias': False, 'run_name': 'lr1e-4_r64_nnodes8_lora_70B', 'data_seed': None, 'deepspeed': None, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'post_norm': False, 'report_to': ['wandb'], 'use_cache': False, 'use_liger': None, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': None, 'hidden_act': 'xielu', 'is_decoder': False, 'local_rank': -1, 'max_length': 4096, 'model_type': 'apertus', 'optim_args': None, 'output_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/peft_apertus/results/grid_70B_lora_time/lr1e-4_r64_nnodes8_lora_70B', 'save_steps': 100, 'vocab_size': 131072, 'ddp_backend': None, 'ddp_timeout': 1800, 'fsdp_config': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}, 'hidden_size': 8192, 'label_names': None, 'logging_dir': None, 'peft_config': {'default': {'r': 64, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'lora_dropout': 0, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['down_proj', 'up_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': None, 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': 'swiss-ai/Apertus-70B-Instruct-2509', 'trainable_token_indices': None}}, 'push_to_hub': False, 'return_dict': True, 'adam_epsilon': 1e-08, 'bos_token_id': 1, 'disable_tqdm': False, 'eos_token_id': 68, 'eval_packing': None, 'hub_model_id': None, 'hub_revision': None, 'hub_strategy': 'every_save', 'pad_token_id': 68, 'padding_free': False, 'problem_type': None, 'rms_norm_eps': 1e-05, 'sep_token_id': None, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['ApertusForCausalLM'], 'eval_on_start': False, 'eval_strategy': 'no', 'learning_rate': 0.0001, 'logging_steps': 1, 'max_grad_norm': 1, 'save_strategy': 'steps', 'torch_compile': False, 'attention_bias': False, 'bf16_full_eval': True, 'dataset_kwargs': None, 'fp16_full_eval': False, 'hidden_dropout': 0, 'max_seq_length': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'finetuning_task': None, 'group_by_length': False, 'hub_always_push': False, 'rope_parameters': {'type': 'llama3', 'factor': 8, 'rope_type': 'llama3', 'rope_theta': 12000000, 'low_freq_factor': 1, 'high_freq_factor': 4, 'original_max_position_embeddings': 8192}, 'save_only_model': False, 'tokenizer_class': None, 'dataset_num_proc': 32, 'full_determinism': False, 'hub_private_repo': None, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_of_sequences': None, 'num_train_epochs': 1, 'save_total_limit': None, 'trackio_space_id': 'trackio', 'use_liger_kernel': False, 'attention_dropout': 0, 'ddp_bucket_cap_mb': None, 'greater_is_better': None, 'initializer_range': 0.02, 'intermediate_size': 43008, 'log_level_replica': 'warning', 'lr_scheduler_type': 'constant', 'model_init_kwargs': None, 'num_hidden_layers': 80, 'output_attentions': False, 'save_on_each_node': False, 'accelerator_config': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}, 'batch_eval_metrics': False, 'dataset_batch_size': None, 'dataset_text_field': 'text', 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'parallelism_config': None, 'torch_compile_mode': None, 'add_cross_attention': False, 'include_for_metrics': [], 'liger_kernel_config': None, 'lr_scheduler_kwargs': None, 'neftune_noise_alpha': None, 'num_attention_heads': 64, 'num_key_value_heads': 8, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': False, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'model/num_parameters': 0, 'optim_target_modules': None, 'output_hidden_states': False, 'prediction_loss_only': False, 'task_specific_params': None, 'transformers_version': '5.0.0.dev0', 'dataloader_pin_memory': True, 'ddp_broadcast_buffers': None, 'enable_jit_checkpoint': False, 'metric_for_best_model': None, 'remove_unused_columns': True, 'torch_compile_backend': None, 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'eval_do_concat_batches': True, 'eval_use_gather_object': False, 'gradient_checkpointing': True, 'label_smoothing_factor': 0, 'load_best_model_at_end': False, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': None, 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': None, 'max_position_embeddings': 65536, 'torch_empty_cache_steps': None, 'dataloader_prefetch_factor': None, 'ddp_find_unused_parameters': None, 'per_device_eval_batch_size': 8, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 4, 'average_tokens_across_devices': True, 'dataloader_persistent_workers': False, 'gradient_checkpointing_kwargs': None, 'include_num_input_tokens_seen': 'no', 'restore_callback_states_from_checkpoint': False}","{'_runtime': 8111, '_step': 467, '_timestamp': 1766081216.6983554, '_wandb': {'runtime': 8111}, 'total_flos': 7958103020535808, 'train/epoch': 1, 'train/global_step': 467, 'train/grad_norm': 0.048343196511268616, 'train/learning_rate': 0.0001, 'train/loss': 0.6081035137176514, 'train/mean_token_accuracy': 0.8330257534980774, 'train/num_tokens': 72708772, 'train_loss': 0.7251207515820701, 'train_runtime': 8104.9917, 'train_samples_per_second': 7.367, 'train_steps_per_second': 0.058}"
grid_8B_full_checkpoint-467_2025-12-18_17-28-43,53i5zo9c,finished,2025-12-18T16:28:44Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'entity': 'lsaie-peft-apertus', 'project': 'LEXam-LoRA-Checkpoints'}, 'is_lora': False, 'subsets': ['mcq_4_choices'], 'grid_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/results/grid_8B_full', 'model_id': 'swiss-ai/Apertus-70B-Instruct-2509', 'base_model': None, 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'checkpoint_name': 'checkpoint-467', 'num_checkpoints': 3, 'match_choice_regex': '###([A-Z]+)###', 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 1497, '_step': 6, '_timestamp': 1766076822.9869187, '_wandb': {'runtime': 1497}, 'lr1e-4_r1_full_8B/mcq_4_choices/accuracy': 0.0006042296072507553, 'lr1e-4_r1_full_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://gnkb4cbh4ghi771dra27793h7q1dlqs4h69b21ij8k94k0qli30pj7rrkgadxle0l11h3lvsogikors59ss582qh1oyt4wytjfbww5ylhj479nj5oeyg2uj4spv352vw:latest/lr1e-4_r1_full_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://zz0dd90gsyvm530yhlgfqzbc8zwt2qotv7fgu2kb16mq5g3vfnmor90pcxlncjbcx7bmogosri11vw9gcjxs33r1lbuezc21frmq6y15ycw3k14e58wwv2hg7u04yg5d/lr1e-4_r1_full_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-4_r1_full_8B/mcq_4_choices/classification_report_1_40e14852e6f99662bedb.table.json', 'sha256': '40e14852e6f99662bedb97b3774288a5bb9088593db887edf916d91fda1d36b5', 'size': 419}, 'lr1e-4_r1_full_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://rjl1s9takcwcfqvdktc809yfarjuw1iqzjbbxcq5bqcxwl59drywry3h2364s8600b2adtanlia5f4pmv88m1kctxyzjwsshydiex32w37az3ooit5ilwds8snw61x9y:latest/lr1e-4_r1_full_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://qj7bwls9lhs0s4f6qftwnqoqh4lmyje1aifi0292dhp3p8filletv6w42ujt9l0nfgllw8dgjirucffbfgk10jevr1kn4jexe3nmveeh8rbubg6b7sy8jthjhmj11b9n/lr1e-4_r1_full_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-4_r1_full_8B/mcq_4_choices/confusion_matrix_table_0_78b53d8459ac4dadcfeb.table.json', 'sha256': '78b53d8459ac4dadcfebf4ece44f3019680ddb350f292b4f189f932d6104c4d9', 'size': 525}, 'lr1e-4_r1_full_8B/mcq_4_choices/correct': 1, 'lr1e-4_r1_full_8B/mcq_4_choices/generation_time': 424.4638934135437, 'lr1e-4_r1_full_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://cev1dq5d1wo16xr9dco2t0tt8an5j138z9da535e83lr2yctfw28t9d5mlkoocyie9bjpc4ff96eu70nu73lyd7hnrrbgeqdscvnht94yvtkvkivj0ydneqaodrzgox6:latest/lr1e-4_r1_full_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://zyn34b70sggeppzbt6zgdilgmn9l8ult5tyyo5ky9iekdffrk2kx8zfht9p27k3eetyo9vn6tkllcz0fj1yc2nzxi9dnz4bli7cm0xpiqxrn7lbw20a9xzmzy60h1ibk/lr1e-4_r1_full_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 2, 'path': 'media/table/lr1e-4_r1_full_8B/mcq_4_choices/pred_distribution_0_26fc5704bb34fcfde550.table.json', 'sha256': '26fc5704bb34fcfde550359a352a073d596a3d409ccd8bf1407106f611792c02', 'size': 67}, 'lr1e-4_r1_full_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://efjv4f5lgpkk5srueg47g67le2dy5m32znvk4mr59l3err35yqo0dqv69xnr03pvf4rubddrd94hyyy1bl4wg6hn4mlypshwm5huamxjcdy4zg0yvfzohayu17864fuz:latest/lr1e-4_r1_full_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://qagtmakd30xk9s634rluvtqu9kq3m1gzvtbhayavnnyf08b9gcxlepawyzfkmqtp481p7xbm056kk387msdfw8qqqzszw5ftksy7if0rwkqx1a5h394xitheocsx7h32/lr1e-4_r1_full_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-4_r1_full_8B/mcq_4_choices/predictions_0_2ddcdc648f13f925e234.table.json', 'sha256': '2ddcdc648f13f925e23429faedce42ae19ac074b9c912797aa3d74d121f47e05', 'size': 29739234}, 'lr1e-4_r1_full_8B/mcq_4_choices/total': 1655, 'lr1e-5_r1_full_8B/mcq_4_choices/accuracy': 0.06525679758308157, 'lr1e-5_r1_full_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://n0js2k9ble2cccay1nhmfgmq8ehqldrtq6iivosg4fjhi7i4lkfiru9mzd24sm3e3es5b71zrgfqj6solyfxcc3wua1qkpunitdjjov453on8n8z8iobq53kzvfa0t39:latest/lr1e-5_r1_full_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ue1eknsv9w1hvs2p29m1n8y165p1qkzyawfvd2io4o1tt5p0fdf7m5nvcg5nin6q4bnrz040swoa487rm8pvndspq0qk3mix7annzqaosngqarl2ndehz3m2infuwf0e/lr1e-5_r1_full_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 11, 'path': 'media/table/lr1e-5_r1_full_8B/mcq_4_choices/classification_report_3_2f3561d338355055a2c1.table.json', 'sha256': '2f3561d338355055a2c160f85541e2c86fbdd495d9a41bc64824b72ae81f4a0c', 'size': 640}, 'lr1e-5_r1_full_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://ir858g9zz1qe6fqdyvbjhassjabf7oszsvecckdk0ow1ie48irv50ygs7r0pqxe7qcc6ljaj3j2lt2a3zlbolggn669mlyuasnmsre5650jjwxtkuhhd4z8qvcaa68sh:latest/lr1e-5_r1_full_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ondg4qsyupnsosqf4413g359zqc4qwavrnv7mio76vi9uszig6yw09t279jp9lakg1rz4incwbdhdfjquw4g70aviiwyzhraa7jrez21v859bu6mxnzrpsasbcg6fjgk/lr1e-5_r1_full_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 81, 'path': 'media/table/lr1e-5_r1_full_8B/mcq_4_choices/confusion_matrix_table_2_91671ddb121d2c537c65.table.json', 'sha256': '91671ddb121d2c537c65934006b55b3f9cf3bcac4a8f4251e8006295aae0b3ec', 'size': 1513}, 'lr1e-5_r1_full_8B/mcq_4_choices/correct': 108, 'lr1e-5_r1_full_8B/mcq_4_choices/generation_time': 438.2929456233978, 'lr1e-5_r1_full_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://3pc6oquzy5bxf48ua8cq2r0wvkbuixw8copxmwjvsjdwiedk35wnc8338sr36cbysdyqjhq49lr5myysy5n1lbcapng7uo7b7qbeud170l57fzt6iy0xsjhpygv8wiwq:latest/lr1e-5_r1_full_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://z5moluugsu4z6rlkd8ivnp83xgu8o2mye17g9kfbzeew7e1pijyzgr72rlsiqjwz1mwxax7vm2efpp2tiiivdgopxrpszpbnberoi4w8zzpbmj68ih438qnyk2ejsckx/lr1e-5_r1_full_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 8, 'path': 'media/table/lr1e-5_r1_full_8B/mcq_4_choices/pred_distribution_2_07647e2e21fe63ce1bfb.table.json', 'sha256': '07647e2e21fe63ce1bfba3ec138b6162f015c08bf74168e8f62a29e5439fe4ad', 'size': 132}, 'lr1e-5_r1_full_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://99c851noe2dazxr1902u5g4zap155d5q0f58n07444f2tm0e87vnqb72o080mkhkh1ze66syzet64z4305rmhvud89iwx75amyict8kn606fbhtnjlrhwn2n77kn06br:latest/lr1e-5_r1_full_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://rqhhpk97hnubb0er33q3mcozjjmjr9ydwulnv748p52hs9itm3bfce1cerj5vqkcmcokieexf1o8wdkm075tay462h001r5d84jobzlvos9ad1nzpbrow1nlhjuh92rd/lr1e-5_r1_full_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-5_r1_full_8B/mcq_4_choices/predictions_2_70e6991232d4d04db7c5.table.json', 'sha256': '70e6991232d4d04db7c56fe6fafbd62b094ebefe37033df02467b86784952e48', 'size': 32741280}, 'lr1e-5_r1_full_8B/mcq_4_choices/total': 1655, 'lr1e-6_r1_full_8B/mcq_4_choices/accuracy': 0.25861027190332325, 'lr1e-6_r1_full_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://9imy78glado14hcswmyu1k8lu6vtji8p5s7wjj2ckl4i0xjx026h5oektlqbwjw9hus3h6ckib3x4mgrvlja0gaskgp269udgb1xo4e71qhlzgd41mstwu2j5nbhxq4h:latest/lr1e-6_r1_full_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://3eifcxeqsi39gepayhkc4vllww6bpa1gu63zeu6ftrrifyan147neh8q7fx5ya3yolp2872kbd91yawmatigtma8mijaiuxxm8qeflovjbky115xpx6ou5lu2m92y3zb/lr1e-6_r1_full_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 17, 'path': 'media/table/lr1e-6_r1_full_8B/mcq_4_choices/classification_report_5_14eae6b4a23e351935f5.table.json', 'sha256': '14eae6b4a23e351935f52ea7ba094bcd2f4d0b88d0cb35ff54ff37c14cf2ae7f', 'size': 837}, 'lr1e-6_r1_full_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://0t56y9po3ijjcj8isl88oqwrlq1wqs6amxyv3kd7vxp2xz8chp6b3jhyauhworoqzr05ngaec8wpsa7g4s8kvdyo9o2y2nay4fz8dd0772txe6q2h6aujl7yai231yt9:latest/lr1e-6_r1_full_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://lia2cgfkvmmt3z5mxjpzll868ro7kxw76rad7y7bnrpud05162gputb3rc5mji53p4lzdimpqwhiu56x9605w83m4gi2s336v57annworr8lpdb15sbhn42rnveyuulg/lr1e-6_r1_full_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 225, 'path': 'media/table/lr1e-6_r1_full_8B/mcq_4_choices/confusion_matrix_table_4_62818d4584eee8137a73.table.json', 'sha256': '62818d4584eee8137a73d00f4fea453e37459815c05bb923751ac2638ee80462', 'size': 4009}, 'lr1e-6_r1_full_8B/mcq_4_choices/correct': 428, 'lr1e-6_r1_full_8B/mcq_4_choices/generation_time': 432.10860300064087, 'lr1e-6_r1_full_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://mw84arzhrj4m06mlmdn5t6dwe9nv82dqxe884c1afv7tip7cg5l0qu5xop5u5n1fg26se76ni97278ym4cj2lxh0nenhjcwcjanbwbkw1xkrg3g2fk5z3ht17q9t4f86:latest/lr1e-6_r1_full_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://j3syby1rwo9f7ks6y75vph4rnoevrio7pqvdteyvnt84cpsy55anhff5jbh3kten76ap4nhys33koyqqutru6595lbkxwdmae8p28gxgfb6diik9vrwzde9mzjn31v7i/lr1e-6_r1_full_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 15, 'path': 'media/table/lr1e-6_r1_full_8B/mcq_4_choices/pred_distribution_4_3adee51ed56a824fafb9.table.json', 'sha256': '3adee51ed56a824fafb973678fe3d470de1885f9a5e77a6a52b5a328e09f428d', 'size': 203}, 'lr1e-6_r1_full_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://ip4cltpauh0j7tr3e6mcthzmiywbsgwbvili2oodum8v3zslv9e8o98kdh0mw2xigg8841632qmz5ysq5x095rk53wljrr87jgndbst2mw1rv1g916lghiegxbabd0u2:latest/lr1e-6_r1_full_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://gv5h8xu99nzbzl8b0h0yvn7ezwl6wiqk3rap683e4oa06b8i8lf82o6gefqmmmnr9k6rhscg55qmmhyrgg4u680wm25ose253m32oiy77xjthucr92beexo2omkmc3v0/lr1e-6_r1_full_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-6_r1_full_8B/mcq_4_choices/predictions_4_e67ce925cf7aede2571a.table.json', 'sha256': 'e67ce925cf7aede2571a3efc844ffd4d8bd18595ca9f4977bf6cc332274b4883', 'size': 34923302}, 'lr1e-6_r1_full_8B/mcq_4_choices/total': 1655, 'results_table': {'_latest_artifact_path': 'wandb-client-artifact://67c5wj7r6to1qjc39b9sho54qbzug5u96i7tl8dr6fexe31t5v5rlg5clbuisorhiao03rzz58un6486ugxyy2h2oa96qmoiiz93rdtdc907y2rzly21c3dz1pic1byw:latest/results_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ipu9rfiuq6e5c9nt3v4tv7rojyhhpibjbxukxk2jzoblh8u7jopvy0t66z3ikmj4zi5xr2ad42or2bdiaytcy2287jhvguvst71x5wchdmryo4r56sdnq7nbb1t4pc22/results_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 6, 'nrows': 3, 'path': 'media/table/results_table_6_7d8c96675f4535832cd8.table.json', 'sha256': '7d8c96675f4535832cd86cc260fea62e46f16f068992b5d187a507beac87f9fc', 'size': 365}}"
(DO_NOT_DELETE)grid_70B_lora_checkpoint-lr1e-3_r16_only,2t86l9yo,crashed,2025-12-18T16:28:45Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'name': 'Apertus-70B-Instruct', 'entity': 'lsaie-peft-apertus', 'project': 'LEXam-Evaluation'}, 'is_lora': True, 'subsets': ['mcq_4_choices'], 'grid_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/results/grid_70B_lora', 'model_id': 'swiss-ai/Apertus-70B-Instruct-2509', 'base_model': 'swiss-ai/Apertus-70B-Instruct-2509', 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'checkpoint_name': 'checkpoint-467', 'num_checkpoints': 12, 'match_choice_regex': '###([A-Z]+)###', 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 4661.52380287, '_step': 1, '_timestamp': 1766079987.213698, '_wandb': {'runtime': 4661}, 'lr1e-3_r16_lora_70B/mcq_4_choices/accuracy': 0, 'lr1e-3_r16_lora_70B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://9np2sbzgey656be16ksfeutcn4ucidcufb9cklxdvia5fgk44qpw72emm3k7qf3fl1kbfrjc2jzt0chonta1vcaqdzbx74y8i049osecwd12nehbvx9e8e2hchrsl0r0:latest/lr1e-3_r16_lora_70B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://d67v6qv5jrh8wguntxd8wsy3ykrwdepxi8pki2ub14luir3byjtv3iv9s9k0fvjx5ob69ipf8xhl2bd0upkjl09z0p42dinukjzhwonqu3duelj6tccmr1kxiudy6y80/lr1e-3_r16_lora_70B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-3_r16_lora_70B/mcq_4_choices/classification_report_1_aa2d0a8537e0dc17f09a.table.json', 'sha256': 'aa2d0a8537e0dc17f09a62c053cbce93bb56d4f6d0fa1ab8a56925507713d51c', 'size': 297}, 'lr1e-3_r16_lora_70B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://6vwzqepip44plofdylu3rkthxn8aj3ns83xrsojkiba6cxto74pib4nnes6gpe4o9hbvit49l3oxlvvhlndoplgez5bjm5hb0egfxi4wly2d1g2xyameztn7jtghgqe2:latest/lr1e-3_r16_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://39saks4npp0bdtnflwcxahy1fx4hap74jk99ki5ewja7waubilvhuwf05wcun7p5jo8c08q9e205lz011m4g1c4eyj89ze9lst1q6gpey64tjfhu7n0zs6qay92msnod/lr1e-3_r16_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-3_r16_lora_70B/mcq_4_choices/confusion_matrix_table_0_8adbc301b7442a65101b.table.json', 'sha256': '8adbc301b7442a65101b1bda744c6aec2064a7feb59be8c3171bab2790bbe282', 'size': 525}, 'lr1e-3_r16_lora_70B/mcq_4_choices/correct': 0, 'lr1e-3_r16_lora_70B/mcq_4_choices/generation_time': 4440.493429899216, 'lr1e-3_r16_lora_70B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://jygjtgicy53krlehn3mvacrqwt79lshdbre1t6mbiuzpdzwc8mypt9wellzqafgvzuarqivaiust1kw7mpsq789kep90ga95u8v27smz33nzqtx9mfm823d4wicshbtl:latest/lr1e-3_r16_lora_70B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ttmlx3m5l0ug4adgnuu85pfun0ismu022qwlk38aguir3c97i1r5zr2d5nm2ezh3xfh58b5lhc2fq0wg2e0ltxi5mkqj8v0e8y6c8x456438dj5youexrpug61lwyuz3/lr1e-3_r16_lora_70B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 2, 'path': 'media/table/lr1e-3_r16_lora_70B/mcq_4_choices/pred_distribution_0_26fc5704bb34fcfde550.table.json', 'sha256': '26fc5704bb34fcfde550359a352a073d596a3d409ccd8bf1407106f611792c02', 'size': 67}, 'lr1e-3_r16_lora_70B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://9op13yfxa06u6avlzbjgbk3yzpx4pxoevtohxvgnherkjv1iyja21cw6vg0ptnkw844cdhmemp8mrzr29iue25f59iyo89yvekukltlx07p0r6ctmvxuhgezgvx1p1sx:latest/lr1e-3_r16_lora_70B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://tk500ob1sim1ocfhoxdleraey85k9zep7jasne8la9r9tckosu3nrcdkdif6sauasb6hxcqnm3c6hgxsq7jd5ctvzu1as14dibiac3byq43yi4rsmj9lahfrvjb84sat/lr1e-3_r16_lora_70B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-3_r16_lora_70B/mcq_4_choices/predictions_0_25b93b498ecc4da39f44.table.json', 'sha256': '25b93b498ecc4da39f44fad43a4c47b94325dca6d3e9b4462e0e12e9bc3b7ae7', 'size': 30110361}, 'lr1e-3_r16_lora_70B/mcq_4_choices/total': 1655}"
grid_8B_lora_checkpoint-467_2025-12-18_17-28-44,bu5kwdff,finished,2025-12-18T16:28:45Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'entity': 'lsaie-peft-apertus', 'project': 'LEXam-LoRA-Checkpoints'}, 'is_lora': True, 'subsets': ['mcq_4_choices'], 'grid_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/results/grid_8B_lora', 'model_id': 'swiss-ai/Apertus-70B-Instruct-2509', 'base_model': 'swiss-ai/Apertus-8B-Instruct-2509', 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'checkpoint_name': 'checkpoint-467', 'num_checkpoints': 30, 'match_choice_regex': '###([A-Z]+)###', 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 21432, '_step': 60, '_timestamp': 1766096757.8918617, '_wandb': {'runtime': 21432}, 'lr1e-3_r128_lora_8B/mcq_4_choices/accuracy': 0.003625377643504532, 'lr1e-3_r128_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://wcita4vd7j1vpg4xhv9hcfgeo8p7w0zhcnbexz0822ukeoocoz1ec0y1diliq1gqqjiga0atgxhtsp6cbw3di8sn6qzy26ytly6pwwmu73fl4e93k7mtor7gczgytxgd:latest/lr1e-3_r128_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://2jpcmyzvgtla09g1fgx7vbx3c82uovl5ghz9gbp6ruslhg5ld7fwytm476u4avgpyitszbxm13gjypubl83onq2mcuz7iebzx6t2xzi711ta5zm646svxd92z162ns95/lr1e-3_r128_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-3_r128_lora_8B/mcq_4_choices/classification_report_1_a2f830936bf666193621.table.json', 'sha256': 'a2f830936bf666193621effbdd898dff68c6a02ceb034b687c35c254dccba0fe', 'size': 547}, 'lr1e-3_r128_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://3kynf9ss9adn9w2v8pv5mkq4xzflklydkw84og4g5bcoijpfr6t181x180enl8lxthsqk4poljto5jjdbsm22fpd2lgh89r7wrmq8mf7iip8ymosnlgcuiyyhhzprmdu:latest/lr1e-3_r128_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://hp2n5eqzk35uu1ct8moujmfd6n3ow7uj9zhuzwq1476amjozoht7vm7jsiq4ehlizqspuhu3g91zpukj6tg0qrcypd8bctiyaof5i1lx2f5tls6ysuvws5wi830ifaw1/lr1e-3_r128_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-3_r128_lora_8B/mcq_4_choices/confusion_matrix_table_0_2c94c17b18e8c538e80b.table.json', 'sha256': '2c94c17b18e8c538e80b3ff06c7669aa7a8c1b360df7fc79e88eeec2858d8198', 'size': 525}, 'lr1e-3_r128_lora_8B/mcq_4_choices/correct': 6, 'lr1e-3_r128_lora_8B/mcq_4_choices/generation_time': 575.9686822891235, 'lr1e-3_r128_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://rmiuc9sv9e7urb4p346x9s967e4sn5d912qs86fwknc68v6ny6owwcxli57yyq17z69v9e9z6yrv74fjcyf746il0t0jswur3d46drpb3p0szw7hhh0vb69j9stg979m:latest/lr1e-3_r128_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://c5zhn8qvcjqk5yxegj3863icbue4hcoz6vnuwu45m7t78j1d5ioxpch8r73tx8gw3gil38ihkq0von7hhig45p172ynqndho5yjibcwuyztg3r8mw5r1p2bv2oirj6xn/lr1e-3_r128_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 5, 'path': 'media/table/lr1e-3_r128_lora_8B/mcq_4_choices/pred_distribution_0_bf33385e6addd5133dfa.table.json', 'sha256': 'bf33385e6addd5133dfad435422b64f6794a34d440c69edc9c7118f7906f134d', 'size': 97}, 'lr1e-3_r128_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://850rqtqh2plz4fhexcxbgordlfrgv6h7lyyptjoa6uullevfuypupas29uc6c8ctpvcllxbpx04i1u70hg7dtvezpv4wdnhr26id8zdbzy6274o9s43o3b44u5uoq8gm:latest/lr1e-3_r128_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://k3ykpj0u4ptfr90q95e3cneq2fwk8x7iy3g7luc4hv0hjrepctohg06ofz2so7r59cmznh7nzk11la4foupdfldg484rz53osdnpreuswgqg2ewx3r672vbjb8u5v2g5/lr1e-3_r128_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-3_r128_lora_8B/mcq_4_choices/predictions_0_4201ae49c0b659c46df8.table.json', 'sha256': '4201ae49c0b659c46df84afa1de67ed612be034a7f05687cc849086b92af177b', 'size': 32412185}, 'lr1e-3_r128_lora_8B/mcq_4_choices/total': 1655, 'lr1e-3_r16_lora_8B/mcq_4_choices/accuracy': 0.007250755287009064, 'lr1e-3_r16_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://mu0ebocl6udlq3ih1znindgzj1lpc2b3xu7dwlvnssgnno0ndcr8eikhl8eps2k62nl4qb74dqwut7bxptbj65cytquk54mgrxo690tti24cz724p2nc59ro1agwjsq3:latest/lr1e-3_r16_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://qzgut9fzx3q4m5dczz5z9d62658p61gceznq6s67mmnlp3587ljmb1qb2jlzz1qsqdfrry4q7lo1x0ohdg9iswjqvfbthn2zgo58gn7k5kpzl0i874xdyv06mw4g0k8b/lr1e-3_r16_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-3_r16_lora_8B/mcq_4_choices/classification_report_3_8448eed5829b99417220.table.json', 'sha256': '8448eed5829b9941722054c7768a95cfc44fc3b98de188b0269b482d05d709ca', 'size': 515}, 'lr1e-3_r16_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://7jnpauni5tpvp0h38in8125mtz0tq2awttwu1hq0t4tu6i01mbm9vu35av6etwhe7jelxv4d0oqrq1p71glpmvqoa4rmino0yf1x2088cuolbpo5za4fvuvnrdm4f4g8:latest/lr1e-3_r16_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://8ip671zmbrks1g3hxb00gc6cmzqoy4dxbfwl4gseuks1vn8x16zh68nkfqh05idbg5atw3f34y0kuhxoqkrfrr9st90c4z6pnqrqktxuslyw0z5e3bxk2vijuply027v/lr1e-3_r16_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-3_r16_lora_8B/mcq_4_choices/confusion_matrix_table_2_7c172d9536c4cf256cb3.table.json', 'sha256': '7c172d9536c4cf256cb3d37445624fa7d1d1d1a1cee192de007061e052d61b69', 'size': 525}, 'lr1e-3_r16_lora_8B/mcq_4_choices/correct': 12, 'lr1e-3_r16_lora_8B/mcq_4_choices/generation_time': 350.58090925216675, 'lr1e-3_r16_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://er5y5u3ljck7kiyp7dnrujyl3bvouhw26213qj1fhv2wtg79xjyvfgblhc5vxj6k773prsbf9n3nh3rbi7cxxnvm0tta2r9x3lb4obs8octvl3elgv3s0yoe3msisu4h:latest/lr1e-3_r16_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://5yeydmwv47vzl52quq0x3nv7m91mq9j388dsc39tbnseczhc5pzo3g0jilaa34ysgkgp7hw5n01eosm8lek70fxpco5z6aakd856o50cm3rj8zsyly9vyw5pnyc73b6f/lr1e-3_r16_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 4, 'path': 'media/table/lr1e-3_r16_lora_8B/mcq_4_choices/pred_distribution_2_dd781d6f0185f6611fed.table.json', 'sha256': 'dd781d6f0185f6611fed8b5f0fa8d0abbd76a964fd7d71054fb2f08371198153', 'size': 88}, 'lr1e-3_r16_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://nw1sds6huy0d65am7e069688nbn627gx058uerpmih9r44oqxxnegq0nyj1avj6ki8cxfwf1a1sb3brcd0aw3jrih7vu5zjih7l3isnn36xnbbsr5yxz4ibm3svlydah:latest/lr1e-3_r16_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://bcob55xdeb4yl79xfx05e51xkxl0w5kpcls9vi0emdbdnycv5yppt6naecp0mr0zsxwzxjzn64yalct7j2yav0jag7kg3zuyfj2m5d0dahu18n0g7b8d4pl01heryp9o/lr1e-3_r16_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-3_r16_lora_8B/mcq_4_choices/predictions_2_3368466c3685b4e7f91e.table.json', 'sha256': '3368466c3685b4e7f91e6a91e197d0dd3506bfe75935a7274872509086f632df', 'size': 15978212}, 'lr1e-3_r16_lora_8B/mcq_4_choices/total': 1655, 'lr1e-3_r1_lora_8B/mcq_4_choices/accuracy': 0.004229607250755287, 'lr1e-3_r1_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://j7jwxd9s1gp7amvuap69ep10ht5a9sbxntvtxftnui7i15gpjvm2uqvizldi0m2iwe0m75u7k27u6vybxyfmfw89y7ncw8a79r7y7u8tk48xpmoc7uwoxs9wyv7nxm4k:latest/lr1e-3_r1_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://03l17ldtcbskbyfzbxorj18ax59cj8f6o73d4sqbaailgou35pw7wk6bvcjpexuzxdfntrro590ol78ti1cvac7hyv4s4zv951avx24q8e00w0o1rpgr4zhq1sl1128a/lr1e-3_r1_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-3_r1_lora_8B/mcq_4_choices/classification_report_5_73bdf4a094682e49ad2a.table.json', 'sha256': '73bdf4a094682e49ad2a644e4689edaaefe337734769a6c5c3fd6924ed00cd70', 'size': 450}, 'lr1e-3_r1_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://4h451pcciqf9qsensctwmys5zobcs81fqmo56hze9636vtryhcvbuwuzq8sf0wwjykcs4i870nqqvth1cpd0ivso2w18z9b1kdnmjc5vlc9s8hqcbjog9sbcgzb7w0jj:latest/lr1e-3_r1_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://u5pxssh7bhf0702banh4kvay0o1f459a402ldjrpqsk1e7efr23xumi4gqtkzj88aitinj9glg4hpl3wid4kq1imvhuy5lqm0kdxvcz7yzdo6lqav878diilseghajx1/lr1e-3_r1_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-3_r1_lora_8B/mcq_4_choices/confusion_matrix_table_4_f85955cfcac6e262a160.table.json', 'sha256': 'f85955cfcac6e262a160a4fa5779bb993eb0f61a842acfdd93c2ba0b3e146cfc', 'size': 528}, 'lr1e-3_r1_lora_8B/mcq_4_choices/correct': 7, 'lr1e-3_r1_lora_8B/mcq_4_choices/generation_time': 633.3344099521637, 'lr1e-3_r1_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://0ysbauhhz0s8287fu9ukzmfalq7vyn24x80lmem41ef5u4znra1nvedcfxrxa18pmcbsp9kblqr3dxwqytyhz5dikodm8i6xn2surktxe6pycg5yoncgni61paxkkxbv:latest/lr1e-3_r1_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ffelcpy1bxysyfd5x7ixxkv0yg0fy6d9v4zzq0slg1968kjz1arz3ynr6vqegi2xkpy9bsonsl2vyj9dhuajps5uccvc9m465dwwddqrqg8ynjigeyqbjqvjg0wsjfy2/lr1e-3_r1_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 2, 'path': 'media/table/lr1e-3_r1_lora_8B/mcq_4_choices/pred_distribution_4_1fbe872e9a5640beb311.table.json', 'sha256': '1fbe872e9a5640beb311d6d78e19e1b70b6c67b99f3c0a9a77b31388dd7defcb', 'size': 68}, 'lr1e-3_r1_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://obx2fnzux8i5z8j3s34m0ktz924tp1hmik4wgg4pn39jup97sk7p0y853rowfpz8xfp48rvh741arnmc9sw8zvdhi3zh8sepwm1hwkr6obrzxdr7tntgnb8ofd73likw:latest/lr1e-3_r1_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://1x4mkvm15vgjb0ox4z7hrbovv5ivi1w0rshyne87w8nzp2hte3ove8rdrztjy6hluif2ibvsy4w5qyq3xd1ipay7lhaj04baavdkpj3aeqnepulbabyv3ql28bws8v6o/lr1e-3_r1_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-3_r1_lora_8B/mcq_4_choices/predictions_4_a1e572f4a50f7cae146e.table.json', 'sha256': 'a1e572f4a50f7cae146e64baf9dc6a2d316be25f9e42f28ecf715449b7857ea7', 'size': 25919384}, 'lr1e-3_r1_lora_8B/mcq_4_choices/total': 1655, 'lr1e-3_r256_lora_8B/mcq_4_choices/accuracy': 0.0006042296072507553, 'lr1e-3_r256_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://iu2p7qy40tqobwhylyymefzoifmqqavdxkxgjhdpb912c5mwquge83kuqlm2yj4za4saff190icg9coc5frcm7zbucdivfgsby7q3ua3i5ima2j5pom08ctisy3g5xw0:latest/lr1e-3_r256_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://wej5ipueefk88wgbzhbxtjdip62gxhn62hpbn4hg6ow834g2bu5b3idvxm3257z4wseoht5ykp0get5gnsleazu46w5ua1pt07gjx7nmrapg5acv8nk3e4ynrj2222ku/lr1e-3_r256_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 8, 'path': 'media/table/lr1e-3_r256_lora_8B/mcq_4_choices/classification_report_7_582a1428adc533aacfd7.table.json', 'sha256': '582a1428adc533aacfd72b09220e07a3c3a1549cd507da3047f9fd9570d8c602', 'size': 457}, 'lr1e-3_r256_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://m7esgolfufzdlkc1xptqt5p2p81wybb12fe8smnzi86d4oume5tyjownfdeepin1e7zg1ra3gbzkxqhfpeko98xuplda27rmthz2sqcavu66hxjytr3rxc730e2enksx:latest/lr1e-3_r256_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://jd2yzn6rergopg33h3wssnbpojcjkaa4nj0jajwd5g5er7355cv6fr6zhhv96ivqdq5r32bqmou227l29piku9gtijy53ppov108tu0c67govzdlmfsi7932acoj2k8z/lr1e-3_r256_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 36, 'path': 'media/table/lr1e-3_r256_lora_8B/mcq_4_choices/confusion_matrix_table_6_200c1e5115cc0c04c85f.table.json', 'sha256': '200c1e5115cc0c04c85f09f2638f6b0c2a6cdbc209fbd4dcd8154c928bf66cc9', 'size': 718}, 'lr1e-3_r256_lora_8B/mcq_4_choices/correct': 1, 'lr1e-3_r256_lora_8B/mcq_4_choices/generation_time': 431.5369598865509, 'lr1e-3_r256_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://y36wpzpjfnephzxqm9lf2mzgmix7qfb3zgnwgdx1pefnmobm8kym16i5j8r9kr6w5ynjd07tscig2epq6uj0xkjz3tggqhcvp7041c5wsqy4ha74kdtrr3xuggc3s3r7:latest/lr1e-3_r256_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://22vrn81e71azj9xpfizxdmgvrtnfhs725aqpy0hfz8bdjtti7knu4t45biapv0vat718a1yjqplz4w0ewijsjbf8k2rox359jz085p7gl5l8wryt7bqxohae5viducgl/lr1e-3_r256_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 5, 'path': 'media/table/lr1e-3_r256_lora_8B/mcq_4_choices/pred_distribution_6_f5bd3409037bb9d86368.table.json', 'sha256': 'f5bd3409037bb9d863681239bed68dd2af685cbfee01a45cb180fdbfcb2f678a', 'size': 97}, 'lr1e-3_r256_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://3pfi0g0l5g549iv7r8if93jie9j4pj5bpg6k2thd9fk1omwpfcpdg6qdtotdei4a5os3w66vlqkka5wfu1ut7v3voqvdrzgt27s1gaw2wn1yboti03zp47lpn36q5m9p:latest/lr1e-3_r256_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://zvki6b93ruer9whbd5frh38y7dwl8bgxb616bbzz7w700c0bh7p4s8ujzrzxju5kb99wa6rgc0cyulr38wk76bvtuabtem858yx8zayrezkh020wehtbn0mshguwjq9g/lr1e-3_r256_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-3_r256_lora_8B/mcq_4_choices/predictions_6_550d0ccfdc47278a11f0.table.json', 'sha256': '550d0ccfdc47278a11f0e382ac15cae538ead0aea5b6c835b3bc762bd1e9a9b1', 'size': 21089786}, 'lr1e-3_r256_lora_8B/mcq_4_choices/total': 1655, 'lr1e-3_r2_lora_8B/mcq_4_choices/accuracy': 0.006042296072507553, 'lr1e-3_r2_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://7qbupdv42eardxerx4gdzzwdbj9c2hnwcrt7bdvpa4aprdnpxxjl2z4ac358dwzbftugyfunwlf7eggd16110d9eq9otc09v4689e1dzmodrv170iroclmt8bp43fltl:latest/lr1e-3_r2_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://eru2ms2i11kngouql5z6chx391gx4rjs4wr6uf07hajl9193jv26k6kh7lcgo7o340i2ypy3l243ho8vhq91d3p1ef1pm64oxs94ngrk6u36uia8wn7q1s6rk2h1a00p/lr1e-3_r2_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-3_r2_lora_8B/mcq_4_choices/classification_report_9_56fce3e890f664a9cfb0.table.json', 'sha256': '56fce3e890f664a9cfb02b280b6c2cc94eb24176361364d6a126f5db0684d750', 'size': 449}, 'lr1e-3_r2_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://rcvo76p3dfm1qfh3juhxkhsa6fck2302xs53lzsroedcrt2pwc14udkkr13hp09a7ryn73ymfk8yat4abvy7wxtty6kyqtv3o6jjpdy1qc2j1cssgbl0recz7x1nizxd:latest/lr1e-3_r2_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://m5lbg4efqipxeon5o1mepmrkc8tedekgu7fnbkotvxr5052i64rjrlvemh9fi6cm52kuhjzd403b2zqba0y2vguycpko7hw2v75i082jno860946t3biw7l6kuhkk443/lr1e-3_r2_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-3_r2_lora_8B/mcq_4_choices/confusion_matrix_table_8_3bcccb66776209ac1d1c.table.json', 'sha256': '3bcccb66776209ac1d1c4b149a941fcfe6f3e50f47d16e3cfb7703ae80910f49', 'size': 529}, 'lr1e-3_r2_lora_8B/mcq_4_choices/correct': 10, 'lr1e-3_r2_lora_8B/mcq_4_choices/generation_time': 326.53365778923035, 'lr1e-3_r2_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://uw74kz3fiwupjviq0ihxyxsc9yfjs9e12m6yivw5iprka54d3t4o7yoq1him51t7h355hn1wlvpdmfxh3mbui82sy32ttbyhqr4zlbcwz3o5zzk9o8xl70q07lwazv7c:latest/lr1e-3_r2_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://5zhn874zp75cix0mob7cszxaqksmwoajok9lgrf0g1b8z1ca82ypr56j0l1ytdrl5t87m9szxstwbxgrswolh95l8qyur672rljz8cohqg5eetkb1070ong5iyug51i9/lr1e-3_r2_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 2, 'path': 'media/table/lr1e-3_r2_lora_8B/mcq_4_choices/pred_distribution_8_ba12f0cbd42e1ee40f86.table.json', 'sha256': 'ba12f0cbd42e1ee40f86aa24cd363f7eef82f8f73ee23a84df0e37f0b671d7bd', 'size': 68}, 'lr1e-3_r2_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://uy5a9xseqfb4wipvnimcgfwxj87wfu0pragf27uhsam0qtamu0sgcfmb02f5z9ezg7vz82u5cowzwvj1k7ahxjy2lniv0orvb4qgzignud8yuh0yk96htwyhg742io3w:latest/lr1e-3_r2_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://egmaco8fbzyjwcchvw6tui7099732vlel71qwox7jl14abam8g33wznctjudyonqmactgi0g3vkm9x6un2qz0ux2sv2ow51zwzdqeaj56lxj7rsslr7vls5nlz8iwxre/lr1e-3_r2_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-3_r2_lora_8B/mcq_4_choices/predictions_8_b949eb018ad52470681d.table.json', 'sha256': 'b949eb018ad52470681daf6bc2333d4f2680d907d6a377d45b1c75c856c35a2c', 'size': 14824732}, 'lr1e-3_r2_lora_8B/mcq_4_choices/total': 1655, 'lr1e-3_r32_lora_8B/mcq_4_choices/accuracy': 0.001812688821752266, 'lr1e-3_r32_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://pth8pw7zuvs4l1q5isneof1azgu45ypriuene4yp0pmiaekv0zovfz5iud93ou9k3h1qk8zkvm099jhhc6v3a3ws477jr2je1jmfltyxcpe3fjvfn1nz74bt2drrezl3:latest/lr1e-3_r32_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://qc9dppcr2r6g5cwbp42vcaxzyfazxgrvbuptqhgkwcfarwqcaces8776g4fu4mao21kyzos8wx2oqd4i3ajr5k7jm5t1j9n7pk333hmqbxo2ofuuw1h3t3m9rie8a5zc/lr1e-3_r32_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 8, 'path': 'media/table/lr1e-3_r32_lora_8B/mcq_4_choices/classification_report_11_a2425eef5b71f82f6fd8.table.json', 'sha256': 'a2425eef5b71f82f6fd855885039288fc24edfc67392a9a4a83ca08d1d92fd62', 'size': 495}, 'lr1e-3_r32_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://jzom4r0w90dyned0fkdqdcgopzx3jxmcgc3h20o4fbqmycyp8w6ragif23xv0mxpprr4gancze21vnbt2h4100ydyaumuhn01kbj17cuqrie9ufww3qstnepe7m39bes:latest/lr1e-3_r32_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://4qr8zwzu8r54mhx2y17wfhuab48w6s39ch0ypnnyj9kfw5p9suy1cvdzcsg8f9dz9yp96hoqrxvlf988qiy03118gkdfq69rjtixutz54uze561q6r4yf5tqn423k8zc/lr1e-3_r32_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 36, 'path': 'media/table/lr1e-3_r32_lora_8B/mcq_4_choices/confusion_matrix_table_10_69f61707598231df57ab.table.json', 'sha256': '69f61707598231df57abe7cd0365b94fa7bf834ba60e0938ba2046cb2a2d784b', 'size': 718}, 'lr1e-3_r32_lora_8B/mcq_4_choices/correct': 3, 'lr1e-3_r32_lora_8B/mcq_4_choices/generation_time': 719.1833827495575, 'lr1e-3_r32_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://a5nexf469wjuxksploe2gssrs7mr9mpb0c7ttliq380s842uhj89feyqjr82iglefdg3y5j71pm1frtcaioh472eo4t6ipzwg49iyfz7td8kofwc42rspfi6cc5pb8gd:latest/lr1e-3_r32_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://9wgsms4wp26urc2bxdhckint6vh62ftglzklj8rfzkzufmrj9mlahnhw13mis1h5bzliu1y2hinnvx36rny4bi136vvf3fz159rt9trith497ofoa4zjwm9dhbw84mvx/lr1e-3_r32_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 6, 'path': 'media/table/lr1e-3_r32_lora_8B/mcq_4_choices/pred_distribution_10_7f8ee7534cad3041dad7.table.json', 'sha256': '7f8ee7534cad3041dad7e1da7a87ecc7d620db953fe76fc75098310041a7eb36', 'size': 108}, 'lr1e-3_r32_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://g1902red848uiab2xu5tl0o0mvgznynx9j5x2esef3l7nvth24klimgpassqk6fde5cj3gau8n2yskwsycd6apom6hztaq5f2m7ayifgunj918ssuggj64tx51phkocx:latest/lr1e-3_r32_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://mxlsdpgz55cqelg94pjfe6iv1406gqow0c0ol5pa5wk3veufuwml9q7l7o2jyiepj8ngn6qh8r424uz8vpar7k3v98s33u9xgqwbunk1j0treo0k1lywq8zl5prpb4l6/lr1e-3_r32_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-3_r32_lora_8B/mcq_4_choices/predictions_10_03dd21bb771687b2cadf.table.json', 'sha256': '03dd21bb771687b2cadfe8b480915af603a870b8ef9bdc821996ec9d8b2fee66', 'size': 34207406}, 'lr1e-3_r32_lora_8B/mcq_4_choices/total': 1655, 'lr1e-3_r4_lora_8B/mcq_4_choices/accuracy': 0.042900302114803626, 'lr1e-3_r4_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://9tokgxe44pdwf3asxk0igmlolkfygraq6q7gvqr09w79crrh7qfvcfj6xgeisrj7ysup9se449vjqhbwxahldcizoksqsdp7thkkzbn99aukowa513uiq9syiiraknoq:latest/lr1e-3_r4_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://rxco65nw0euyxqbsza8mfz2s8anoc3tsznlbfaoyacdi6cxzpgblah2ia4617rxw3l5lhz7stkmtcnt84jw3b2u8aq3odc38w2b8mdk6uqera7w6mfe040omh10gn7jp/lr1e-3_r4_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-3_r4_lora_8B/mcq_4_choices/classification_report_13_67dafbbf301e7afcdbe9.table.json', 'sha256': '67dafbbf301e7afcdbe94f5765f93493aff009ebb61f10361f6fadba7cc36529', 'size': 585}, 'lr1e-3_r4_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://3v66gb3grbv2oye0icka5zje1bxc3y7ybw0e8304efrv58tuncxl752x3cqrswlxnuoyu81ybqsum3tg6qdfqq4e4vdrx12icpjil5k4ng0g8t48nd07grzqpvv89j5z:latest/lr1e-3_r4_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://76ditbn2zcndmkwikyaor28bz4b898y8r6g2hvvt39mjx152zqklzxn511turlnprg3wvscs9q2lez3enn6srfcnbx2vv2plrhl7cp2m1n4zuljn3yyox4e5cos1aga4/lr1e-3_r4_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-3_r4_lora_8B/mcq_4_choices/confusion_matrix_table_12_f63c78290bb0f76a831c.table.json', 'sha256': 'f63c78290bb0f76a831c68b9b76d17fc54f8ea0be4b3834364ff0add1ed79447', 'size': 535}, 'lr1e-3_r4_lora_8B/mcq_4_choices/correct': 71, 'lr1e-3_r4_lora_8B/mcq_4_choices/generation_time': 721.6327896118164, 'lr1e-3_r4_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://6x7k630djacs1lz5dg1a177ve571by91tzpvxahs7qpxjo3iedb9se146hlns8ek14czgp1h03a0g1kkfkwk1e342rsixwna15ql4y41sgxx42wci64omi2ejco4ukkv:latest/lr1e-3_r4_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://3fg3ualc0certpb9kofisuoacoot1efbmi2xd53irki46pb8i45j5eg8n6fes6mzmlpj4z66wv0mt2rean1gebufzsbcg66rz7j5xlj8isde79sjka14g3ffyklpy63e/lr1e-3_r4_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 5, 'path': 'media/table/lr1e-3_r4_lora_8B/mcq_4_choices/pred_distribution_12_6357e465dd460a580a77.table.json', 'sha256': '6357e465dd460a580a77259bee998688d3cd920c9dac200aaa52c242e3507d41', 'size': 102}, 'lr1e-3_r4_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://o2ulayh52ij0z22xmt2vn8u4leugpg5n2re98fr0c9up40gxt8cw5ezafvquljqigd8ukr3z929uhu46pb655xm84qaxiuwgiv3wyg0ydzi08fkgaukx1a9cgewacrxf:latest/lr1e-3_r4_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://rpwhieu40kpqv0tcb61uu4ptnjbbzzs25y9gpo480rgwnudby2uuey24ym13rj2w7jt1lqymlo75r4thsska6hjnjiq4c8zcsq3hq0gcv5jvrodqnt9yf6l61zsrrvho/lr1e-3_r4_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-3_r4_lora_8B/mcq_4_choices/predictions_12_7b82c33ee35ab96942c1.table.json', 'sha256': '7b82c33ee35ab96942c1051df8d0a7b7d9913b572272a8e8192efe9421c7a5f2', 'size': 31832386}, 'lr1e-3_r4_lora_8B/mcq_4_choices/total': 1655, 'lr1e-3_r512_lora_8B/mcq_4_choices/accuracy': 0.0006042296072507553, 'lr1e-3_r512_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://s19e7j6hqk0m3lrmib7swhnl0nh29v0z6rlgd0mqgisxdha7pszm14ztznifhs6rqd7kw8vo3lo1uvlagyaoks3a0tre4n2qay700gjo0spmj54p205uqxbsjywklvnv:latest/lr1e-3_r512_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://nlag7i1i4xb9fr4caphktd7g83gxjhirzf8pooy3038uljlvz7excrplb4crtqjjjjkyc42la2spyejqzr529rnf5cx6f3vmo7014g0htz2z34u329xk7j740coh2moj/lr1e-3_r512_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-3_r512_lora_8B/mcq_4_choices/classification_report_15_0ec2a06b9b01d8aa4ada.table.json', 'sha256': '0ec2a06b9b01d8aa4ada91a2635ddff9bd9b3591e257abd4d6122d06b15b98ad', 'size': 418}, 'lr1e-3_r512_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://ipq0lg4nng5vxz9dzxnw3tdv3hm4fal95bsfbxe2d5bw3ehrb02d7n9t4tn4iu39yk85q4i6mvie7ilfkooqr94lx26rv2ef7hnco5a92j7dsinavxwnrcdgg36hcz25:latest/lr1e-3_r512_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://wuzojhu6r7pxfuaykpzdi00teotovybaxefrnrk0n0bkj7fqs9ioh8zrddfqxut0fu8hbdd9u9ijphlazhol2wk9d14igrx6h20tic17t9xywbdc5msv7n4x2k2s2ykj/lr1e-3_r512_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-3_r512_lora_8B/mcq_4_choices/confusion_matrix_table_14_37ce15c3d2bb1eb21357.table.json', 'sha256': '37ce15c3d2bb1eb2135763afc1fa43aab8aef7de2b35ca41e535f663fd9adad0', 'size': 525}, 'lr1e-3_r512_lora_8B/mcq_4_choices/correct': 1, 'lr1e-3_r512_lora_8B/mcq_4_choices/generation_time': 736.898318529129, 'lr1e-3_r512_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://uj85qc5rs51op4lg4w09d3thk50hnp8bj4rotqtrch7hgztmto7ahk5hhpn0vdvjvszilpki85e9wgtl5y7b0fzvn2oa9wh7yaio7gnwsyqosqr8fngedn1haj2lr52v:latest/lr1e-3_r512_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://3o1l2ejv1zpe4zrhdjthprous4dq86ch7q9irnep0mhfxenn77u94taatg5siavk56cka3pwyf04r5mmc7093dfsrm9i3lem3hgcvo8odfon98mb1i9cbv41r4udlnoz/lr1e-3_r512_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 3, 'path': 'media/table/lr1e-3_r512_lora_8B/mcq_4_choices/pred_distribution_14_db7003c66a3fadd9ac99.table.json', 'sha256': 'db7003c66a3fadd9ac9995a0872d6dfd565edcd043a900fe4399990a8b7a28a1', 'size': 77}, 'lr1e-3_r512_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://prhrbvdz1ag8ueegz58o36x0jgk2xuxjmjcuea1oyh0lbw29em67oia55liqso3dve8xa30xmcwpvkvijrswo1510eip8f9rh5fihzp82uwpylgboj0xuh6rtoibslxu:latest/lr1e-3_r512_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://x733746dfydbe87rcte3gk81nxo20ppoctaoxhtetxqdgd4gbt46vx9wkr4jm8lsgt1ckwmaag2ckgktrscq7g1pp96i309981qfckvfdchiyjpclwobmqzd2wjp8xga/lr1e-3_r512_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-3_r512_lora_8B/mcq_4_choices/predictions_14_221b883cf516bc4f25cb.table.json', 'sha256': '221b883cf516bc4f25cbdff545835a41f830123c4c2b34222ff01b89ad0032d7', 'size': 32759869}, 'lr1e-3_r512_lora_8B/mcq_4_choices/total': 1655, 'lr1e-3_r64_lora_8B/mcq_4_choices/accuracy': 0.018731117824773415, 'lr1e-3_r64_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://m3ht4sn5906hup818xcwjjbbhfbj1ynouudkzh4mn9f4itrlsjhxpr5k7zw46y7mccqxkjp3x8iji6df6l14c2b01f6axka6j784ot5x7dn8l6e9ffu5dv7kfvdust8z:latest/lr1e-3_r64_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://5qzc762qh3pp310ytrcpkdjp6yzj65b4k9qztqobg72rg7f55l6o3w1o72zoiz1qfkikglsfntm9ums036e4unxabd3junzlcweq69n7hzlnbcpp28a4logc7s0t3vzk/lr1e-3_r64_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 8, 'path': 'media/table/lr1e-3_r64_lora_8B/mcq_4_choices/classification_report_17_41e53df880880aad0fad.table.json', 'sha256': '41e53df880880aad0fad011180e3db042394f58436d92fa16c51e51dc3dc10ff', 'size': 556}, 'lr1e-3_r64_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://lp8fi6ooob5o1xfv8dw09klywqc8vp6825ftry72awfj9t0mhs4gzrsi76tl880h0y1nos5ka49zq82f1gt2qgwpmidbrzqyvkjp1b53gejreuksjyk93tpdy8is8ucd:latest/lr1e-3_r64_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://07gf1wvfke195sg5qzsl5bqom0e3l7rygmxxsoetmjzrm31dgb49j1km0ix44wc5tm2mrf88bhuld1025mt7xmce679rqz7jq1flpsukv6hn4r6o5zp90cvrrjsq3ofo/lr1e-3_r64_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 36, 'path': 'media/table/lr1e-3_r64_lora_8B/mcq_4_choices/confusion_matrix_table_16_e6168e7a0249ad9be33c.table.json', 'sha256': 'e6168e7a0249ad9be33c44a130ccd921d1f3e2cb62c9c747e6baba2d38d08e15', 'size': 747}, 'lr1e-3_r64_lora_8B/mcq_4_choices/correct': 31, 'lr1e-3_r64_lora_8B/mcq_4_choices/generation_time': 753.2761754989624, 'lr1e-3_r64_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://z14en8uycazecu90juy0ld85408xhg23de8wmblnzk70w47zk4ohqqv3o50ufl9asrv4z0pr1y6fw8osx2g9ynuxg52rzm9d8jcvpv7npsjdihu0lln1eb657zup19bv:latest/lr1e-3_r64_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ii3c6r83kdyy02qvmsymvr4jlqz0wdk72t9eiabwqfhpzvyq776jpxesd9it862hptz6bchc5p1tpudb2t14cthsgiw2uo7cz3bk9rt5d8n34tti1dyycf13yqyuvlrz/lr1e-3_r64_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 6, 'path': 'media/table/lr1e-3_r64_lora_8B/mcq_4_choices/pred_distribution_16_07b5cb920a76d3c8e992.table.json', 'sha256': '07b5cb920a76d3c8e9926c358f41709b6f13d8183201f033bceb0aec21d52645', 'size': 112}, 'lr1e-3_r64_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://b20g37ftazp9h8wuttu8sn3enw5slpugjivkp17omboglkgul8disozbl6mq6lkaj1sn7ew70a548uu6up9oenvh5n2zpqpyw3e3qf89veo0jp01avywcvdy8txodjpk:latest/lr1e-3_r64_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://of6ty5quf2twa584b13hlaf90k1kgex6ak8b4j7ngl9u6yejt1cmyzb0ndi1bmgt5otckindgjx3ybmltgxax7o7x34k4a3ofx627gpjm9d83f91xhrqa8ml14f4596g/lr1e-3_r64_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-3_r64_lora_8B/mcq_4_choices/predictions_16_54a584978e6a59a5c5a7.table.json', 'sha256': '54a584978e6a59a5c5a7ed46f7f773d29ae4184467eccfd564c1a7da270e97eb', 'size': 34247537}, 'lr1e-3_r64_lora_8B/mcq_4_choices/total': 1655, 'lr1e-3_r8_lora_8B/mcq_4_choices/accuracy': 0.0030211480362537764, 'lr1e-3_r8_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://w25waercarckap9mo7flgoyvu40gp48zgxbrrdymur3517osktgqsbs7yvgist0wccm2kdypegu2ztadgof5afadypvoodv4p4c58sppe9xxsadyu78j8jz4pwe1vmw7:latest/lr1e-3_r8_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://76i73i9fhvoo18pygmgyc3omlj1112j9tf2mc4rz9opwejwnjcfxr5h1o5qw4yky1w1gscfmuc38119dt9si4wxqgclsl71c3ehykcgxbfcqjk1fb36s64dpq5zy3syy/lr1e-3_r8_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-3_r8_lora_8B/mcq_4_choices/classification_report_19_b158c1eb9cdbd537ca8d.table.json', 'sha256': 'b158c1eb9cdbd537ca8dbddf71119b8d2efc2e3b302685e03f807652ecf13f33', 'size': 484}, 'lr1e-3_r8_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://n97ztbsemphqsvumqw4yn24cx4axx6y95cvbqqp2jaq6upsl2acj3tacc4cjl933sx6gldocx0vadzb45d35cs63m8lhmzhq988xfe9nrng50p4obv7mx0t2rau92ttm:latest/lr1e-3_r8_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://shd3mn9avq80yli5y8fsklr1jrtmm3odydn3d0vetb1m3pqint2p2f80cp9trkkeq7ha1ef0gwph0czw0t65gassqauhywo8c4cp3iris9s9ndj02hdvfgmycsmwex7v/lr1e-3_r8_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-3_r8_lora_8B/mcq_4_choices/confusion_matrix_table_18_419db80b45addff51bfb.table.json', 'sha256': '419db80b45addff51bfbc1a5c2b1e2e451cf156d60f7c799e3c38903c97eaca8', 'size': 525}, 'lr1e-3_r8_lora_8B/mcq_4_choices/correct': 5, 'lr1e-3_r8_lora_8B/mcq_4_choices/generation_time': 721.7824592590332, 'lr1e-3_r8_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://evisyxdq87u5bte4bmtxbv1z09262h3ezcmfdpkvinpn3og9rulluwo3gyxl9106ngtx1k5kupjufq42axmixsolgp9g4mddukxalayj7c2vavg7qbyhwk2oadpibntq:latest/lr1e-3_r8_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://1lp4irq0xu0vxl9mc2qd690mrdoi9l0bjxl6nxyp6o4hm7gsy9krkdfjyk5zm3awvlt0o5yb94ar7vvr9sau8tzcwwj3xy4ywpaqjazl8phuh5969v2awglj51zsmjtk/lr1e-3_r8_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 4, 'path': 'media/table/lr1e-3_r8_lora_8B/mcq_4_choices/pred_distribution_18_38042b2a84f91c8fac2e.table.json', 'sha256': '38042b2a84f91c8fac2e477f27f961980df39631be25cd46d9e374cb305d6605', 'size': 88}, 'lr1e-3_r8_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://fxjasgvasugbm7x9i5dvn45myt34yfsfbnsbr2cj1ntzlqi19rdumcfjqpv2lq1xqcb9j5ehx72amfgaaoud2x7cg18xrhgxdo6gi9ke7csmqvasne4aerbdnaihveb6:latest/lr1e-3_r8_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://r5r9xgxprvm1em997698rltbej7qffjupw6k7j2rhy1r8w9c3c0ep7p6bw4hs5fqx9ldxracccaqcx7f1kgzom2dk50ghf8zp90oilqvuq2i5c5zodmh5tdzaaw149ze/lr1e-3_r8_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-3_r8_lora_8B/mcq_4_choices/predictions_18_1a6222d5e5ab7807a1dc.table.json', 'sha256': '1a6222d5e5ab7807a1dccce59c517608dac3017ad2660778120e1dc1f72c4713', 'size': 30485050}, 'lr1e-3_r8_lora_8B/mcq_4_choices/total': 1655, 'lr1e-4_r128_lora_8B/mcq_4_choices/accuracy': 0.13293051359516617, 'lr1e-4_r128_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://155t6bb6kr9gtuc23yk0k4nynp6homfw7j3qiz1thyg33oq2q7shd6mm3iflv9qj23icjrxtlpzlcect5wfunp471nrv89e0qp61s429btnvby2kmd3oh928f2dwygnm:latest/lr1e-4_r128_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ru53md9vdpa4qjtvjblbemaaxmfxyu3pi1swrpr1m9gaiy0xjef7rn1wsydvdoamc8chhruzkobe5bx72sogss0rtksrccoekh24ebs39w3finpaellemwf1p1vc3bor/lr1e-4_r128_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 8, 'path': 'media/table/lr1e-4_r128_lora_8B/mcq_4_choices/classification_report_21_51362f41bdca3393af37.table.json', 'sha256': '51362f41bdca3393af379c53273b4811ff8be514b6da2b434d1a98d4b9b9f064', 'size': 595}, 'lr1e-4_r128_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://5d3m6yrqn51kbm8vuiade2q8vu1q2crls3t55cvx6jz4jmqhy5hn0ssnqc5kq70mrrvhb7pc02tkzavx7wwaag93antfeykesmpaq2fvoxe42v3bu2zpi1xv61t0nc8s:latest/lr1e-4_r128_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://dcya1gvyqcuur2r13lbg3p10ka3z78jg2mi613g5e1kxav7jsxjo0mdqc5wbk0z485cf6b5noj1g1j2mas0o9ms52fa7f8gf57dv4mc73wy2r9qcq5j2k50z59uli7ko/lr1e-4_r128_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 36, 'path': 'media/table/lr1e-4_r128_lora_8B/mcq_4_choices/confusion_matrix_table_20_f416d4ae7b6e3d532bde.table.json', 'sha256': 'f416d4ae7b6e3d532bde2f6c839cf514ff4bcef5d020e61103113202ad415977', 'size': 730}, 'lr1e-4_r128_lora_8B/mcq_4_choices/correct': 220, 'lr1e-4_r128_lora_8B/mcq_4_choices/generation_time': 756.3528161048889, 'lr1e-4_r128_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://3pikirzx3a3lpnp5nlpzf6k25zyjm6lg7n6putsq6m2aciu6s4t5ftjuvu1140dtqgmgdgxruzfc9evjloye77vikp8a9iwm9ctyddh9l4auajciph9z272d8q5yq7ak:latest/lr1e-4_r128_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://z8e1u1pengrmzytnhwnkv3ibhr8ujrj0wecz36mz1qmuilx5wotra3v4uvsf8l52m77ow1sfx53sbkgn4dyeczzh1j8bre6lgci9etiozf7y75d6q2tv2ih8mvycequy/lr1e-4_r128_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 6, 'path': 'media/table/lr1e-4_r128_lora_8B/mcq_4_choices/pred_distribution_20_52820c1b99be649a91b9.table.json', 'sha256': '52820c1b99be649a91b9af4afbcc59b2d16b3dd9575d5986223a2398f40cbb7c', 'size': 113}, 'lr1e-4_r128_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://pczfbopzf1z785w3do7bla2in61w7gebmkjltgd9vyae034nxvbw63azr96intwctap0hp7pl11f4msurjpkp663v46f8qe0tmjt26i9eytnb8uwmdznhgn9x0zjpcte:latest/lr1e-4_r128_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://7ptjv03efm87x261idba1xo36a7ldjowtr9wxmeweez055f7yyu3pu945ncoomyoezfzuj950hmbyzqh6rcxs25obj8u183tjklwjiqykzaqyhretkce069t7qq99f7m/lr1e-4_r128_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-4_r128_lora_8B/mcq_4_choices/predictions_20_9f2457768cd7d2339741.table.json', 'sha256': '9f2457768cd7d2339741ec03c5629053c495e0b2ea86f559624ee995ae5c9ac0', 'size': 32915267}, 'lr1e-4_r128_lora_8B/mcq_4_choices/total': 1655, 'lr1e-4_r16_lora_8B/mcq_4_choices/accuracy': 0.1323262839879154, 'lr1e-4_r16_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://qnnq9ixou4uw53hdfmeb3j6uhpcal1ap9l31ncqxwsq1pea620nubjwde20cadloey39k620uuejcr5qhiwva7ilxkhv9p2ysh3uu25xv3t4a8aq1xooy53dr1onexs8:latest/lr1e-4_r16_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ogj0q21ocg3e946ro3drzy2mvf0ruwutan9a7kk16kx2sprzxkfu6ssvdqq1g7p9f1xnx0qune3v9prhvcv7uyutn5vm80j59x7jz3wxohzor82wda0reiqis279ofcf/lr1e-4_r16_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 10, 'path': 'media/table/lr1e-4_r16_lora_8B/mcq_4_choices/classification_report_23_ab4908b66bffbc0d2b63.table.json', 'sha256': 'ab4908b66bffbc0d2b63abc28d96eb70860aea9c0c9ffc34120a2f629688e4fe', 'size': 661}, 'lr1e-4_r16_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://v96fvc24et6qed2851yl08sjp0s2bp1c2l2v6a1f22yuyxyg6ln0ic9m88z064r7rgxv7xwl6makmewfqioe70r609vc54sk7dhba5evjf6bljuvjzdlb2yx3b18izzb:latest/lr1e-4_r16_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://0s52e9mqizadpaub4s1xl6vyzhptbdpd3ph79r9gp5ul0b6cgl5uxcg08jp3t3islc9iyqtw3zw4qhhsmmaizppf23wofioy1hh6hiao9dsl31n9xs53367o7gw125uc/lr1e-4_r16_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 64, 'path': 'media/table/lr1e-4_r16_lora_8B/mcq_4_choices/confusion_matrix_table_22_132484d63b174dbd74da.table.json', 'sha256': '132484d63b174dbd74dace903a78fddf158fcd39500c3d22912b87282e76a010', 'size': 1218}, 'lr1e-4_r16_lora_8B/mcq_4_choices/correct': 219, 'lr1e-4_r16_lora_8B/mcq_4_choices/generation_time': 752.2632286548615, 'lr1e-4_r16_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://02komrndqpbixjy1692t1lvzfb0x13aglakacfejzhr40wha6e994odbdqj43sl7b21mucnn2wskdp8abt0m2xm41brrkqepcrlea691w8ig7dy2k09kgz4ekjbcv84b:latest/lr1e-4_r16_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://lxnirtp6r7xj80w42ywnotnj59867jx1sm6eo5lnj7ey9vbnmh4nf81gk5thtcqdxgbjzqyu3jjbzyexolaget1bpber61kkv2nxalbdisyvdfuygf332srwquwc2t90/lr1e-4_r16_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 8, 'path': 'media/table/lr1e-4_r16_lora_8B/mcq_4_choices/pred_distribution_22_99092c566360b72eaecf.table.json', 'sha256': '99092c566360b72eaecfb7c8ca645d2d02dcdcfd6701328492a6d64e71a54dbf', 'size': 133}, 'lr1e-4_r16_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://xbuiicwldhegbxal5m097bp4iomsrrptc6jv5b1t41ohmd6p2eq0okstnqdth4jw5bppa0hnpxeo5rqgspzbf10p63s1facnw486eyx2fxhib2tw6zbfzf1gm8zvte4a:latest/lr1e-4_r16_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://aiga53v7i9vawlwtut6nr4ub1yu8eovv3ba6q7qynnpjfzypwmkyuey0ycv26gdbqir8wpf4xwrsjhjg55srrum4hfz3zavzfnctzm2u76400e1fgy789wqammk5svgg/lr1e-4_r16_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-4_r16_lora_8B/mcq_4_choices/predictions_22_025b3d259c24fbf5b36f.table.json', 'sha256': '025b3d259c24fbf5b36fe9a08f894405df868f661bf12f3495901e6a7ae4d0f1', 'size': 32682284}, 'lr1e-4_r16_lora_8B/mcq_4_choices/total': 1655, 'lr1e-4_r1_lora_8B/mcq_4_choices/accuracy': 0.1619335347432024, 'lr1e-4_r1_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://shj2mo0u9alml1y7k7cfzb3nv58i7m1f4jkur3ndkj9szsalr4cadbhudoa49etmjwoa3u3qfi77d1jw7kgnophkm3ifnwpn259q3plja5ooe88g7tijkjzcgj1uco9a:latest/lr1e-4_r1_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://7fourkd467r3zga1atuunvechokt637znrp8gkghf0ypq715v25hnwl83nx2pi7dbgsf9ms1twpub7xwdbvonzohe9w8buyxmkg6302dbin3fe3jc72ubgt2egze7pgw/lr1e-4_r1_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 9, 'path': 'media/table/lr1e-4_r1_lora_8B/mcq_4_choices/classification_report_25_0f9f189173c30142260b.table.json', 'sha256': '0f9f189173c30142260bc4bab054de6803b91fa16375f409a3c497e8c2e5cfa3', 'size': 620}, 'lr1e-4_r1_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://cuuvnneag77vvbj72uemc99lydqcwiwlof1uzyc76zmj73rlt9m6hag63ihevmonp62kyz7fy5et94awkvwvahv74irl200lr96of6nnm7rt68uhhvdit8xsog3e8gx1:latest/lr1e-4_r1_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://r842u5drpg2v174udgqv3z2kws91lft6ao800gldf4gixio2ozs18a1cp5w60wgvx5wwy960c6jjble7cz7xms7zwmggabv4msn2mjp2m96smt0w8gsv9s7yejk54ele/lr1e-4_r1_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 49, 'path': 'media/table/lr1e-4_r1_lora_8B/mcq_4_choices/confusion_matrix_table_24_008069c9a314616fb343.table.json', 'sha256': '008069c9a314616fb343ad782f2861b3d43443bd964cbd2c8bfb23cc5493aec8', 'size': 959}, 'lr1e-4_r1_lora_8B/mcq_4_choices/correct': 268, 'lr1e-4_r1_lora_8B/mcq_4_choices/generation_time': 753.3038668632507, 'lr1e-4_r1_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://lfw80uo4kfjai0qj6m3wqfqy4l438swd7mvremnvy7og2vrebf79p6ngnuk5b1mpy30034mp1e24q8lc67jck6tk42pw48xk815laejgfye01z1zc20goush9li73siu:latest/lr1e-4_r1_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://c5gf60nt28br5o1uneu1pvyjsfuy7zm44hw6p0j80hcd2mbo7avigbk780ii5t184efmf6843ft3hgm22fbwe8ze8wlttw2g2twdt32au6jxigxuvkv5dn2vv3h0mp7a/lr1e-4_r1_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 7, 'path': 'media/table/lr1e-4_r1_lora_8B/mcq_4_choices/pred_distribution_24_43df51d55609069e2cbf.table.json', 'sha256': '43df51d55609069e2cbf2df8950cf6083cd408c4008bd21df589ffdbb4f2bfc1', 'size': 123}, 'lr1e-4_r1_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://thd6bgcmu3sr43khvhmzk4lzgpog8frxmtdumeihv04leg2thzzbxn5alxm3npv5vjgbx7c48mhsmflanbmh1lo343lq5t8pb13dkveptrdcpgdkzrf4mxvpiwx0etz5:latest/lr1e-4_r1_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://w47j3gdoebgvqwjz9xgel3n329durcimkigcga1xbyyd6db1iat5q9vf85j1q5nnnt5i3jhp4bhxzigxzzcokhlm45s1na1s5gwvmuj0h7b77fxpcikxd2rubsyu87at/lr1e-4_r1_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-4_r1_lora_8B/mcq_4_choices/predictions_24_07f50bbd897eeb87d7b3.table.json', 'sha256': '07f50bbd897eeb87d7b3cdf25dd42240983ba1f09a46b383e46981cde9c2e42a', 'size': 32832004}, 'lr1e-4_r1_lora_8B/mcq_4_choices/total': 1655, 'lr1e-4_r256_lora_8B/mcq_4_choices/accuracy': 0.1419939577039275, 'lr1e-4_r256_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://9h1iuukht75yjmqp67n1c4su1r4xvodpjrav2n6s2uo89w1ltnmdqwc7nejtix4p1c7fu5matqv3u1rexio7bpld99e2lperp1gv3zz9bodgbrlqld4sgjjns1w3fjo8:latest/lr1e-4_r256_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ykxjzsdsxkstaqicymnzsh8das2zdr57i8r5qo1fzy9edo64lzg8ezi151tyw7a4j470766pmkykfw9ldv71rju70ztznzekoc29lqwngw5nzsnmvim3lbymez1z2enh/lr1e-4_r256_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 8, 'path': 'media/table/lr1e-4_r256_lora_8B/mcq_4_choices/classification_report_27_48c6bae6904a4954420b.table.json', 'sha256': '48c6bae6904a4954420b63ed27967a0c53e5a7660ac8c26141449eb552875fb6', 'size': 608}, 'lr1e-4_r256_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://cuwa4ono6twsn0zlvssfitjg69xjxdk48ljea9t0wmgxl4t40ok1k4h467dzcbx67edh9zufvuz1zy64ry2gfb0vzf81dxasnxzo749cr41tz84jabvvk8znllemmbqs:latest/lr1e-4_r256_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://czfpm5b1bqbgj153iimzzk8y316ri5ej8pavs3oergcbiwdgahjhkjv6euy6kwgptp2ptuw6s7kwu6px16nr8zdfk2btytkn81dsx27ddolmoh150iffdnimm6lsh3kj/lr1e-4_r256_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 36, 'path': 'media/table/lr1e-4_r256_lora_8B/mcq_4_choices/confusion_matrix_table_26_dd9638e999566116103c.table.json', 'sha256': 'dd9638e999566116103ca06a1ff944acf3cdd40e9e4fe174240a8858aae71cf4', 'size': 731}, 'lr1e-4_r256_lora_8B/mcq_4_choices/correct': 235, 'lr1e-4_r256_lora_8B/mcq_4_choices/generation_time': 762.8739156723022, 'lr1e-4_r256_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://hlmkinfdnvlqevkwayb7xp1ofi4t7qxgdar20zli8b7n38i0ragwfoxt5eu4vsw0wgmaua6ztuh4s0tzyabccsq4hn78eds7dl2erxg3dqgk6feejoog4q3po1ff9i4y:latest/lr1e-4_r256_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://8ayeycgu907st5p11akaydf8vn5nxuruma6wso8lo3eq4muz9ojmo8bbo81kvy0b7fjvjh0peiq9udtf9z30iqveo0zxn18orurxgwlzpco8a7jr86j4fo3s2ya9sxsh/lr1e-4_r256_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 6, 'path': 'media/table/lr1e-4_r256_lora_8B/mcq_4_choices/pred_distribution_26_08c466f5bc0215ffc3a0.table.json', 'sha256': '08c466f5bc0215ffc3a07b021340741afe0eb18893faaa089c62e521550e6f8c', 'size': 113}, 'lr1e-4_r256_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://kk4cdz6380x4mxd2rydk2syra3kht3krftfzdafulgjv1j3fvnpu3igry381zsm2ji6ciewj4dft8wk3foze550d7aakah94k1zjp2wva7vn03f87hf3duoz0rec1q5v:latest/lr1e-4_r256_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://iqa4fc2xkwxgjiyhd1bm4fsna3i82e143cnddgsozsf9ouxbaysag7547gop47pnz3z7vqscka42p4ex0iunf6gcqaibxr40kb0u9tviw3txr2x61u6eh9l0zgdc7bex/lr1e-4_r256_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-4_r256_lora_8B/mcq_4_choices/predictions_26_6012c199df1fc9770c91.table.json', 'sha256': '6012c199df1fc9770c91c6106f6377fd7da758d000804ebe7f1fed5f7849ce70', 'size': 32907364}, 'lr1e-4_r256_lora_8B/mcq_4_choices/total': 1655, 'lr1e-4_r2_lora_8B/mcq_4_choices/accuracy': 0.07673716012084592, 'lr1e-4_r2_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://y9hvh0nj2ewev9cffa69toaym2huuhz96tig8lbot5abb7pwt49vf5yhraqvnup76kxpwg71ixj5t6iqu07caxefsg958eh2y3fl54c0voytctmb6u0b64tkiwzxqvys:latest/lr1e-4_r2_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://vct27s747hert1nzx3749hvs6nwu9elha34klrbze1aa7tojpr9re4bo8l8h81sj5g8sfdwzo7veijr2k1j0fpz488c83ouo7rgnwe9yrmmdtsne5vuub2kauntor8hc/lr1e-4_r2_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-4_r2_lora_8B/mcq_4_choices/classification_report_29_f7c38bc4ad83fc203f3d.table.json', 'sha256': 'f7c38bc4ad83fc203f3d723ba4f3f44f407631b13c6ae5e65e274bd9218c1030', 'size': 579}, 'lr1e-4_r2_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://inhujx2so0zqz59243mh692zsepwq8k6ztgqqhjf7wrw9wijnhoclvr5h22ohll12ivwv4275ayt9ogiuhok59wecw1p7husouqits2p9ilw7hlfva7j1s6br1ked2ga:latest/lr1e-4_r2_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://oku248xsisrki98a1pqlj5rfhcmxqzdjbgz008j3xe5c1n3k7ma6cspe4kyrkviyyowjzsoi80h5t8omxsqhwcacveyiakxqfqahq8vrkq4o8xt7r0e24euedzak7zty/lr1e-4_r2_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-4_r2_lora_8B/mcq_4_choices/confusion_matrix_table_28_df0fb7a6686be7481739.table.json', 'sha256': 'df0fb7a6686be7481739e5a7706cc615d9be41357369c6cc24bc52e4ffd3bfb2', 'size': 537}, 'lr1e-4_r2_lora_8B/mcq_4_choices/correct': 127, 'lr1e-4_r2_lora_8B/mcq_4_choices/generation_time': 759.2852094173431, 'lr1e-4_r2_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://ek5cks5t0e5t91wgep5pdjvi9ka3foxsm6jmxs625jgb0y2q664qzag05vn4upcnybr4gwd0zft5heqpbf3jufhidh6orb7afmdht4i6j55qcfk66snv4y7zaiqs8ws7:latest/lr1e-4_r2_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://9ka58r6csp8osu3pepr3fk1ja6tt0rnmloxu38wa4ts9fdzcjedw63hgj7yf13j0ugmnyfxqo1jjyrl53216q2grdjnafjadstn0fq6k6s1tf29wnl312ybj8ofhqxdk/lr1e-4_r2_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 5, 'path': 'media/table/lr1e-4_r2_lora_8B/mcq_4_choices/pred_distribution_28_ebfae89704afc28af5db.table.json', 'sha256': 'ebfae89704afc28af5dbd58a92eef49cdc08d3891317101ef9d667b255710895', 'size': 102}, 'lr1e-4_r2_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://8l7kmf8vztgcm1cmui3miylkyahlzoawtw8x6mwu3bcf672qmhmejqjj1hw63ackr30y83tohkkpavdv1sbfw56asfz5tky9ifz9dqgrty1i7uewjiwjfwfepz57gbxs:latest/lr1e-4_r2_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://bpx5pzpwsx8lh9jlygp0tz3lgfpex7n5hqefbw7dw204u82kl4yhlgeadr8r3jicv7kuofixtzdi50iu6dou4tdtmrm2zp6k2qggkf79pahzhaihupciz4exyyf21g1e/lr1e-4_r2_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-4_r2_lora_8B/mcq_4_choices/predictions_28_6519f3237adecd8744c0.table.json', 'sha256': '6519f3237adecd8744c065e8bf46b997d90cc1ad89ba3318ca5db1c62784d359', 'size': 32743793}, 'lr1e-4_r2_lora_8B/mcq_4_choices/total': 1655, 'lr1e-4_r32_lora_8B/mcq_4_choices/accuracy': 0.08700906344410876, 'lr1e-4_r32_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://oqz1zrwzrf4lmi7vdemohq1tisn1vax940ior3v3h0wyy715qx0wgd1dlgc6j4m6wjdqyv8x8gyq26jlzfbfxuyxwsp639h2dh3g4jp1kqs4piu6kxqqi34fbtxizklk:latest/lr1e-4_r32_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://90m67tvasq0a2fosqiiz86uc9oagx4lgep1bliwgs0tzgkwizuryc9vnio25kl3ljsggi7tehewjn0oqdvxfjx0ydu5k6x58u78mpf0mo080vc9a5i57e64hpgel88z7/lr1e-4_r32_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 8, 'path': 'media/table/lr1e-4_r32_lora_8B/mcq_4_choices/classification_report_31_3870dfe6941414fd72e4.table.json', 'sha256': '3870dfe6941414fd72e42110439525d122ad8a53013d0257c8027638d9f475d4', 'size': 610}, 'lr1e-4_r32_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://ro77khri8vci1yy5d94ob5j4jc40otox2muxktqrh4a7eyu6u0fv5mzjt5yj4kgieiee9jvwkapblh53k6v88d1kj40vue5tuvql1hz4ksmfwpkgazofioc0xb607lpw:latest/lr1e-4_r32_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://73317xdeir2xinmpqpj5ndckbpt37l4c60cnuyn2k0c9p35gt7l705n1nf4p5c3hlbgypr7dy3nqag6tq6m6xlm1ggui7b27zeqmx3d5z58f2piecrqkzpii9odmsfa1/lr1e-4_r32_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 36, 'path': 'media/table/lr1e-4_r32_lora_8B/mcq_4_choices/confusion_matrix_table_30_faf32f6f48d3a8caae29.table.json', 'sha256': 'faf32f6f48d3a8caae2940ca1762dea96b0f84fff1bf129a9d84eb0512d61012', 'size': 730}, 'lr1e-4_r32_lora_8B/mcq_4_choices/correct': 144, 'lr1e-4_r32_lora_8B/mcq_4_choices/generation_time': 766.4578051567078, 'lr1e-4_r32_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://3n7mhwtl1emzltxmql7u9q1w6xlz04vt0galujfqogp0xm2w1w2w0sqxahgjyt1p05cdhezcx1yskhemd8umkmzz8fpsb5j2dqjxw038gbv3bl2mkeh3ae0zplkzvu6u:latest/lr1e-4_r32_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://y1xhalld9lcrlaxv0twv6h6qasaq7mqcumh6pxdj15dy4q98t66vyizjcaxk9j5mkj9shwy0imwot8zfv28viujkokkcdek81zo9nppng8ut7x3dy4kn8i023tbiloah/lr1e-4_r32_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 6, 'path': 'media/table/lr1e-4_r32_lora_8B/mcq_4_choices/pred_distribution_30_1396a21f757ead445978.table.json', 'sha256': '1396a21f757ead44597819c09f1115c1baa75b0ca10f3c8c7efaecbf81af966d', 'size': 114}, 'lr1e-4_r32_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://l9iq63aprach756gcgpgctzo8uj2awc60y0k5lwbbi68njb5aj9shc2d1wc84sd8f2oe1hu6k7sj3tfnbguo04itoje5r80g7lgh1vgwu77q0j8ounc8rzaa6waqhupp:latest/lr1e-4_r32_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://gwb27y1o5h7r5mqjah7anhfi1dnd76rmpacayv4f6y9ekici3s0gb1bcb71kgxknadqi8ygwl31htkfg8wiqkvpjec3em2c85jrtl9md16iks70wm1lbhlk17knnz20y/lr1e-4_r32_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-4_r32_lora_8B/mcq_4_choices/predictions_30_00af3610284602362899.table.json', 'sha256': '00af3610284602362899cfe370259022bd4d00082e9160e15403a898102e6a57', 'size': 32922237}, 'lr1e-4_r32_lora_8B/mcq_4_choices/total': 1655, 'lr1e-4_r4_lora_8B/mcq_4_choices/accuracy': 0.09546827794561934, 'lr1e-4_r4_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://6jdkrrwfar4o0r7cldcw23g341p62nf7xsca5z9golnlkwcxcpn81rtzgabhy1wx25vgrywkt5yzlttmy5a6k67b2xgdj1wzoecyctr1gon1zsrnjhceyqtajuaovb2p:latest/lr1e-4_r4_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://doje5thuo1ut2ppbfblcdahz9e7cuxiem8sn6vlddnt7az9506loc29np2cd71bvwddhxlsfg8kqjpn0j0myrn2zxw7cxzdmhok1uyb8xcquh745naameuuzpxazkwyr/lr1e-4_r4_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 8, 'path': 'media/table/lr1e-4_r4_lora_8B/mcq_4_choices/classification_report_33_9f01780967f9bedeba25.table.json', 'sha256': '9f01780967f9bedeba259fc6e6ee07b0971691a09590abfe52ed2b4ed3386464', 'size': 609}, 'lr1e-4_r4_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://jrj8c46sccztpo3anvqtv166hhd22cmq8l4gc6rqttgc0wgobo5uqrxq47b01qt0jobids1ya38iotak5dovuloiqgsn20pgtukjhoy9eeoydthetjro2wk2a0j17xem:latest/lr1e-4_r4_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://uxqfflierk8lrr8e4roq1igmcv9gux4pksxib2e01vy9irdegn10yddooqhrpbkt7eu7767nm535qwmopd5dtcigzdz2v5h2ee85yfok3faapo0itb0lsn8mfcmo3uv9/lr1e-4_r4_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 36, 'path': 'media/table/lr1e-4_r4_lora_8B/mcq_4_choices/confusion_matrix_table_32_7022f3a59d0d13102e54.table.json', 'sha256': '7022f3a59d0d13102e5432be5d4641cbc68cfbca968eb92ccba4a43782b5b70b', 'size': 730}, 'lr1e-4_r4_lora_8B/mcq_4_choices/correct': 158, 'lr1e-4_r4_lora_8B/mcq_4_choices/generation_time': 762.2955389022827, 'lr1e-4_r4_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://7gmj79capo104ftkxe4g71t7wpcnmdgf2tzu937il8drhcbhr59rlogcxp8u1wwbi6h66ttgvlg2cdkwghb3worf9kc1nv5jhvzjc1vdqiuwsgme0a2uus0vzrf0wopy:latest/lr1e-4_r4_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://an0y5ogm9jl2zt1os4c9azhcxohez6ge334urwcctowwwl1q9l09evslyw57v2oxptupqm86tlvghlf290bifdolu0n72rszeb1khpnk7tckvojw7ehbwjrn11qaial1/lr1e-4_r4_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 6, 'path': 'media/table/lr1e-4_r4_lora_8B/mcq_4_choices/pred_distribution_32_0903557f4c49af43b6dc.table.json', 'sha256': '0903557f4c49af43b6dc00d8190c38aefb5f5cc46a68b4f00336a3275bb60dd6', 'size': 114}, 'lr1e-4_r4_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://sies21am0ittp96u2pyce5x1icch63nf80ohxc1s75ug83tw8r7x8g1nwfyztda55lzujiz0efuyy95r0awa74lpemqyv537copk2himbdtdvtkt5cnwylcykxzggeeq:latest/lr1e-4_r4_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://cqwom7cswriz9a937ysors9lbh5j2iyqj9tynygd4nyr5o6qa4tjwaqy10126vfu6b0wzkyi67u9ui5er8wmjxv20kkp8whabkq4unyn9yt2r1pip95r8hjeyuez46dj/lr1e-4_r4_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-4_r4_lora_8B/mcq_4_choices/predictions_32_4e7258aedef36000fc2a.table.json', 'sha256': '4e7258aedef36000fc2abafe0dcacb83a0aa2338727f62b43106813d0954973b', 'size': 32712987}, 'lr1e-4_r4_lora_8B/mcq_4_choices/total': 1655, 'lr1e-4_r512_lora_8B/mcq_4_choices/accuracy': 0.14561933534743202, 'lr1e-4_r512_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://gbn1mmbtv4upaaro1bmvvvvmifegmbue19yb57vnonivv9xinbxpo9gzv97sokvofc7x5p3ck9cxcrh07fpufdz4hrnly14whcf9f4wu3sfthpa0ywe9d6fvy3ldk0jm:latest/lr1e-4_r512_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://db2vhj8kbiegoipjyo80l0x9i7pnw611oj8ah76z7r3pe8s93f7m6lat4jtmsls75ilbm64tu859qaavvfvqjadfwjk3ty72o5fkdgj5fpywh6l2xl527hv10m1h9qsv/lr1e-4_r512_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 8, 'path': 'media/table/lr1e-4_r512_lora_8B/mcq_4_choices/classification_report_35_bb5f332798e30cf7f0c9.table.json', 'sha256': 'bb5f332798e30cf7f0c97b7ee5259e65311b11666ef9906e5e4caafe47e034d3', 'size': 580}, 'lr1e-4_r512_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://h3gas834oerttuaskewidmzsbmc5am09pv5y9uz3t3u88a95nezc9f2hdvizlk691lszq1h39zdqi08mhcnaa63m1fjc9yj0affokw8k6fe4sbrsa49h9jgyhyfjssnm:latest/lr1e-4_r512_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ul7ifo21uqamwcejh7mis5ogybe92pcr5vjrrff7p44w4oe6tchrizbvehf2fjbexdanqr3538dcjiigsi24q4sg0h6ica0qu6ypp3l53esrrcbtuwt3nv4ops2wh0dl/lr1e-4_r512_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 36, 'path': 'media/table/lr1e-4_r512_lora_8B/mcq_4_choices/confusion_matrix_table_34_61e29efc94ce42b3c15c.table.json', 'sha256': '61e29efc94ce42b3c15cf8034881c407ed3f8e3662ada0c435fafba1531604e4', 'size': 731}, 'lr1e-4_r512_lora_8B/mcq_4_choices/correct': 241, 'lr1e-4_r512_lora_8B/mcq_4_choices/generation_time': 780.2903263568878, 'lr1e-4_r512_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://6bb0mfgpkkmdwgt48ak8ijq53n1p1nc8v6a50c58ddblkbvpk32xx87sjixzbzkulj8ocakwyvmbe9xh2t992vnh7501axxlahw55bqoc18r403ps5mm0sgeiyv9eh6n:latest/lr1e-4_r512_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://2bae7y5wer4c5nzqsdrrceimc0hrtsm57d4bn4qrmnuxlxzysi7g9dib5ubgvjcd7iizxpx3mi2h3oupiw01ekbmq8v2dlqp22uib6e4t5zfmmc7hct7y43he3tvzvlk/lr1e-4_r512_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 6, 'path': 'media/table/lr1e-4_r512_lora_8B/mcq_4_choices/pred_distribution_34_5e0bd0a134934d8e0db6.table.json', 'sha256': '5e0bd0a134934d8e0db65fe7e2566b8b1cd40513e72d9e577ef5f9006e782cba', 'size': 113}, 'lr1e-4_r512_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://c1io396yof5qm8blei8nm5wqz4e1mmb5kenrkn50vsuvuhb8bn9b4owmtlip2k8lfmf60y8qrnzv0dc4j7m0tjjnfjae6frwuv5kfeq9zx688mqkmhpkfny01kdht8m9:latest/lr1e-4_r512_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://5zdaquv0ksl6jdbm0e8rminwrtf5cykq046e02gtqyz1pvjv35fou5i2asd1ugtk18379xhx30xk1iihxa8q0w4l6tccxgu68fjtohoh54ec5fytfe5a38iojw0tarce/lr1e-4_r512_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-4_r512_lora_8B/mcq_4_choices/predictions_34_03accd69df4e92ec33f0.table.json', 'sha256': '03accd69df4e92ec33f0d84e8192412c6e60cd793cb3d3a907ad1d405fc1a495', 'size': 33049055}, 'lr1e-4_r512_lora_8B/mcq_4_choices/total': 1655, 'lr1e-4_r64_lora_8B/mcq_4_choices/accuracy': 0.14682779456193354, 'lr1e-4_r64_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://k09kfhghjz1waqovg8oe6rvjytxnxd677t7vzmjdszchud3blm8g6djdcdgz86ucauy5v7gva7ajaj1sesxlw4wuhk5403bq72ms44nos5gkg7rzzpou79db4ojmkail:latest/lr1e-4_r64_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://v639orfe0qjkzrjxb91xm11oemlvziz8c3m12nxh9ugwo1nkkjnaegdnnzcl3fokk2pn2zoh5az75w3161gmc12hzgjvmlfthdb54bd6ushr978zg8j7bxkm1k9uarqz/lr1e-4_r64_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 9, 'path': 'media/table/lr1e-4_r64_lora_8B/mcq_4_choices/classification_report_37_47a3a43b8fcbc3976c63.table.json', 'sha256': '47a3a43b8fcbc3976c63923c46be49c6c5cb7f6eadaa6ac36a66d9171679ea53', 'size': 619}, 'lr1e-4_r64_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://vx3e18r35v451zbsn3fhps0m29caqgw9rmpbl0twigw5a3fk67rf6wmiumvqx2c6nt4tzzfokmfhnffhrkl0upjs6dn0u0i0czt96dwmziozpfycotufffw1y30tcc0g:latest/lr1e-4_r64_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://re27rdbk7dj0li9cuwermhwc8v6ywr8els6rit06o2qqi2ngmdszg6mt5kaoihg2fh599okpqv1pnudlsuu4zmyoz57e9hcvkf1rmgvgl41jux7inbr3k0vwe4tn0occ/lr1e-4_r64_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 49, 'path': 'media/table/lr1e-4_r64_lora_8B/mcq_4_choices/confusion_matrix_table_36_7a2857d3a3021702ebcc.table.json', 'sha256': '7a2857d3a3021702ebcc6a2685d2e6ff8ff5e337018a74dc1e2ba766148ef803', 'size': 957}, 'lr1e-4_r64_lora_8B/mcq_4_choices/correct': 243, 'lr1e-4_r64_lora_8B/mcq_4_choices/generation_time': 774.055212020874, 'lr1e-4_r64_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://d8szdjlo8pom30x2xav7l092cfsbr0c9eog4tg0qzh4ioer30fd6s77rapavcy5473e7hjcub5w6zk0fcq8l1maat36f60jovv08i9hh8q9wg9zbnfaccc565fm0eg89:latest/lr1e-4_r64_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://nkn83zzspxocdbdl80mq6cvrzdcy98ofczn3satjk9a4lpqydwcsq1uy9lfgpr4zxx4qgb859v8b0qssx9eoc8uuubst9zxbswvxr1x1pyaqtu2htvvkt8cyrj53kc39/lr1e-4_r64_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 7, 'path': 'media/table/lr1e-4_r64_lora_8B/mcq_4_choices/pred_distribution_36_df25904d01ee17de63a6.table.json', 'sha256': 'df25904d01ee17de63a60d9aba7ba60612376b6334ad09b9dadb6263ad7cabd0', 'size': 123}, 'lr1e-4_r64_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://53f6o7i6ymgsop0hgfmrx930i6yagfuth9sqvrcu2ejyi0uqh9s9m6iwkuwg34rnfxizwhq3kch3u5qpkpoa38ps8zez4mmx5bngq4fe636h2x5z8j2hw0cn96vrcy7d:latest/lr1e-4_r64_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://jxd2bhs3q9hz05kzarloqxvqzfuqto4pr12h77clerqgi4mbz19qjsn7oxyd9abkinnwfxonusxe1zzn2u1tce2onsiajzvgjzlfxe37z8hz8h57hbgybk8ten4jg7x2/lr1e-4_r64_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-4_r64_lora_8B/mcq_4_choices/predictions_36_c6920777694a469ff094.table.json', 'sha256': 'c6920777694a469ff094a5985e8d5225535bd37802dde1ea160805f14d797c11', 'size': 32849471}, 'lr1e-4_r64_lora_8B/mcq_4_choices/total': 1655, 'lr1e-4_r8_lora_8B/mcq_4_choices/accuracy': 0.08821752265861027, 'lr1e-4_r8_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://tpw3vm0dabgonh6tlni28bxul7lwjg0n7ntwrh6eescztpdd1yafptvw0h4lscvot0ewlybl3tbrwozlyg6bye8z7jnz1c56f9kcu9g3pg715ofzd2d7ubwk25zgc82r:latest/lr1e-4_r8_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://tcilp0900zb5rckmqlmpscmk8rkcjqbxrokn9ojbcg839e2jiguctmeles3gu5m8mbffyod3a14if3vrtshxhv9c293d0pmkuaem15n3qwxgbpd78v0750dktz5eepeq/lr1e-4_r8_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 10, 'path': 'media/table/lr1e-4_r8_lora_8B/mcq_4_choices/classification_report_39_cbedf8cb35e6082c697f.table.json', 'sha256': 'cbedf8cb35e6082c697f2f71052d57fbc3383706266823fb309eac6a968ea6c4', 'size': 651}, 'lr1e-4_r8_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://zkhhhe5joipmqqeq9e6qxa3g4lmmoadvfyvmc5rpji180rx890a03tg9ingh24taanhixm19iwe95q8c1az8r12x0kpt4r0jxeffeshc0b7n8oyihiq6395vpsrt5zwh:latest/lr1e-4_r8_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://7je417ksl417dtnlw81co49l3o8jkxh4tysnf54497h0d7kn2wmrwy1ufyrkmo2h8aur0of2hv1e6h20ge8e2vky25a0lk6nmuu5hgx94bj4z1knwwcy7h2oqatijq17/lr1e-4_r8_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 64, 'path': 'media/table/lr1e-4_r8_lora_8B/mcq_4_choices/confusion_matrix_table_38_cbf1302cfa78254d17c4.table.json', 'sha256': 'cbf1302cfa78254d17c4a7a52895f7ba9f8f3ca26039167f17d372c7e6b7b80b', 'size': 1218}, 'lr1e-4_r8_lora_8B/mcq_4_choices/correct': 146, 'lr1e-4_r8_lora_8B/mcq_4_choices/generation_time': 766.1466190814972, 'lr1e-4_r8_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://sk2anou7uypq72g7m7fwk9i8fhekzpzj0v86mnne8jo9c5uvukoaauas7ns6gdhf4yz0se490tzbjik99yiavg773kxo3gtidnadt433cged0ul3o12rc6a22jlmh2w7:latest/lr1e-4_r8_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://x46y9lbgb61ejiyiss99v8ihhjqr37z25me1grbmqf37klawmcumcersp3m73s2r4fgpiy5bdr687ol0kngjhifstf4ju5z53043b8fji53jlj39bnt6ymxfc5hs99i9/lr1e-4_r8_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 8, 'path': 'media/table/lr1e-4_r8_lora_8B/mcq_4_choices/pred_distribution_38_a400663421f12325ba19.table.json', 'sha256': 'a400663421f12325ba19e1f10658b6788294487e8780b0b3742d7b0acc888f44', 'size': 134}, 'lr1e-4_r8_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://ceyj7kiuvvkaikh76iprgo0mxztow0oahqnwm936tokyhmlfjtx6ypytew5r7947gu35wc7717tkf9j2xps7u5tsttn6y9jf2yop0ublw3j8ia00mzn1wkveefs7kaya:latest/lr1e-4_r8_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://pjt1wo6eo40s4rb0fhcsuzepuskvb2omlq5iaf6umugghght99uzdpfe11re8x2nl7t6ljyiueq5cnjq0nj8q1lgij8h3vcn4f03origcq6yaxwpg0vzekoyt454y87p/lr1e-4_r8_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-4_r8_lora_8B/mcq_4_choices/predictions_38_a042611d9059e8f209b2.table.json', 'sha256': 'a042611d9059e8f209b28339b511a5d772ea86039bc30d6fbfca3b4bf934ae49', 'size': 32934961}, 'lr1e-4_r8_lora_8B/mcq_4_choices/total': 1655, 'lr1e-5_r128_lora_8B/mcq_4_choices/accuracy': 0.27250755287009065, 'lr1e-5_r128_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://bklbh8tdpda1bdfvkr6msda4uk5i2a056u1201sokw1volxofwjjqk630dgzahjikslohpe12ly7l3o2iapb9qd3d82sflgfagz9g0onilertnmxph3766co3aesf8wx:latest/lr1e-5_r128_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://pyi9e3pzvltjl0lmtzywu086jag1x8cvkonglh2oanrnfjas2iqiiqsdbvu461czz9y4jsrygeuoyzpr36qzn1q0et5v8at1ye6ieko5kc4r3xwf8g4rafynbci60cgb/lr1e-5_r128_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 17, 'path': 'media/table/lr1e-5_r128_lora_8B/mcq_4_choices/classification_report_41_0ac956c10d378da2ca29.table.json', 'sha256': '0ac956c10d378da2ca29c5517f3bdb6ccafe0622115ef4957cf3cd4d6cb72f06', 'size': 837}, 'lr1e-5_r128_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://17s9v7bidb4forqqpeic2xgdwvfli6knih2h1a5qksga60tbrojwfl0hdhr676d1o2wkydiiqwj9698if2h23hqrm9ttdbpzbm552qiq57g288cua2l23hopsv1429mx:latest/lr1e-5_r128_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://pmg3vizcudu3vjh57mf1ly6gldgucgbjiq3pok39a7279tqefdfx7ct9265zn7aoj2jngt7cjskfcb5nfj7iq1ocbpdkamamoz7c87w402f24mh291zly08hlwlf0pjh/lr1e-5_r128_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 225, 'path': 'media/table/lr1e-5_r128_lora_8B/mcq_4_choices/confusion_matrix_table_40_9df81e30f9d08f2bc0ce.table.json', 'sha256': '9df81e30f9d08f2bc0ce085b7a7c4611834a2f6e73ee0df622cc8befc8d74138', 'size': 4005}, 'lr1e-5_r128_lora_8B/mcq_4_choices/correct': 451, 'lr1e-5_r128_lora_8B/mcq_4_choices/generation_time': 777.0965807437897, 'lr1e-5_r128_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://omz1p77xinsoz6u16jam7maoc36bhp2i1lej2bzhoe71he140prqxxd01tuafovct2nb5vupma1eir6ck0yiiedz3h9aukb7w02qrkktjfq8irmyst1i17ac1vxwyfox:latest/lr1e-5_r128_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://r2ba02xiuj1vjkedxcakz5jr5wyoj0uq4tcwvx6el6horgehuv0dzomhspdvzilsb2i6a9gtz4sqecgstmm492n6t477z1uqd5e5wl1q7qtgdj7ss7ib9dhkt262o00x/lr1e-5_r128_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 15, 'path': 'media/table/lr1e-5_r128_lora_8B/mcq_4_choices/pred_distribution_40_d9f1849fcb4f87c39c6a.table.json', 'sha256': 'd9f1849fcb4f87c39c6a8b81aa018fed23499aa8f87b30a3c2fb3981f843b009', 'size': 202}, 'lr1e-5_r128_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://0gektqc1o3pkr0j2hn4e5w65xtg3rnhtnspvufkowu08oel61gnprwe0rvf4d3g8g39wx7gvrmfx94xk2fjsqzr88oncpwednfdtepfmwd130ln6w3yazn61ak0yqejn:latest/lr1e-5_r128_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://kjpiorybvkguj1cmdwosa800y39ss5rkscx9sp9eeyrrnysfi9heio3g5wuy9km21wp9rd1u1uhprxvbl3al6mt5umumfij9ortkf2umul4q1zmyogqjz8vut17nqrhk/lr1e-5_r128_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-5_r128_lora_8B/mcq_4_choices/predictions_40_2b25a6da152d12ac72cd.table.json', 'sha256': '2b25a6da152d12ac72cde0bc277dbb5a710f42fe4507bb9dfeae95c8ed702907', 'size': 33795201}, 'lr1e-5_r128_lora_8B/mcq_4_choices/total': 1655, 'lr1e-5_r16_lora_8B/mcq_4_choices/accuracy': 0.2676737160120846, 'lr1e-5_r16_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://m19yfgz2ynjskmikn6ow661wrv59b2dbdnidf4lgfnlso91vp95oo0wudkdj7ql9x31ypbgy5p2qgquwpdjldis6hx81l8z98i0kc1z17hoj7n2kqhohs1teo25swvp1:latest/lr1e-5_r16_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ih4qoq1au7sw53vsa4b4u1wdat0eg7men6wvfs66yrcfd31ib4ge9bz21x99ggitn4k8z5jsajmo9pnyxfc9afwd571qmr2o76ap90x9a7se853cqeqdeyg9pg81g09a/lr1e-5_r16_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 16, 'path': 'media/table/lr1e-5_r16_lora_8B/mcq_4_choices/classification_report_43_6ea14f09e28282d7eb1e.table.json', 'sha256': '6ea14f09e28282d7eb1e43fbd87bdcc3482d4a53dd73bbff165475c42928e581', 'size': 820}, 'lr1e-5_r16_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://qig66l2o4jezhc9472y41nhx9cns2p8h3pfk3cgx5au8jhy04ap9moavg1f9qqmheod472wz4wehywalw8muk8hlj0jpgpwp4ht7suazatmc92198xakhwztdje0789k:latest/lr1e-5_r16_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://lefblljmfbchsb3yunlk5sgywb5t2aj50qf1sbpnyue7uo9mfglrkm5eee1deco6d1fuj6chsue9wc99ap9r0fmg24up1i4pl5fbiprsd3i68qpxq63cfdxbw21sn4ra/lr1e-5_r16_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 196, 'path': 'media/table/lr1e-5_r16_lora_8B/mcq_4_choices/confusion_matrix_table_42_8c2f6a1fe94a09b9e380.table.json', 'sha256': '8c2f6a1fe94a09b9e3808dd64818b92133e1e2d3a44ff76ef24a0b7c80421ba6', 'size': 3506}, 'lr1e-5_r16_lora_8B/mcq_4_choices/correct': 443, 'lr1e-5_r16_lora_8B/mcq_4_choices/generation_time': 768.870552778244, 'lr1e-5_r16_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://p5ffxy2lps8tnykrt1z6i86k10ntldf9skrhe9myholh5dkfgxdsvbtrt6jlx7tbu15ohnwvcpqjo3alwljfr9pasl0i5croly4wu2cii1bnzouk4rpewk064e3siijz:latest/lr1e-5_r16_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://2nyw66gngcsc2j5oqlqjjkdvvqdyvghkc0933wjol0jdalii5vf47qdns0810kdpm0hu2uulq82raznyqih2j5x6dwa0sy3jo91v2o7ol4e4x12c4oafwnkuf997pvjz/lr1e-5_r16_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 14, 'path': 'media/table/lr1e-5_r16_lora_8B/mcq_4_choices/pred_distribution_42_29fe27adfc9693ac7f78.table.json', 'sha256': '29fe27adfc9693ac7f78e518617bbd7e976f5ca839bda0791b9c398261cd42a5', 'size': 192}, 'lr1e-5_r16_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://ydtyv8wkdslsiggwj4jxdt47fydwjmxuyuhhqxbuomfoefrmqg411yh45rd18008e2fv2wsr8h8jiyajiw88ynyumzcbtw35swsrboxx63oo7nnhu1p83ravvppjetds:latest/lr1e-5_r16_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://yzpm5effsd0w7h8qqzrqbspw66kbydt1w552ftrh2txxvu5sfaska8glr5g5omobe33u9xelv30iwotklz61bg0pqhhdjiv3wnr38nk8xtn67xfe63qnqmrynjtt8j93/lr1e-5_r16_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-5_r16_lora_8B/mcq_4_choices/predictions_42_38705556aa61b28d7b2b.table.json', 'sha256': '38705556aa61b28d7b2bbd0b5940e94d3b19bb90206ab0612816c90e92c1507e', 'size': 34050186}, 'lr1e-5_r16_lora_8B/mcq_4_choices/total': 1655, 'lr1e-5_r1_lora_8B/mcq_4_choices/accuracy': 0.27069486404833837, 'lr1e-5_r1_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://22lm4i08gkjxi0maxpp29yqjg94muu04x8tytupy3a4r21cscns7ltdmfzhuyqng31xr0knz454y8x9lkr0mj4wwm0hadjrye9b4l3r4fe8ltnf3ghndzj7ee2xmwru8:latest/lr1e-5_r1_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://h702w3s40aktmjgr8yk9grr3d0hhxtnez3cp0qsj9dfl2x17c1etde9a87udk3x8itueylqjmjnhfa6jrne8bw20v0i05yf9p5bw8pqg494b21vkg6zyg0xixouni9v0/lr1e-5_r1_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 14, 'path': 'media/table/lr1e-5_r1_lora_8B/mcq_4_choices/classification_report_45_6d16761dcd35639aba63.table.json', 'sha256': '6d16761dcd35639aba63715295985cb808589a2d00273c36b229516e993e7feb', 'size': 767}, 'lr1e-5_r1_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://3c7ortvfpnmad7vaae5cwfkkekqduqjpryxcgqt2miblyyfcsuu3pym5r1lvhem7ojqlpium65z56a1icdv3hiqb3maarnr0t6izypnx822y0eu70q4x56rach2dkuf8:latest/lr1e-5_r1_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://sjatirlajq6gudckvqtoic5igolvkk15dmegt4xtuqbaeyvp5i477k9iof5buwv5al3tl44fmvvb7dhvn9xbyg6pbtlwco3nlssmxel3spdhq2q9tdcbnshgdd7m4r4o/lr1e-5_r1_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 144, 'path': 'media/table/lr1e-5_r1_lora_8B/mcq_4_choices/confusion_matrix_table_44_b6d8f97db7cb1b14f2d6.table.json', 'sha256': 'b6d8f97db7cb1b14f2d669ed8b4b6b6a4e4470d5ea1968b5742a10df66e751d1', 'size': 2609}, 'lr1e-5_r1_lora_8B/mcq_4_choices/correct': 448, 'lr1e-5_r1_lora_8B/mcq_4_choices/generation_time': 772.3496537208557, 'lr1e-5_r1_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://ncmlq3nbhuv6nws68dv2bnj6cigm1yq5z0v686b0b9jihfjhcx2rz2stkgi1m91km7u7moochmq3189qq6lbhd5eqc0yhltbtwf1wsp4ev4kub8qc0cqqvc22j9er2fp:latest/lr1e-5_r1_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://5bcxd8vkxe1zgrcumuvvv0dk9dmhn8bsq3vjfq3z3o0lkrtpmys2ufqg6mf16l55pfzjgev8b606eocxvvlsb43pail4ir06mxlvl57467xy0jxx1hlg0hq4vtxjeif7/lr1e-5_r1_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 12, 'path': 'media/table/lr1e-5_r1_lora_8B/mcq_4_choices/pred_distribution_44_438a6f68b3cc34d6718f.table.json', 'sha256': '438a6f68b3cc34d6718f6b9aafb84bc5154b5c996d1e0e2532eb0e9f9909a396', 'size': 173}, 'lr1e-5_r1_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://r6a92ahwgojzw6gji0t5psvxm69ar28t5f5h9rogriuj3u5jzximbap7wbnoq9e0yq8yiycpqrj5awrv3w7y8xtvu3r07vhy3y85yhwb6xjl7ffoq9gdrm7zy8d4y6l4:latest/lr1e-5_r1_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://g3t2kymmemhvjnsddgq2fd9yuj64auqrr7zb7m6ko9pnguoxmczvw1mzk528080n5arky93iqduv4q9dlliesl6j0d0h0m0bqx5od0iv0snzlb04xwmly4224d8rwq6j/lr1e-5_r1_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-5_r1_lora_8B/mcq_4_choices/predictions_44_421c5b0476f434bd701b.table.json', 'sha256': '421c5b0476f434bd701b7b5ee0d6e26340344b306dd8f6439b624c8d8d9d83b1', 'size': 33858951}, 'lr1e-5_r1_lora_8B/mcq_4_choices/total': 1655, 'lr1e-5_r256_lora_8B/mcq_4_choices/accuracy': 0.27492447129909364, 'lr1e-5_r256_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://t06axxxa5faeo9swetslmp1i3hr4l7vew8wmgvg1bwrd98amry6pz8g5k2dz9qir25cpd5a1p4j8wyzmpcdyv4day2wr65vdp5hv9l231xd1mopphhe14zcbheppnl57:latest/lr1e-5_r256_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://0mgoqol3vwezbny1riysx9vs2inz4ubb7h4fh8ar45q50dhb6zi46txt8vv5wq0rc1qbjf60cvzl6w43kdmhcxgar0m6jk6kzc3bvu0y7gzjjdm8jcihur1tk7ezavmz/lr1e-5_r256_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 17, 'path': 'media/table/lr1e-5_r256_lora_8B/mcq_4_choices/classification_report_47_e12b6074eaae9d28d75b.table.json', 'sha256': 'e12b6074eaae9d28d75b794bdc43c9527958b7a2408dcdef9cfb7d38ebc67c40', 'size': 844}, 'lr1e-5_r256_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://wec00xpgt6p8bqh5dw7fulbdapnhh9ocytrrmhl5jyt85o56rq9pd1xsh4umhisi7ttfughbne7ihitmc4iq4z7zkfipdx3hirlsisqdkjeu06qsg4u9t1xbucg7f6hf:latest/lr1e-5_r256_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://8ufi1apine193dfo2cfefwmui98er4gh6blzz25eowut0idx6drrkyxrqlya0j0dxlf8k60cd2l7w1srag9iyw1wrdfvoz5kjz3bcao16misrgz9s37jhjrei31nleu6/lr1e-5_r256_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 225, 'path': 'media/table/lr1e-5_r256_lora_8B/mcq_4_choices/confusion_matrix_table_46_152da0fec18ee27cb64e.table.json', 'sha256': '152da0fec18ee27cb64e832d551d01def13f57979d5a09e8d16e958c772c3933', 'size': 4006}, 'lr1e-5_r256_lora_8B/mcq_4_choices/correct': 455, 'lr1e-5_r256_lora_8B/mcq_4_choices/generation_time': 766.445422410965, 'lr1e-5_r256_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://zqd7xw86zo2n86gmca73xe2bku0l2cafb7tbfgcr4hsj724aao6jol99kop0l2mxdj62v3nxa9423b6cpncctjkf26lirk792khai5n1280zwb9egun02kgps2w6wf03:latest/lr1e-5_r256_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ux0s6oudlh3esuz1k65jv3tv9izzezer3buhm4vg25f2eidtb56kjo0ubpotpesup96fqich6pgj5f5cf0dk25lm0f7rmg6gruxwg97kgewvq0sw6192p48zrtyn2hic/lr1e-5_r256_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 15, 'path': 'media/table/lr1e-5_r256_lora_8B/mcq_4_choices/pred_distribution_46_c7f8dadfb9b4f2ac7791.table.json', 'sha256': 'c7f8dadfb9b4f2ac7791fc3b8f12d5e6a37b0af7d3cd3b912a4c1ad485aa71f6', 'size': 202}, 'lr1e-5_r256_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://pihmelvek886mpx3gotl8ql2vufhiwtzz50xixsheoydtpidnrluyk7t484g7nn6n7lplfdzym79kwdesystj1bm0l73jlfozlyfz5ura3q14wswvntgrf8a7if0hqct:latest/lr1e-5_r256_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://s8qhcljxvln1ocfhvo23nn8rqke3es2i28no9m1yup095zxuox7332qvn4c4pr4sbvbvuqyj0701qbg6y3zzviorijkgaso0alitwr92agogdj1iwtvawl4ju75n48am/lr1e-5_r256_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-5_r256_lora_8B/mcq_4_choices/predictions_46_b8e5ec09bd20363e2096.table.json', 'sha256': 'b8e5ec09bd20363e20967a386343fccf748047ff74d03b4ebbd0179fced0b034', 'size': 33993607}, 'lr1e-5_r256_lora_8B/mcq_4_choices/total': 1655, 'lr1e-5_r2_lora_8B/mcq_4_choices/accuracy': 0.2797583081570997, 'lr1e-5_r2_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://k46hr2ukd2c6a92e0nezar8m1qszu5v73yw9lklqqajdvtb4936cwyrptoxoykutnbqd19a1y2dluosugrdeslticjr1c65jxizixod5r79yboyaqzav21qh1y1ma7vv:latest/lr1e-5_r2_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://vcrm73hp6n7vq2lpfg16l7nkvzf8cv43nez5olwvuke5nn0cewrzw3pr187z98zycwp2ijhor2powfmdqi1o3l436tkh4qg28g5ojzd0o7h7dbywplvaebr59yj1f7am/lr1e-5_r2_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 15, 'path': 'media/table/lr1e-5_r2_lora_8B/mcq_4_choices/classification_report_49_5f31fbe0ad808b47bcbc.table.json', 'sha256': '5f31fbe0ad808b47bcbc46d1ea130b8e484d40784515f371373f09044069a3a5', 'size': 791}, 'lr1e-5_r2_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://52222msjjxo6u610v4o0ogmjiontthtrcn5cw0oejl028mj498xkwoco6qc02swqhqjdozamspo6l47gsjqjaijjetkx6llh65p26wfhpaxtzyx0emo4w9n9xn2ug91l:latest/lr1e-5_r2_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://lfhtnhgiar7kvg0qrqcefivoiyv1vcc41vwzmn4252tb779ceuf7ojp90tgiy8s6mzk3mh1rv9zpxe51uh6ivruuh8mg1phafshmjx88clajhai5v9w2idrjy09xq9dx/lr1e-5_r2_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 169, 'path': 'media/table/lr1e-5_r2_lora_8B/mcq_4_choices/confusion_matrix_table_48_e58725ff122fab902fde.table.json', 'sha256': 'e58725ff122fab902fde39e217707e75f7ebe3c631ba684cfe50247db2d5465f', 'size': 3040}, 'lr1e-5_r2_lora_8B/mcq_4_choices/correct': 463, 'lr1e-5_r2_lora_8B/mcq_4_choices/generation_time': 761.3998401165009, 'lr1e-5_r2_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://i9w0fp65vwnoxdwiqpo42vh41bl57e4lrv5sjigi0uvjimoch4q78mi273qx2kc7sq84a21vumd9m8hq3bopcjgs15o57tl4y6uszp7cf9opj41vi4b9hgbld2sn8wwm:latest/lr1e-5_r2_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://2bdtz3nynn9lfqgtpyvqleh1j73irt79td9oznquh9zfl5gdvyvf9zsr8e97663huvtghlmd38y476go067vhl3pud4j62xhqzy234pv7p230n9pzs867nhjaie58she/lr1e-5_r2_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 13, 'path': 'media/table/lr1e-5_r2_lora_8B/mcq_4_choices/pred_distribution_48_388118c41828e77c85d7.table.json', 'sha256': '388118c41828e77c85d776873fdd07528c296e9f5fb559d16e7b660782a6bb5a', 'size': 183}, 'lr1e-5_r2_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://fe2e88ootrefsqmsip79780mtwcg4mdfnargvw3d6ne4ryajrfgbo12i3ly2rh1r9po6bgdm8uxgderu1z28g2urknpd33y9znlwlc8sx5uzespvi0nrpit1hczry3el:latest/lr1e-5_r2_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://u2zcm3i5iopgj0eb8dcxzif18hniul6cq0ouq222t11fjjstlctob7pf9oen4slgnbrxhqslwrcepxa2kwy1pvl6jpzg24o48vouwplq9d07vjplp0hgxieigwr6mwtj/lr1e-5_r2_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-5_r2_lora_8B/mcq_4_choices/predictions_48_f7fe20a8381f736d8989.table.json', 'sha256': 'f7fe20a8381f736d898933784f92e799b0d1307b1a719b857eaac0cb94917538', 'size': 34106105}, 'lr1e-5_r2_lora_8B/mcq_4_choices/total': 1655, 'lr1e-5_r32_lora_8B/mcq_4_choices/accuracy': 0.2737160120845921, 'lr1e-5_r32_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://0617nmcyvy39lie9vc4yqo1u9onjy1na0ed3x1z6rqzjamlz310p9f92pzbylgg5wiwk80yu5851bqa24dqbnuu5l8g4wdkegchc3w5xck0t94ix61nhv1z2ytlpevcf:latest/lr1e-5_r32_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://0eorafjz2znekh5x9h205semibctkuwbdifajv1rvsuaatqozd01ei81kddjr9xyze11ziyh6vjnauzmha2jznx1wec4re2jjok1lyr24bc7uf6rmv3mvcb74nh29zjn/lr1e-5_r32_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 15, 'path': 'media/table/lr1e-5_r32_lora_8B/mcq_4_choices/classification_report_51_17d1311c6eac959e2858.table.json', 'sha256': '17d1311c6eac959e2858fe3219590ecce7dc3fcfb5670cabd246ea7f7e9743b9', 'size': 792}, 'lr1e-5_r32_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://ow82uftgf62laxjp63q9bqrmuzrdu191xrs25xtknla5sq5wmnf9ph32d4argmoxnbt6pyg71mudthgx4tqh2s1gvgxq41idzs0gkqfonezv9ecwh65xq0svys557wqr:latest/lr1e-5_r32_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://sudjb8d5ppt61gc8xos68bgv95my2qk24fbtwrhx0ixzmnq5etde3mpzv6ntvs60uy2fmh78ru7tduto45jscwqknktfry60j198d2gkbuwjg8jbavs6fcgln8fd5xgi/lr1e-5_r32_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 169, 'path': 'media/table/lr1e-5_r32_lora_8B/mcq_4_choices/confusion_matrix_table_50_13ab01c70e502f1b569e.table.json', 'sha256': '13ab01c70e502f1b569e2fde5c830f7d4b0b14ae70ca28886446a53987573c41', 'size': 3040}, 'lr1e-5_r32_lora_8B/mcq_4_choices/correct': 453, 'lr1e-5_r32_lora_8B/mcq_4_choices/generation_time': 764.8409457206726, 'lr1e-5_r32_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://78b4w089cmevb8wamvcx95sefp80ljc8dze3499vx7mqktm7xmf0o351bos36dxsvcxsdh1llm9e528v4jz5xwiavhce89ldllxa7e59dotb6tkxgydbh6efdqz7dxwc:latest/lr1e-5_r32_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://d16xee3y0twrz6rrv1fjtgic8aqgz5qrvpihro19swrcsi7mmecsxofqwifyn27cptrxuy8ewsfuj104nq8tfy0yxxlj4pbkk7xaauyh090njuum03w5p9593f5klrns/lr1e-5_r32_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 13, 'path': 'media/table/lr1e-5_r32_lora_8B/mcq_4_choices/pred_distribution_50_4ad6098c6e3c2c3ddc4f.table.json', 'sha256': '4ad6098c6e3c2c3ddc4fdd409c45d45d73ee5436b4e788dd49f88dca3a004f42', 'size': 182}, 'lr1e-5_r32_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://9tfi3eok5t7qwozrpa4ct1n1icyzaf7fb0vl4hvo6f6k1wjzle1r5c8qxn8ntfiu3dmrlq2jmbm30t0vn750toxr53etchod5sjpwwv7nsypd3j3gemzkz2ms5rid8xx:latest/lr1e-5_r32_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://z5m05eil3cuir6qqkytn9zaxf0sc5op92uw02epnxvpc8v2jbgkur73ob403myerqkbhxusqyosag3oz8g8hm71d83go1o25ubr7imwthfik2zw60j4janr1ibitztjo/lr1e-5_r32_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-5_r32_lora_8B/mcq_4_choices/predictions_50_42055d80c936ce8e2f32.table.json', 'sha256': '42055d80c936ce8e2f3265a6d5854a4b1c1cdf0be71e52fa4256c4dbe42bf9e4', 'size': 33962493}, 'lr1e-5_r32_lora_8B/mcq_4_choices/total': 1655, 'lr1e-5_r4_lora_8B/mcq_4_choices/accuracy': 0.26163141993957706, 'lr1e-5_r4_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://7aumhek4kq9uplwva758xhlrdejmlvpf3v4vfiq70qp8xpszptnnw0uigtxrpilyovfbepnj7isecprem21sgrtlxt34bpq4ihk50agqxvw1hoht04z261dhbun6go5e:latest/lr1e-5_r4_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ve0cys572rhde2o8wugvwu89hs9uexk612f2qmttsmf0np3vfulk0kaztgkw0pvo2g2jnxpy67r749laxjlgxgor4nrjwy8q75ndjlpjgz3uxbrzpafb04ldlomhy3ul/lr1e-5_r4_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 16, 'path': 'media/table/lr1e-5_r4_lora_8B/mcq_4_choices/classification_report_53_49e3f896fd20ac53241c.table.json', 'sha256': '49e3f896fd20ac53241ce1fafb7142108d001cab976d683b510d5c209d55af3c', 'size': 821}, 'lr1e-5_r4_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://ew1irlr8eg2gkag6a7k8oq7rw8gmzlw09cdznjnpofqivuolcedga7t5wmwvgd0uvq01vhjts6kzgajz1cgi7e3mx0rl24u0k4dnx3jbt19rmibr5d9kqz90l5puqn5k:latest/lr1e-5_r4_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://8qchs3z1y353fbng80qe5eek4rtcco0dcuv9dhjrsendoelui3lmtaz24iijs7twgqcc48c19shb8tq564p89j86vh8xifyhb0g29gwi5lxl52shgbhd38o8ob3u975h/lr1e-5_r4_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 196, 'path': 'media/table/lr1e-5_r4_lora_8B/mcq_4_choices/confusion_matrix_table_52_52ce1fc5e085d22b0714.table.json', 'sha256': '52ce1fc5e085d22b0714a97ff6612f067afc53a4e10b495d3b5c4eafa4c6601c', 'size': 3506}, 'lr1e-5_r4_lora_8B/mcq_4_choices/correct': 433, 'lr1e-5_r4_lora_8B/mcq_4_choices/generation_time': 757.5914783477783, 'lr1e-5_r4_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://bl9ne7oyba3cvytd70cxkrcdx8scyjah3vq4xwr9zkvxlbqyn437nh3mxzctznp13a91pniilqbutwy8zbeye4ap2m29rm0o9epkg0hgiih8rif9quss4jggzofrftnn:latest/lr1e-5_r4_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://54jk0g8zbb6mo6limm5vkhtn1nd920rpiqvt1estukfsm289xq2phwru8z4wehuic6sk3f3582zp9rqjuj5im4y86dw1qhm0082vzb7d5p3dkv61hf3v04u0otvxe1gl/lr1e-5_r4_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 14, 'path': 'media/table/lr1e-5_r4_lora_8B/mcq_4_choices/pred_distribution_52_3e85b146f820e928c0b7.table.json', 'sha256': '3e85b146f820e928c0b749be104db8665a206f968c696843d0abca578272e26c', 'size': 192}, 'lr1e-5_r4_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://8per5nl996xqy6aleot60trxybhlaxwm1ibk008xh8e5zd05n927bdboldqwesxceja5w8l8pitx6hwh43ttrjiasopiqws230nljwkpotsy3rg4wj6di3g4pusgd4js:latest/lr1e-5_r4_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ytjv0raw9t1pc9xmubjj6c6v1wyv1sr98rc7pgwdztcf0eusl7n6jbzbcoi3x8cavjccd316u0g8ol5wz3pohhy35clpeqd86h33relmwhz0runozv4wk1ov1xcbl6k4/lr1e-5_r4_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-5_r4_lora_8B/mcq_4_choices/predictions_52_e69f4c41b6bd2f89122b.table.json', 'sha256': 'e69f4c41b6bd2f89122bec1b4b4dc084f1f980711e471adcca5d5d7e63c488bb', 'size': 33966600}, 'lr1e-5_r4_lora_8B/mcq_4_choices/total': 1655, 'lr1e-5_r512_lora_8B/mcq_4_choices/accuracy': 0.27069486404833837, 'lr1e-5_r512_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://anq043nlj0k41x2bte7w6r4lo4sutv2wgiogttu90v03z1pxeyyg5ucb7enjtkjghe2z0d257jmb328j4luxeb6ndtgo0derxn64gg5lypqvfafbpnkg59cgk452wugz:latest/lr1e-5_r512_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://a36q11lfca8rljr5dgqxu26nkmyxla7cwmgs1wkpo38l5io737jpugtiefsewdh5ky2zia0g23pwbnr5azxw8sja3pim9dfsqnidak3m8viq8vqgplyfbqgbsollkuzk/lr1e-5_r512_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 15, 'path': 'media/table/lr1e-5_r512_lora_8B/mcq_4_choices/classification_report_55_0de352aad5ae0272f5fa.table.json', 'sha256': '0de352aad5ae0272f5fab58a0b7ae52972b6717dabaf289d5cbdec6981a3f564', 'size': 792}, 'lr1e-5_r512_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://ft7gwwiy6la5aylcqf4iv00rafq858tv1ax4aanf4fe9hwzcombz7vlvq50f9ofyo4uff32egh0k4z6eqpyh32x4qdaw3rtor147uz4q81jgc6j3j4fubsdcohfehwjr:latest/lr1e-5_r512_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://kfg46f1q3kp8prcd5iklc9q7oerbc05xughcukpocdut79u2t9hopwdg7zujs4lc6vtqpkjzqn87kfamc0eemfynpoa604beptzehturhsl3702nb5usw9pp8sw09zw0/lr1e-5_r512_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 169, 'path': 'media/table/lr1e-5_r512_lora_8B/mcq_4_choices/confusion_matrix_table_54_8b1378736b094166e25b.table.json', 'sha256': '8b1378736b094166e25bb3432f856e8c7ae8c90fb9d7c3329b7c540444d36897', 'size': 3040}, 'lr1e-5_r512_lora_8B/mcq_4_choices/correct': 448, 'lr1e-5_r512_lora_8B/mcq_4_choices/generation_time': 775.7822926044464, 'lr1e-5_r512_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://4w9yjhlqcgkovtsaioq09d0effedqvjxrp7kxxa0io3haq4y2uy2bq0q96rtvs5a58w4m4rqelbzckrwl8w314m3itw70ko9kg106afhsjb3023tedstc83itbonkjo7:latest/lr1e-5_r512_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ryc7qmtv5gjs1dtsdtbdbyst0p2ts2a15tlumjomwyzs0zjfk03sltp28rqnnu11qhk1fyti6fh9uj2o3pw1qjfcbj1u0ucwbnj7p76otrb9hofd5u0rou9byz0iqy34/lr1e-5_r512_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 13, 'path': 'media/table/lr1e-5_r512_lora_8B/mcq_4_choices/pred_distribution_54_db92999d8acd07e94f6d.table.json', 'sha256': 'db92999d8acd07e94f6d11aa18a6a3745800d0a6c45c1c4d37b92a8770fc7853', 'size': 182}, 'lr1e-5_r512_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://2gr7fn65frkfyykrilu9btmy9zmk7ir4ro275fknzgt04h0wri2eiff2djdnzi7d2n3jil0sbbrt9tplk83n6r5pdks714un39ov3e3uy2iki9y0i2mt6lhenis79l15:latest/lr1e-5_r512_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://tuush3nsneucnf32biivwof33h095ldylmb9gnkvl0nw06x9spqxjgit2a9zs5c4nl5j011jrykc3r8pe3es1nbos9am35w7b8vt8r7dq0bnvkj27lp5sbdtvhfhmmmy/lr1e-5_r512_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-5_r512_lora_8B/mcq_4_choices/predictions_54_71b1cc964df752fb561b.table.json', 'sha256': '71b1cc964df752fb561b31f3af9795d47b364a779057ad56b77fa4f39f09816b', 'size': 33822709}, 'lr1e-5_r512_lora_8B/mcq_4_choices/total': 1655, 'lr1e-5_r64_lora_8B/mcq_4_choices/accuracy': 0.27069486404833837, 'lr1e-5_r64_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://9yq0rsabtx47wvic7y6myqrpo7junj6vlnvqjvj79li1fsnzwqyc2ozwtmoz1xd98jb6q1a1616bowjdb8bjew9nr2t4x83urm68bd68p3guruqmd255e5c25ucxrs06:latest/lr1e-5_r64_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://5ktrlhbatt3khuzq1oofugyu6ofav7lfiizk83tw2hjnnnvet0v0wmov17mz0ylch6wwaqi60984zs044jlqvlq1lwpfdzgfo9ubha41at1dlmsllx2c1wj241ifo9ng/lr1e-5_r64_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 17, 'path': 'media/table/lr1e-5_r64_lora_8B/mcq_4_choices/classification_report_57_4f8a11476386069e2824.table.json', 'sha256': '4f8a11476386069e2824f918e43821bcef714740a9ad13f4754f106099a83dea', 'size': 836}, 'lr1e-5_r64_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://qmckhtfc4thrm019luak2usuhrwek8d3eph1w9opourlfc7swyvzxlubbkugoyv2mx56mxaajn5ttp50iunm94pkkc3j2ppy7sw5wa0yt56r6kynyrxvkpgjep0xcx2f:latest/lr1e-5_r64_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://mvhr91rnlgrd8m4654eq6br03vyg4jeu1x1txdffzlkyliavvbg2nglmhibmy6nh7tmq2g74zxnl66ubtyp29vfi5yl974h0f4ua9e6iixt0wy886al7acayp1wcq1ev/lr1e-5_r64_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 225, 'path': 'media/table/lr1e-5_r64_lora_8B/mcq_4_choices/confusion_matrix_table_56_a4db2b3faa8007d40b0b.table.json', 'sha256': 'a4db2b3faa8007d40b0bdd8589591b4d2a9b2c4c07e441fcec8a6bb273363341', 'size': 4005}, 'lr1e-5_r64_lora_8B/mcq_4_choices/correct': 448, 'lr1e-5_r64_lora_8B/mcq_4_choices/generation_time': 771.0563411712646, 'lr1e-5_r64_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://byffoyauvfi6mepwawrjo8mxank6hccicgkco5y3ir0uj73v3xmsi2g1p4a7om5mku66l9rkthdeq1uzsqa67h6q858mseji9cy23kckh0oaykulym955x3h9ldtubk3:latest/lr1e-5_r64_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://plc4n9qchxd4h7eo1gv1nmm50nmndyc850t2d7al1v36icu0x4zxw2hrr6myo653r8lawb0enjcpma59gw1ty0nd23r3tc8nc8piawu8nenlarhqf7ex69zippzrpqod/lr1e-5_r64_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 15, 'path': 'media/table/lr1e-5_r64_lora_8B/mcq_4_choices/pred_distribution_56_1d4ecec30d693dd3ad01.table.json', 'sha256': '1d4ecec30d693dd3ad010878e39812c02bb1ebc7339c03908a16e15a536caabd', 'size': 202}, 'lr1e-5_r64_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://ti6h88uoppu5x83hojppzui0jul3geqz4p0w5ah2zrwzhcql5k8ou4d8wyg4q9gw301hdpkuvpfaiu3zk85fb73siyakx297ei49t12mcrt7e9rqpuu9g87t5o3b7x4u:latest/lr1e-5_r64_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://4lug2xu6xqmtedijkfdmt202z36ix1c1vdpcza0mrps1x0p8655eritre5ssqwnmtpt3wpsd66m0xshgvu33uhrrsteuqe1nxcbk2nnhiykc9ne0xoejy76mcvptb1cg/lr1e-5_r64_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-5_r64_lora_8B/mcq_4_choices/predictions_56_2c915d0e9921f6ae4cdc.table.json', 'sha256': '2c915d0e9921f6ae4cdc83a8b6853f30ab3e0d0f98dc3a957c55805fabfcf27e', 'size': 33980845}, 'lr1e-5_r64_lora_8B/mcq_4_choices/total': 1655, 'lr1e-5_r8_lora_8B/mcq_4_choices/accuracy': 0.2598187311178248, 'lr1e-5_r8_lora_8B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://9vsnhmqj4tg6d9cfsvzcg0x5qwgqnkpricviun2zt8r4b44d30002tlnxvfd6arxazdfc90n0qxz87hqu67sxl6aeosqee6k9v3648g4t61qnb7vniylkctfk97vb19d:latest/lr1e-5_r8_lora_8B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://glmr865c6ex423cdmgbpvha25p765hcpis8fxjmvo0cpyqf6ui6oz7nj4uitg14b68q9zotbe7ak3kz24lt8br8ltta8r8czwulbvp68oagqwvjkjcss59tmr302p2hw/lr1e-5_r8_lora_8B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 17, 'path': 'media/table/lr1e-5_r8_lora_8B/mcq_4_choices/classification_report_59_627d4fa392b75c1114c4.table.json', 'sha256': '627d4fa392b75c1114c4d481829a7971534e56ad87ae8cd394bdafc58504f7f2', 'size': 836}, 'lr1e-5_r8_lora_8B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://vt4lawm5fv4rnijm9z6j1iqvsarscbaziqow9jv8h8nsa97giksndoy5d10k78g8bqe7eqgvps9o7qcq1uzy9w8zhxfrz5ar0gg9od9xjdavb1yqruncfqonsnun143j:latest/lr1e-5_r8_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://r7n2y2k55kwjlmlzt9zo0nc6gngjkr69nsiydjomkahcqz43eqnz1q5wlp80m3k2sxh0gmwq7ene23olv28ssu07x8ncs7ygpk7p1hs2cgfqh6l549p5iyc8mudcqxyj/lr1e-5_r8_lora_8B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 225, 'path': 'media/table/lr1e-5_r8_lora_8B/mcq_4_choices/confusion_matrix_table_58_91407a9b5916a0c6dd2d.table.json', 'sha256': '91407a9b5916a0c6dd2d482654c48ce9ffe6a5a9c7b60bbb8c480a8dfa33aea9', 'size': 4005}, 'lr1e-5_r8_lora_8B/mcq_4_choices/correct': 430, 'lr1e-5_r8_lora_8B/mcq_4_choices/generation_time': 768.2191293239594, 'lr1e-5_r8_lora_8B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://u0xedd9cy471h1q00l8bx44c84wec6wj87kppsbpsbv325hfzpe1kgmbji4iilebw71kxhqyuhqmnt9lmw4k2scwm1awq9lbr2lhoyvce2sqyaqzz2vg73vv607y2jyb:latest/lr1e-5_r8_lora_8B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://4oxwpf9cbosqm7xhkzkhlg6wkn1r3vjusb98hliwv0w3ib16s2f89q1v7idxowukmzooqgs69b5gebgae1vuehfsnadteup2dq3uhbn4gtmk3hcmqpxif2t9z4ng76tz/lr1e-5_r8_lora_8B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 15, 'path': 'media/table/lr1e-5_r8_lora_8B/mcq_4_choices/pred_distribution_58_c0ff002a87ed09337e01.table.json', 'sha256': 'c0ff002a87ed09337e0128be6f7b1e69fcbe22cf732327302b303319a6e03ecf', 'size': 204}, 'lr1e-5_r8_lora_8B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://7t3zu8nr6n0tbwzq544np4wavbehwhsy3vig94l5kumepgrl48tbahzrrk6cwjn1g5t0rkmyw2v9yh7s4dvzd33d95eriil7ozk34hhnlw2gyiuyogj7dabwx88dk7nn:latest/lr1e-5_r8_lora_8B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://qkxejhvzrjsy7ilmbynj3bcwxrffkv7zdlvlknj88kgwlk2x29aww2w25rzscvypiq0jovan8qtk4l74nwdsixqoh0q1t3zwwean0jakmc3dv9mgsvzfebd771tbddum/lr1e-5_r8_lora_8B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-5_r8_lora_8B/mcq_4_choices/predictions_58_dd3e9c2e3141856470fa.table.json', 'sha256': 'dd3e9c2e3141856470fa3dc3ac2326e0aff6638fe43b6631334d396c6996569a', 'size': 33694325}, 'lr1e-5_r8_lora_8B/mcq_4_choices/total': 1655, 'results_table': {'_latest_artifact_path': 'wandb-client-artifact://3xjkp2qej1smm1i83fa5iwjrzsjaerwc9151jh7pnbj2nk5exa97uwyfcmaq1qu0onrwetdcqtzbagq6vjqt6qfdt13lth9u5w8uejyz6yw0k64g697epxmba5zjowyj:latest/results_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ip0qhqv9fd7snelskbi9t67zzig41eyu3ejlrpuriq7jjx1sr883l83c4ayz0u7lor0z2fmzfd8ukd6pus58xmh5fpzcslzh5g1ftv1mdc3z8fow1wg6kfbbzsa4s88s/results_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 6, 'nrows': 30, 'path': 'media/table/results_table_60_9f4c650add028a9515fe.table.json', 'sha256': '9f4c650add028a9515fe363a2f33a6c4f8a327b712139df27ad6a86031b95954', 'size': 2815}}"
grid_70B_lora_lr1e-4_checkpoint-467_2025-12-18_19-04-38,qqduvpkg,finished,2025-12-18T18:04:40Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'name': 'Apertus-70B-Instruct', 'entity': 'lsaie-peft-apertus', 'project': 'LEXam-Evaluation'}, 'is_lora': True, 'subsets': ['mcq_4_choices'], 'grid_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/results/grid_70B_lora_lr1e-4', 'model_id': 'swiss-ai/Apertus-70B-Instruct-2509', 'base_model': 'swiss-ai/Apertus-70B-Instruct-2509', 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'checkpoint_name': 'checkpoint-467', 'num_checkpoints': 4, 'match_choice_regex': '###([A-Z]+)###', 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 8455, '_step': 8, '_timestamp': 1766089536.9270546, '_wandb': {'runtime': 8455}, 'lr1e-4_r16_lora_70B/mcq_4_choices/accuracy': 0.2821752265861027, 'lr1e-4_r16_lora_70B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://utkh2k6cwnkd4ltfhpwo3cs6xy2n24epmbz6bqj858dozpyrqx51mwso63fqhzab6t6ejz6cc65lgrpv6uchxb9nv66ztuvibx89b59qbrx0eeepwjql4ex7ca3i29p2:latest/lr1e-4_r16_lora_70B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://0vfmfun8lft2ch3zx2sd775alsjjpiww3oakkaz47fg0nbgqscptn5mlpjilxu9ly3eulbnzqcilacpcloahukc0u580om57gknogmy50owwik9y3v3ltlvhehb89qqx/lr1e-4_r16_lora_70B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-4_r16_lora_70B/mcq_4_choices/classification_report_1_813318c72c28af9e8188.table.json', 'sha256': '813318c72c28af9e81888e5f304d32f4243d189459994aec05b80d39bccd0204', 'size': 561}, 'lr1e-4_r16_lora_70B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://vk02587y7m557an0hudwo0j2b4ppjafhe6eubr8d7urw4lsdrq7biyig1ydu41cmz9x4p4o1fdcxjr62oml1dgwr92j1u0i7pcn703zfcazufeuuoqz41acvznvfmzgp:latest/lr1e-4_r16_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://mf4yvu05f31ue5242yag81g1lfc5bypr7bz97fih6okcyelfkxe19x7wzfpx172td8y0b9nz4rsuoquy9ivqutbs8mojgyd464yhm68uhwyxiemr8w04uo3ar14ke8i9/lr1e-4_r16_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-4_r16_lora_70B/mcq_4_choices/confusion_matrix_table_0_97366264b355218deead.table.json', 'sha256': '97366264b355218deead78845ebb834a0b3c41ebf9d17664c063a0da563569bd', 'size': 534}, 'lr1e-4_r16_lora_70B/mcq_4_choices/correct': 467, 'lr1e-4_r16_lora_70B/mcq_4_choices/generation_time': 1347.4365980625153, 'lr1e-4_r16_lora_70B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://7wddb93h30qce5v3v2sz7rtuw3l3bj2wbve099b966ihmf4cwj0cdiv44oo48q02i0louey58hmpdm4lwr5nrk67i53ttl4p205k0d9xu4uxt8p4io8c7lzbmg7pweoi:latest/lr1e-4_r16_lora_70B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://c5xhnrkviqealbi04kkyyoahn2d8h4sqg84hkdg197bo4ksrbw456vfwjciqnnycwvzgbexee0g72h87hgmhs5zag0n63c1sw7xau69s9ob1tki354w508okai333j78/lr1e-4_r16_lora_70B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 5, 'path': 'media/table/lr1e-4_r16_lora_70B/mcq_4_choices/pred_distribution_0_2275857062a2d5a242df.table.json', 'sha256': '2275857062a2d5a242df4a5babb906ec7290104a8cc3fb0ace1e32705a1c57f3', 'size': 101}, 'lr1e-4_r16_lora_70B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://x9cxn1y968ivykxq5l10o0pmykhghxx3zvsgqlurw5vcrlj3mag3pgybr3jbt0qppfli3tlse5ajyw0qiuc7djrq36zixh6cp3uvunaqpzfjsrwxmlvqncfvtwqwuiwa:latest/lr1e-4_r16_lora_70B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://lqhhwsrr43ijkaok4fwjwywp608pt3i092sansar2kikzsxesz51qt4y7lfsb95fitoybcwhtkvgb5y7dyny0mzpcjjw42ocwlojq7ks5am1iy85vc1snfcu0gag5osm/lr1e-4_r16_lora_70B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-4_r16_lora_70B/mcq_4_choices/predictions_0_0ead5a987777b82bce23.table.json', 'sha256': '0ead5a987777b82bce2368eed3a08e30501341daaedb4f05a7ea0974db6ad952', 'size': 13642412}, 'lr1e-4_r16_lora_70B/mcq_4_choices/total': 1655, 'lr1e-4_r1_lora_70B/mcq_4_choices/accuracy': 0.28882175226586104, 'lr1e-4_r1_lora_70B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://49hx18jjy8981s13up1i74ioec1f21mlcalabaz4gai2jap9u5u57z6itill52mq9k27x1e6ff64o7vv4qwdanfj9dldgxxxwk3fmu52ink838993o2i1opgn7t7wxz0:latest/lr1e-4_r1_lora_70B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://vk9ionqsv7sd1pne5qlgipd9je2ui0g6pmhry5yz65xp3eqr9uh3vhompiq98mw988816097pz72r103i278yqxdg16pocw65zi9fmv5jwfqzxdgycp3ewswoxqmbpcr/lr1e-4_r1_lora_70B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-4_r1_lora_70B/mcq_4_choices/classification_report_3_d63a8e75dd4181c04001.table.json', 'sha256': 'd63a8e75dd4181c040014d95ddf5d9cd648f84410ae435d56bc8bfb710436de2', 'size': 549}, 'lr1e-4_r1_lora_70B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://v2f7hnkisyo73ffys3xrfa9oeu3uv31ndbzu7n3msv30d5qoxtzhuo1azdka0nhsrva2rod6133wzgesd06zd9kzcygqxp9x32kuzejm9fwdh0hz5wz0suk1cx70jgjp:latest/lr1e-4_r1_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://96ofq9opuqr4jk2wc7uhwoh7b691kesv1mnalq4afl5hxqpdqkab2c1yxdfktct3bevvvu2m23h5gcjixwc5ksnd6sm3jjkflqnzfgw3wsiw914cj7gdlsq7qfzhw83a/lr1e-4_r1_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-4_r1_lora_70B/mcq_4_choices/confusion_matrix_table_2_5effcb9138af49dba909.table.json', 'sha256': '5effcb9138af49dba909c350286882428447121694c3a7aab801a8b19ff2bbc8', 'size': 537}, 'lr1e-4_r1_lora_70B/mcq_4_choices/correct': 478, 'lr1e-4_r1_lora_70B/mcq_4_choices/generation_time': 3280.2507967948914, 'lr1e-4_r1_lora_70B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://vresrnhv2lo966mlyf834w2wdcji1xmewlsdo0fdqyydn6d4nxcdmtby2fbsronx0xcq0uekkneuppxzcurknydhc6d0xig46rczcs2v7qz7k7mnshm62y39c54cwkmy:latest/lr1e-4_r1_lora_70B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://pj43mr9d2zs16ev30ul7oytza5v9tpuh14lxwuu9wprsw93qbd8qyhhfoyyz6s6i004tcfdbry7dgbgbm4127ka10jo1rf6dguilhmpxiv0u7rjb5sa5slugwckqjtfe/lr1e-4_r1_lora_70B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 5, 'path': 'media/table/lr1e-4_r1_lora_70B/mcq_4_choices/pred_distribution_2_3ea096f96596f0aee2f3.table.json', 'sha256': '3ea096f96596f0aee2f3d5428547e46d68e7a6b03121402227223b72cb3eb9a2', 'size': 101}, 'lr1e-4_r1_lora_70B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://zbjmjicy0l3pmc8hixw06jpru12x69nmuam8q5r2xiaw6hlozd5g0m6akeqs1okjoymtlajrujcibr6rmf7dygemomhk4u6jo143medm7uv6n0fr9c3gum68wtx3r9ig:latest/lr1e-4_r1_lora_70B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://int3oia9vb7izrp5c98m9trso1ibi22homtr1247l5lmcje1yspo3c34srr2dlwuuqmp5gci68ngpcensrepspmld5roc9brdl8m1pyhiy55gbdsj1bfknccyj3rb6j2/lr1e-4_r1_lora_70B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-4_r1_lora_70B/mcq_4_choices/predictions_2_d83fd5d81a63e62b13ff.table.json', 'sha256': 'd83fd5d81a63e62b13ffdb8735311cf8549982539631227da459852fec77b11a', 'size': 26898973}, 'lr1e-4_r1_lora_70B/mcq_4_choices/total': 1655, 'lr1e-4_r512_lora_70B/mcq_4_choices/accuracy': 0.283987915407855, 'lr1e-4_r512_lora_70B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://clxnebumi57rgdtrholimlrotpzrchqz538pai76hj28alwn9bfdf2uumt4pmd7svstl4m5yil492p0kxipt15xi5aiokkuniof72y2rd6h9qc6ds64gsn9sobd8ggya:latest/lr1e-4_r512_lora_70B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ng94bxahwd6nwbbebcvz1zp4qzkhqxt0bu1bdb8qjvtnhvcjuid176383hv6mqgywveakhh6umkt5zf79r2o62yijsmr8b09hh9cmxbvfi3we35ocvu6mgjw1op13kg1/lr1e-4_r512_lora_70B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-4_r512_lora_70B/mcq_4_choices/classification_report_5_78fa5adfc3861965f10a.table.json', 'sha256': '78fa5adfc3861965f10a71a499cfeae8dabb46318866fef6ac74259e1083be7e', 'size': 549}, 'lr1e-4_r512_lora_70B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://8tw50tm1dkww3x7szanpqu1qq4uap80ut6s078qten5ep4osei2k1zdecgixibpzq08y7gqbjihdse4i2qcecpad74uhz8re471bbm2fnntdtbgku1p7ygu10vi2rgbq:latest/lr1e-4_r512_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://rylkkmnk4zmevnjp7hzia8wr70fj5tb4ts51y3jtbrlvboxwx3pxsu914rydfzehyrnkdppxvz9px37slr9v34d7uey459zg338zpy2epyfn0ktm497ruyb9phm6bjpg/lr1e-4_r512_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-4_r512_lora_70B/mcq_4_choices/confusion_matrix_table_4_60ba26436e4b4e87338d.table.json', 'sha256': '60ba26436e4b4e87338d437ee0435f05845af3ec8d853a0a21130ae954cef4a7', 'size': 533}, 'lr1e-4_r512_lora_70B/mcq_4_choices/correct': 470, 'lr1e-4_r512_lora_70B/mcq_4_choices/generation_time': 1795.0530898571014, 'lr1e-4_r512_lora_70B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://ipluol4ttzc8446980gmr0iiv98stwyh4rszdcyrj0nwymw97u9bj5tptqaiwxzehcv3puz3c3a7au45xsw7i68t06ili8ixyrqy34k7za6ytaup5c7lpigrzoch6ax6:latest/lr1e-4_r512_lora_70B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://mjfqd8dtbrvuwmcevj10zrydlgjqp6xlbqdeydpomx1fycazixe5zv6sztvwn6fq13zdq6ubt8gevr3pnspp8zb369pcxx9oodzw5f2xa0s7mtv7a4o7crsnljtgoxvl/lr1e-4_r512_lora_70B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 5, 'path': 'media/table/lr1e-4_r512_lora_70B/mcq_4_choices/pred_distribution_4_47a4aa494fc147eb7f96.table.json', 'sha256': '47a4aa494fc147eb7f963ce0adff48481aad1fdf78f9712aaa534a42f70b9864', 'size': 101}, 'lr1e-4_r512_lora_70B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://22ci28tbxxftny77bkj3cbcvb73783zkdrt0we2sgqpv1lm4b1omewoy1udeam05jf47xwrcrg183kk66m4si5uujtpxvmguapqmkhjp9ya4f1n1wsvaax5t69qq9d0v:latest/lr1e-4_r512_lora_70B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://5o26qz0mxwgu3h6fewc16ubnfuoyc5olvabgowc9qgh42rbrooskxiqh97flcpztq4lqam99wmcn87ypxj6288t6x330a9hjhlkhedrm3bgn5gr93s9xac39yn1z5uik/lr1e-4_r512_lora_70B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-4_r512_lora_70B/mcq_4_choices/predictions_4_5ad84de2ec2b2bbde055.table.json', 'sha256': '5ad84de2ec2b2bbde05589e95fb1584fbee4f0776e5eca9b518577e89c3a3fa2', 'size': 15755578}, 'lr1e-4_r512_lora_70B/mcq_4_choices/total': 1655, 'lr1e-4_r64_lora_70B/mcq_4_choices/accuracy': 0.27794561933534745, 'lr1e-4_r64_lora_70B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://40yzxj8wndum4ewpp4sxqjpccme46uacgiis2hdy4qzf9wfrimmi7yf0i6lrq4i3xl2iq3uwo566lqui0aslb29lpokgi67zh0klhnhpxqlbwtfhmz4sk9wdjc4izhee:latest/lr1e-4_r64_lora_70B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://jxklw0caffapw283bwmwl8ql7l877fjzhbrh5fiywqxj6e18phtoc4upflqsu585fiqmav0qw01mt627o0aguni7otbnk44aji1pcvmj15j3pa6hcxfvyojockr8kg20/lr1e-4_r64_lora_70B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-4_r64_lora_70B/mcq_4_choices/classification_report_7_2eba5758a752ea1c8481.table.json', 'sha256': '2eba5758a752ea1c848147de5831dc4bd57d7dd9493afb342f548e7e7ca7cd1a', 'size': 578}, 'lr1e-4_r64_lora_70B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://kdxjuw57qoptkct6qvp909m9arl9fjo27tw3aieyez7g5iowzc3bae1wtx3xrl7yvjcfnahbsy68pefb4718acl8dumuzct43hkn7ctorwodu6ci7qrspn1jyxuuzfet:latest/lr1e-4_r64_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://rvysjh493m200vrx492pxlrmtda3mcud6djetnecjbvtne5euxkiemjd2inbxsbfm4jrrqths4rz5sxce22mj4wn3ot8gzxzzecw6v7do2xu3igh34fdhen2xumfw53c/lr1e-4_r64_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-4_r64_lora_70B/mcq_4_choices/confusion_matrix_table_6_d03ab769db5c5767dad4.table.json', 'sha256': 'd03ab769db5c5767dad4564114b6c799612252a8bf62fdf1cafc7b5bcf324f09', 'size': 532}, 'lr1e-4_r64_lora_70B/mcq_4_choices/correct': 460, 'lr1e-4_r64_lora_70B/mcq_4_choices/generation_time': 1816.4035620689392, 'lr1e-4_r64_lora_70B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://syeyy0qvjtyscv2kg6ipp3ie5dtsv74z9rk2vfy5iwzs82ww1jqwu46qdo4vvvltk7mhgbzax4cg8gsfgj7pqh7z2f1836wa0jy7e2oo3rledk557tiidw813rncrxqr:latest/lr1e-4_r64_lora_70B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://b3lu6z3pkyj3n193l036d97adzjgz8mfblud9mi8z3ysft0sxky5y2ppwwguaqvkatrdrer1taqi6jh7161vxbq1ohwvt2n4fh36rikzeigpk5xibg79mi0iw5rb3qvn/lr1e-4_r64_lora_70B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 5, 'path': 'media/table/lr1e-4_r64_lora_70B/mcq_4_choices/pred_distribution_6_4829ce19a4afc816a805.table.json', 'sha256': '4829ce19a4afc816a80584cf80fae088c4a7c3ccbd5e3385fc218aece4fc6fa3', 'size': 101}, 'lr1e-4_r64_lora_70B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://oir2rc7cw8iqqb2fnytkn8lzkidsxhs302o4gxo7tn27l4c35yqqeqvapez2dkdbh9g7a0shgcbpd307ntu5sw18u51rs8vthmh1vf43yvwbswdwlnw7t9l61zm7uw4p:latest/lr1e-4_r64_lora_70B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://14dz1yw1gz0m91y5rwhdr5jdzoubuyyqnabl8yli4bqrwdcqw3jkzivvsdin1iqwj4s7xztyl39jnskpecqsv7uw7o50omf604xgyz4ag93zl9ehuqgpnotfvufqfp7c/lr1e-4_r64_lora_70B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-4_r64_lora_70B/mcq_4_choices/predictions_6_187c1b906311cde267f7.table.json', 'sha256': '187c1b906311cde267f718502b702de9f82e0674d9ec04350b4d95a9945b24b9', 'size': 16119428}, 'lr1e-4_r64_lora_70B/mcq_4_choices/total': 1655, 'results_table': {'_latest_artifact_path': 'wandb-client-artifact://7ipppb726evqxdjktg9dbznroi6obkl543ampp8ihj9d1jgwhmpg77g8sdgu6jg4cp3nxsw6gdimtydjjubgqrfxz92jnvpx9ndft1h4nbuvedav6yk6m08ouoovx5mr:latest/results_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://l3lihhnx9excwldq58u3sbwoezzguh6s1hddy0kjidem0r58g21sjmvkna41bvxao9ux49jytqlkvbvbg40ygu6geigtx260vovygxv8os50ofh2g6exq99p3pv18irk/results_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 6, 'nrows': 4, 'path': 'media/table/results_table_8_d632511b1838622774cb.table.json', 'sha256': 'd632511b1838622774cb6b31323604f3b3036cd71a142283c9969a2f0dd1a03b', 'size': 460}}"
grid_70B_lora_lr1e-5_checkpoint-467_2025-12-18_19-04-45,1po2qv48,finished,2025-12-18T18:04:46Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'name': 'Apertus-70B-Instruct', 'entity': 'lsaie-peft-apertus', 'project': 'LEXam-Evaluation'}, 'is_lora': True, 'subsets': ['mcq_4_choices'], 'grid_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/results/grid_70B_lora_lr1e-5', 'model_id': 'swiss-ai/Apertus-70B-Instruct-2509', 'base_model': 'swiss-ai/Apertus-70B-Instruct-2509', 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'checkpoint_name': 'checkpoint-467', 'num_checkpoints': 4, 'match_choice_regex': '###([A-Z]+)###', 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 6605, '_step': 8, '_timestamp': 1766087693.006529, '_wandb': {'runtime': 6605}, 'lr1e-5_r16_lora_70B/mcq_4_choices/accuracy': 0.30634441087613296, 'lr1e-5_r16_lora_70B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://7zh1309g84hmv41ih8lvzmik83bctawb5qcsevw59ps9k1j1ikod23pqzm6motguq32tnolw8j6hugs44jwcnhw43kfeybqohyomk3zoctdt2gxtlpirblhsq056ykmc:latest/lr1e-5_r16_lora_70B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://cgmev4v20my5umdwr636ixhmx5t9t2ben3ac692u0agl1v08t4xfssgyb8n3jbhgsg4pfslrjf0als1wjabvy7gg5jdnzp3aodilaiwv401coqtvg5ib3nlzmvdknkcr/lr1e-5_r16_lora_70B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 6, 'path': 'media/table/lr1e-5_r16_lora_70B/mcq_4_choices/classification_report_1_05f878c0fa055d831e1b.table.json', 'sha256': '05f878c0fa055d831e1be66e4fa1a27128841d5f419806347f31e6ffde79110c', 'size': 546}, 'lr1e-5_r16_lora_70B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://fi5uwkb6l32y23z4fbut78eezh3o38fs4exi20j3tsyirnwdwb3racc5ywecmt5zcohnvrivivyq9wg4p4iqq7nf75rhde2ijbsc6csqiqr8kko1jodx32qfsapdzbua:latest/lr1e-5_r16_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://fvq284bzq86n6cs3q97pedt1etf8gz2x2t7yor3hvp8ek5jz8jci7hdl0aifbamyjal9ll6aewdr85qazl0k08f6fhab751xojoitqbdpqpr6pu505plvwems0lzo8id/lr1e-5_r16_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 16, 'path': 'media/table/lr1e-5_r16_lora_70B/mcq_4_choices/confusion_matrix_table_0_8075b15956997b378658.table.json', 'sha256': '8075b15956997b3786587e8163cf2af1177d774ba1b4cd0670a6b7aabdf66191', 'size': 353}, 'lr1e-5_r16_lora_70B/mcq_4_choices/correct': 507, 'lr1e-5_r16_lora_70B/mcq_4_choices/generation_time': 1579.828228473663, 'lr1e-5_r16_lora_70B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://x1yapwwncr13dava2kxfoyfeht7o5vadc7d2b1tsmev7dcebgblnsg3eaojs5upfzvmxdfhao1ftsg3czlbtdyczg9hxkb6n6fn6fobwfpysanhqeuwrlbe3pq8j8bg2:latest/lr1e-5_r16_lora_70B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://b88hp53539g306px40hi9vc8s762kox7fgaxat86o54s7lefdj6jzznzx3juin6jq37covpicd9inorodxwasyqu87t1vatefkxjj88s4d9j6jl52gvygzqekggmeyck/lr1e-5_r16_lora_70B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 4, 'path': 'media/table/lr1e-5_r16_lora_70B/mcq_4_choices/pred_distribution_0_a1e4ad7dc3d8d8763efb.table.json', 'sha256': 'a1e4ad7dc3d8d8763efb3ae00d1e73d34c256f4350af8eb7b3a68cc383394e4f', 'size': 88}, 'lr1e-5_r16_lora_70B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://e1ys5yr9gbqod3xhqugbt3k2bjbn25yhqvudshloewfg8gcsxlxfaj14lm4eyc7wjadbmca989ny1x5si7s3rfymepfouihxw4n6hr1d4al9j8hdsg7dj0l554vywi5z:latest/lr1e-5_r16_lora_70B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://nigwi6w0fox40y1od5i10jowwr7owinh73c4o28d1ub314ctbpc2hgi07gyvflmqaiprrqvdeb0jesxrspuziypoe0trzwcco6ssew73ipyyg4k5f7hcw3d93gt58oht/lr1e-5_r16_lora_70B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-5_r16_lora_70B/mcq_4_choices/predictions_0_43e55acfb881b41e2fbc.table.json', 'sha256': '43e55acfb881b41e2fbcbf213695ec12a1e6984fc2c3527c6a4a5173eab87514', 'size': 15374484}, 'lr1e-5_r16_lora_70B/mcq_4_choices/total': 1655, 'lr1e-5_r1_lora_70B/mcq_4_choices/accuracy': 0.3039274924471299, 'lr1e-5_r1_lora_70B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://xppkauv65t95ucewy2tg91hgirvtiagkfjrmh4n8x1fg022vweeuzva6wog47eqo6cnguk7yawn0lrqn7iv8z0a0c8i4cc6lufkxe5mpizz87xaa5k6qls7r9t3ufhnl:latest/lr1e-5_r1_lora_70B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://0g2rfle6v6iqzzrblhypr4v3uc5871t74gb28wm4fmky9o5wwwopuxwbu11sw267z72krj33wxb0nladou8wdkg9g55hwf9158ih2mjkyw39wup7g96jhxjknqqie9fg/lr1e-5_r1_lora_70B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 6, 'path': 'media/table/lr1e-5_r1_lora_70B/mcq_4_choices/classification_report_3_dfd78bf7e9b4b8c2d367.table.json', 'sha256': 'dfd78bf7e9b4b8c2d3679d4666c8ad31c6ab53871dd787654e479e67574e74dc', 'size': 544}, 'lr1e-5_r1_lora_70B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://cj3pf95kyci20cr3zd26aydr7foa1711ep5k2d3vdyw5wn5h3hk06tepqvxbvibbbh73h4jwaimfjq5ssa2o6s93l1suwkc6ing6umrry2ams1dt25c8ld7fzhcsadlb:latest/lr1e-5_r1_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://0ii20rjgz16iyy25qnodak7v81pemfuh9zb2kitkapr2s0oygx1k4hw310aujn5xiwtpolvwe5ygr2qybfzgp1rctzyvx7ynjkochxnphpyeh8cr3l92racc2j42ly2f/lr1e-5_r1_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 16, 'path': 'media/table/lr1e-5_r1_lora_70B/mcq_4_choices/confusion_matrix_table_2_11e7ab774efd5d180ef2.table.json', 'sha256': '11e7ab774efd5d180ef23e3276eb8de3e45828c630f80939728b88b7aa990a1c', 'size': 352}, 'lr1e-5_r1_lora_70B/mcq_4_choices/correct': 503, 'lr1e-5_r1_lora_70B/mcq_4_choices/generation_time': 1385.806709766388, 'lr1e-5_r1_lora_70B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://9vtu65uxr6f7dmtny5cb51244056in30xw7t7z1ws78xulij24xuwvumyu504zzcicm9h0fe7dmzjq0o7gcv9zqtduapems17lw7jtdaiko8u6wiok3hwcgl2un54v5l:latest/lr1e-5_r1_lora_70B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://nz30ta375ac50en9084if037s0iv9ooahpjjb82y4vy1ve8cfiavqe1yluzgev5hk1sf3ss27x78o94lwykm5m97m05p53eqc472qhagpyrn2quegssrfu47tovm5l1z/lr1e-5_r1_lora_70B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 4, 'path': 'media/table/lr1e-5_r1_lora_70B/mcq_4_choices/pred_distribution_2_cad998a718662209442a.table.json', 'sha256': 'cad998a718662209442ac985336403432a2a62be0e20ef5b39b96950d587d661', 'size': 88}, 'lr1e-5_r1_lora_70B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://esoq10ltkii6m68akxp4h45v4wkncc7yhdsa86mwk9c2fosio0e57wfd45rhkwvovh6zpak3ozhevj2uujbuay955hme8a2h77kncx9b80enfaj9094tgynhu153cm4h:latest/lr1e-5_r1_lora_70B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://2xqexssc1041apv71m5pxdtq21dknp7uubu1twfgq9t5utwruj4c1ih7vco3tpcizeag9b9j5y8hof92fo5r0g0vewsknhznka2pwklyvl7tchnlj4xjalzfprgrmb7s/lr1e-5_r1_lora_70B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-5_r1_lora_70B/mcq_4_choices/predictions_2_42be9a120fb0b5dea9d3.table.json', 'sha256': '42be9a120fb0b5dea9d328e7db62a2ac284e19fdf7bf3b91c8f35b54fb8b1f06', 'size': 14147211}, 'lr1e-5_r1_lora_70B/mcq_4_choices/total': 1655, 'lr1e-5_r512_lora_70B/mcq_4_choices/accuracy': 0.2948640483383686, 'lr1e-5_r512_lora_70B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://sghtovqvtsl3aqg4mk27jdg0y4tlfqihcmwandoduzdp53cg0czwln3armjro4x13hfsulhim1uflkxg87b1paiu66prdq0ur8cqe3gcg7gye58vimlmxs4s560b4crx:latest/lr1e-5_r512_lora_70B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://c0r7a6phaunapvfnr2k7odmzjve9bwd24ua3f59aswr4a6dv2ovmypfy58n0tcttyk18cwskenczaktk8hmmstaohmto0ncwh6kdlfh27ef36cu0gey7sz3dltofhaj5/lr1e-5_r512_lora_70B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 6, 'path': 'media/table/lr1e-5_r512_lora_70B/mcq_4_choices/classification_report_5_a0978529bc533a345c04.table.json', 'sha256': 'a0978529bc533a345c041526c838cb08dcd7852425ee27850955dcdce34819d1', 'size': 525}, 'lr1e-5_r512_lora_70B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://bmjbybzanitodpl3b9weywfzi64m5jipk43jczcxr2wa4v5b37an8jx72w75xml1whhqwcfmqyovr5u2yk0j7nv3apw248ecseb098g2yoru2xkjstclm0ae0y98jb1n:latest/lr1e-5_r512_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://r2tvzqtpw803zdc6pg9vfvfv2rso9jlq9eewlxa11f92zstpd4vsnynvs1gxz90ow26k4phixdjlycbafs6x9nwp70omlznerwkqph9tf2t5t8xbvdm0tfrvkm08jim8/lr1e-5_r512_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 16, 'path': 'media/table/lr1e-5_r512_lora_70B/mcq_4_choices/confusion_matrix_table_4_a0b707081bb1543a1d39.table.json', 'sha256': 'a0b707081bb1543a1d39d8ad04a832f36b6d57ca97f93d67fd62d4488d65facd', 'size': 353}, 'lr1e-5_r512_lora_70B/mcq_4_choices/correct': 488, 'lr1e-5_r512_lora_70B/mcq_4_choices/generation_time': 1734.2689974308014, 'lr1e-5_r512_lora_70B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://oxppqhqn2y2w77jl1dzvw501yt7045lof5jd6a08zsxfz39ceocnsbsdvgok7uewslelflj456hk08o7ewkxrx0w5vm5e6doellfe03w2eg5jgqdhfwztbnmqcxkhys2:latest/lr1e-5_r512_lora_70B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://t50tpqwaxr57nrl9era9cegu3rtye778xagkarrzp9nq1cadib6xkqf0qllh5c9h3qt1lx5bg60sv4gso84btlzaeys67j3yautk0imxr54zki4f9v3qwe9d2w9l8z31/lr1e-5_r512_lora_70B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 4, 'path': 'media/table/lr1e-5_r512_lora_70B/mcq_4_choices/pred_distribution_4_c3e7cbd6d99dcc4bbb85.table.json', 'sha256': 'c3e7cbd6d99dcc4bbb8599e110b7567481cca74ee70204736a7e2ed1c068f7d7', 'size': 88}, 'lr1e-5_r512_lora_70B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://2fnxprb17n3l9yj074z5en6js01ya5widi2mv0vwmby0q7pnzcuvsyyjyufbg4g3v0izeb64dxfe44dmjlwzbwtrkrcz6wq5ncw4qbg4u3kl7wdgmcifp5raha5gndbp:latest/lr1e-5_r512_lora_70B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://xrqy3jdfnw5eibzu1y21ayfuovkvarkj9pptnaglpyjqbxe1coh3r7j0dwqcb5r27d3zts3gnbn2d11sjtzat5n3s1gif15afk6cs6lctmshkothjkh024d3sszx1a7m/lr1e-5_r512_lora_70B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-5_r512_lora_70B/mcq_4_choices/predictions_4_0a50c635fd8f6922dfdc.table.json', 'sha256': '0a50c635fd8f6922dfdc39afe33f192b9303ca082b80febd1b4dbcc9e27097f5', 'size': 16657752}, 'lr1e-5_r512_lora_70B/mcq_4_choices/total': 1655, 'lr1e-5_r64_lora_70B/mcq_4_choices/accuracy': 0.29425981873111784, 'lr1e-5_r64_lora_70B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://zx9zoe92xjxlkkz2jb1csa5r0rqa6its8a6ehbk1n3p4dgdlbsqf41n3e174vlm1lt1w29uf3jc1nc52xzkczkq9ob8d2s3kk4alyy6fhv4cgmu2udw13cia23tzpby5:latest/lr1e-5_r64_lora_70B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://tqwhgqol9bhqecee0z4os2tzows1mg75le38woz4gw955m33f9ndbkh78qaevjafnozu9qoy1mlvzhu9dsht3u31uzpmyh6vyyfapnr21imy8j2fy3qls82j9t3temh6/lr1e-5_r64_lora_70B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-5_r64_lora_70B/mcq_4_choices/classification_report_7_61b8c2d3228cdcd24fdb.table.json', 'sha256': '61b8c2d3228cdcd24fdb1b4ef5d89fc8614675b9da29b97eaeabb42cac5021fe', 'size': 557}, 'lr1e-5_r64_lora_70B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://pxb21n9s5lg1ijkfvoh53w3cgvvq9vreu92xtpq6fsajv5bmyg37kzitc3hfoyigw1vsm9h6rez9cvxn9l77lwepl9p6fixdl0xuwi19c9if8tmmpm9yosz5m8lbt6z2:latest/lr1e-5_r64_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://c1k0spidh0bwz9rih8h4yk4rfqss4b9njvfyf509e1q1fw3aebo2byest4jomgxa7343j6qfssdsjq2yu6vp2lwthgtyyaxzooknmfhs6tjjf3iaymi1liqbrb1e2i2h/lr1e-5_r64_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-5_r64_lora_70B/mcq_4_choices/confusion_matrix_table_6_cfa4ab826971572880b7.table.json', 'sha256': 'cfa4ab826971572880b7946cd668db7e7209e8744a499e685f2e3263cee6ddf8', 'size': 507}, 'lr1e-5_r64_lora_70B/mcq_4_choices/correct': 487, 'lr1e-5_r64_lora_70B/mcq_4_choices/generation_time': 1694.162724494934, 'lr1e-5_r64_lora_70B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://2lj13pqnzkqhf7wmlyb37x0ggkfqyzzolgpw39vupdakjw1895ris537591uvzqaw26iggmmfko99k6xe1ieovxu6mkpui3pdizc8voqzva69pkwbvv1me0hq4gj0ghz:latest/lr1e-5_r64_lora_70B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://a4wkeyoubrxkqnqvc6v6mjufgjsbcmxhojh446s904z9g5d6zjfu76q0a403x003jrr02879mwm16t5yk5xl1x1lz6xyk1zbyqy3a6xebo0naj6x4wfqknn0fqeuo318/lr1e-5_r64_lora_70B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 5, 'path': 'media/table/lr1e-5_r64_lora_70B/mcq_4_choices/pred_distribution_6_6f7da5fc95f31cba1f0c.table.json', 'sha256': '6f7da5fc95f31cba1f0c718ed1aba45e3c6adbac2ebf572c9862670b883915b2', 'size': 98}, 'lr1e-5_r64_lora_70B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://0xjpl4d6usf2hu96yennxl95ianeywvqcch99kpaqbbpz8s9cj06lz9gexpjo71srtmbn1zdo9elqo7dm9ev2u6nrar33j5jpz835euqncozo6yl7owr78ye9mcedjsj:latest/lr1e-5_r64_lora_70B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://kzpa00qaxyxpsjmf9499islt9u72tim7p2nvxsz7sqztdw4r4ubdys65pj95u2drqjbfcgkk8szapr9tqlpsudospp9vgfhwt0dr46b726f4ccga80pkzbau46n284h3/lr1e-5_r64_lora_70B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-5_r64_lora_70B/mcq_4_choices/predictions_6_96bb200c671d38771437.table.json', 'sha256': '96bb200c671d3877143797730e56838e717723aa7bd7d13e6cbee3b2f1058f22', 'size': 16398565}, 'lr1e-5_r64_lora_70B/mcq_4_choices/total': 1655, 'results_table': {'_latest_artifact_path': 'wandb-client-artifact://xa5lh75koj8tq55lutzffipyf1qr7lk7y2sumpidhxi9aiez1em3jfi53wgl3yor0jnvx384z3lop9tnqfro315xcoyr6eulf2bjtylsykwam4oag4bxbi3sj3sm0plw:latest/results_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ob47adnk1vr82bbvhw3xbil1y415tca0ub2t9dlhvbqy621pkgdc3eh9xkluzwhmy3a6b5bnwqvh80yfhge29tgu46x3x2k7o5qoa3kvh1lv47nto04kq7iwzbbourjr/results_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 6, 'nrows': 4, 'path': 'media/table/results_table_8_bb31f86d331a2dac54d0.table.json', 'sha256': 'bb31f86d331a2dac54d029422c27b223dd672b52e53f5d46a26b676fe730e81f', 'size': 461}}"
grid_70B_lora_lr1e-3_checkpoint-467_2025-12-18_19-14-31,a3e6dbj8,finished,2025-12-18T18:14:33Z,"{'seed': 0, 'split': 'test', 'top_p': 1, 'wandb': {'name': 'Apertus-70B-Instruct', 'entity': 'lsaie-peft-apertus', 'project': 'LEXam-Evaluation'}, 'is_lora': True, 'subsets': ['mcq_4_choices'], 'grid_dir': '/iopsstor/scratch/cscs/aashirmatov/LSAIE/project/results/grid_70B_lora_lr1e-3', 'model_id': 'swiss-ai/Apertus-70B-Instruct-2509', 'base_model': 'swiss-ai/Apertus-70B-Instruct-2509', 'temperature': 0, 'dataset_repo': 'LEXam-Benchmark/LEXam', 'max_model_len': 8192, 'max_new_tokens': 4096, 'checkpoint_name': 'checkpoint-467', 'num_checkpoints': 3, 'match_choice_regex': '###([A-Z]+)###', 'tensor_parallel_size': 4, 'pipeline_parallel_size': 1}","{'_runtime': 12720, '_step': 6, '_timestamp': 1766094393.7648504, '_wandb': {'runtime': 12720}, 'lr1e-3_r1_lora_70B/mcq_4_choices/accuracy': 0, 'lr1e-3_r1_lora_70B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://o12s7wf93yri5g97oney5b0osn8hqwmtvr7prlztwb2s16al4zom3tu6dp7xn1v40fdzkut2p58yuzgbw5mch0ow0oyq2mdxp0yjv1kvcqa0xlqm96v9jsj97onmu7hw:latest/lr1e-3_r1_lora_70B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://aph4aiwsoy6dkhjinbpxh4godyt9ut4owncumsffchr8h69j3aunr4g2ggtd4pcxxe1gy01e2fa1wnqf8ox10j94c67bpdb1kjsvghadcnr65krdy0ctq5yyevw346ca/lr1e-3_r1_lora_70B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-3_r1_lora_70B/mcq_4_choices/classification_report_1_aa2d0a8537e0dc17f09a.table.json', 'sha256': 'aa2d0a8537e0dc17f09a62c053cbce93bb56d4f6d0fa1ab8a56925507713d51c', 'size': 297}, 'lr1e-3_r1_lora_70B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://i4put1r9g3qh6jwuykpqjj79va3we9adpg9v24fnwa50e0jpncek4hfz3qu9s6se61lkv43rn4rx92vxpwedkv2ifbj6dcobb6ckfrpdf23lrbo98o8u1vbv4k0fqt38:latest/lr1e-3_r1_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://x68fgmq3w8vcdphv8a3y1c6uivr060oianfgsm2jqvmj69etytgples34g42t8q1kxyg9xczf70h3j02nevlbyfzcf7uvmbjhmjm8fk1hf3mfrjkdpkhpk0dbs2893lk/lr1e-3_r1_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-3_r1_lora_70B/mcq_4_choices/confusion_matrix_table_0_ea22b1e960a8ea83d780.table.json', 'sha256': 'ea22b1e960a8ea83d7801e949ba2e1931b787b5debb7714b8efd3f3c0ca97602', 'size': 525}, 'lr1e-3_r1_lora_70B/mcq_4_choices/correct': 0, 'lr1e-3_r1_lora_70B/mcq_4_choices/generation_time': 4326.505434513092, 'lr1e-3_r1_lora_70B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://f87xzmg01nn2b8lvww11yb5eulh0u36tv4fyqte6dkuy4qqfobaqtp5k5vfa62fmsk5le2kw7no62miqo4w0uv2bfhhqj8buo683j4ylickheqyiv980j87e9gm9f0p0:latest/lr1e-3_r1_lora_70B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://2sor8h8khr0w4bvlueosz5y33ra8vm894v23sdbs0opyertaeeg57y0pdrcsgb8dsdu54nr1sz5uhc3ljvtw7bzm1mr5l8uo8ihq2fmzt4tjnsfagtp6vskc8bv95p8e/lr1e-3_r1_lora_70B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 1, 'path': 'media/table/lr1e-3_r1_lora_70B/mcq_4_choices/pred_distribution_0_fb1a923b89a7b362edee.table.json', 'sha256': 'fb1a923b89a7b362edee1d456c322c5553a3ac798795efb696a45e22e094fa11', 'size': 57}, 'lr1e-3_r1_lora_70B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://nx8b4rlwrovbh6wenf6kdw4vvdon7ljsxatinrh0xkqb19o1ii4b69qi4e2hl8z9lwe0bt00ugcu2vcw5zgm4r71miturz5vldps5kuajiiswhxovqap69x0xvmt2ob6:latest/lr1e-3_r1_lora_70B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://yqv5mq5e2xxw0tpncaonc52koqmq951gzzopfj0gnhh6dlev686zbsv44xjrx6cuvlsl1vrsz6hlx4q7ze5wqfgaf9reptmm23k1p0d5hyazj8ijhysjevuwddq1uqd0/lr1e-3_r1_lora_70B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-3_r1_lora_70B/mcq_4_choices/predictions_0_ac49dd6549aa7a516f0a.table.json', 'sha256': 'ac49dd6549aa7a516f0a275a46c466a543919c1e6e826e29964ab333f3e271a4', 'size': 10449019}, 'lr1e-3_r1_lora_70B/mcq_4_choices/total': 1655, 'lr1e-3_r512_lora_70B/mcq_4_choices/accuracy': 0, 'lr1e-3_r512_lora_70B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://w0zpijqn0x9x44xq4pdg57dzrosm1chhfjg7xszgqok5jvj5wv3319rkb7g2y2a6z9l7iryuw9hc5byaggb1hfnecak8c679ffa2fvdg5aspumcxrwltwout25xedppw:latest/lr1e-3_r512_lora_70B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://9jtejwrbdl6p1czm8sabko3lu6h1qoct0dvqqfrzbm5az1hb072wlbgxjq62h3wjc4wx7kxi7rkiquifse8n4gwxwjo4f18nrbja31m22dniba3cz59jneg1oh1nxgyv/lr1e-3_r512_lora_70B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-3_r512_lora_70B/mcq_4_choices/classification_report_3_aa2d0a8537e0dc17f09a.table.json', 'sha256': 'aa2d0a8537e0dc17f09a62c053cbce93bb56d4f6d0fa1ab8a56925507713d51c', 'size': 297}, 'lr1e-3_r512_lora_70B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://vhep4n56b9tqse4qq2jqak14m3w3nhqohp8godm4g96634o1jlgqj61ppezbaazh5latbba33nf0vg6zkw2zrxfvd2gqwfi1evxvgkttbesaxww44j274fptoa3yurk9:latest/lr1e-3_r512_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://ygprbvdn8xntalydt6atpox8mtvolcdi05tlkm74em2lnqnub315t6zxadsm2jmgd0raj7n5wf1elidknzs090bszb8apdaly2qsupisdua9j9shss8bzy4x3hg34zod/lr1e-3_r512_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-3_r512_lora_70B/mcq_4_choices/confusion_matrix_table_2_ea22b1e960a8ea83d780.table.json', 'sha256': 'ea22b1e960a8ea83d7801e949ba2e1931b787b5debb7714b8efd3f3c0ca97602', 'size': 525}, 'lr1e-3_r512_lora_70B/mcq_4_choices/correct': 0, 'lr1e-3_r512_lora_70B/mcq_4_choices/generation_time': 4497.03532910347, 'lr1e-3_r512_lora_70B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://bq401sc984ss3w4olt626ywyvhthcoi642s73zrn92qe3fp841ldffandsxl6kqonh6yvyprgswtein0nk3h6xoabnsaw1qvtii0n9p3nee8o7dpe3xpnbyuvsyntwk5:latest/lr1e-3_r512_lora_70B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://qa85h1n7kfnq708sve652hw6dstj2qwheotkhvtfoqwr1qabcnhno54m69twn7iobxxjojh7zjgodfqrb371rwzv1zz4ebicb1jv00zgjxqs6g11nqgu7jx1pqu91uzg/lr1e-3_r512_lora_70B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 1, 'path': 'media/table/lr1e-3_r512_lora_70B/mcq_4_choices/pred_distribution_2_fb1a923b89a7b362edee.table.json', 'sha256': 'fb1a923b89a7b362edee1d456c322c5553a3ac798795efb696a45e22e094fa11', 'size': 57}, 'lr1e-3_r512_lora_70B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://6mtrqshnd2johnygzx6u05p1p5dqvg7iakdp2281styvijuwjczj8u55w9jkqlsyz6d8xg1biaxcpxeyr3r4dkyf6lzdjbmsts08jt8nnp7tcujvitgn8gxnerslkil3:latest/lr1e-3_r512_lora_70B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://lh86pm34dba70rajx7v0jkvqsyzadepdhum6ubjhdr2mpdncz4qn6gm8polqu97yve8dmg7actgkavi8ktr7z85qlj9z6zxdxjn4gb1li4uga17zc0ff3e0fhnoaxw35/lr1e-3_r512_lora_70B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-3_r512_lora_70B/mcq_4_choices/predictions_2_e64633704ae7562ba477.table.json', 'sha256': 'e64633704ae7562ba4773a8d2159d0c68e0a248d9abebd8207a7bbe08b21fb0b', 'size': 29252114}, 'lr1e-3_r512_lora_70B/mcq_4_choices/total': 1655, 'lr1e-3_r64_lora_70B/mcq_4_choices/accuracy': 0, 'lr1e-3_r64_lora_70B/mcq_4_choices/classification_report': {'_latest_artifact_path': 'wandb-client-artifact://8vub32jbw5pu733yaffi76xqt34dcks6hkig6szks6k4y5n4svypphqlkhnswkwecvm04lsuxqxl7andd8rol2qukg59vq6bdck5xvin3tfkb53l87z40lvq8sx4b0ws:latest/lr1e-3_r64_lora_70B/mcq_4_choices/classification_report.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://cfo2smnsfysvogoxsrf3xrwrykwm2vvypz51fq8pfqil20f4eqzoclkdoe9a2asxtj0tfmglfy15184uj8kzwizqknxd8azdtbkd641l4ndvws88iy9fofk578loydn9/lr1e-3_r64_lora_70B/mcq_4_choices/classification_report.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 7, 'path': 'media/table/lr1e-3_r64_lora_70B/mcq_4_choices/classification_report_5_aa2d0a8537e0dc17f09a.table.json', 'sha256': 'aa2d0a8537e0dc17f09a62c053cbce93bb56d4f6d0fa1ab8a56925507713d51c', 'size': 297}, 'lr1e-3_r64_lora_70B/mcq_4_choices/confusion_matrix_table': {'_latest_artifact_path': 'wandb-client-artifact://2kx8j1o2k76z31x6knofahokhzsr47q6fbwuz5gp7hahu6yk36wdt8orggcy8izv5vl0iglbuulc0dcr6photkn0qz79ekfx47hg46if4gr733jwo156rzty64lf6qdi:latest/lr1e-3_r64_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://zvsywpvc4h5pbjy44o6pmrwtelha7z092aiy9xiy72swen2cd4w1n6npec036ss0xbqnz2sl0n9f1zo30jd4q0lv7pbe5r9easw6qfpgf35ed32vqn5kuakwmig951wd/lr1e-3_r64_lora_70B/mcq_4_choices/confusion_matrix_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 3, 'nrows': 25, 'path': 'media/table/lr1e-3_r64_lora_70B/mcq_4_choices/confusion_matrix_table_4_ea22b1e960a8ea83d780.table.json', 'sha256': 'ea22b1e960a8ea83d7801e949ba2e1931b787b5debb7714b8efd3f3c0ca97602', 'size': 525}, 'lr1e-3_r64_lora_70B/mcq_4_choices/correct': 0, 'lr1e-3_r64_lora_70B/mcq_4_choices/generation_time': 3683.810516595841, 'lr1e-3_r64_lora_70B/mcq_4_choices/pred_distribution': {'_latest_artifact_path': 'wandb-client-artifact://oczmd451u9aqhcgc2u2a8pblke2q47u2omrd8xao6addzur3o2xwfrwqv5scpt5agsb8khi819103m520bam44q1hderyrgokzw0hk6wy4rk00k0npqbphep3i2k4m81:latest/lr1e-3_r64_lora_70B/mcq_4_choices/pred_distribution.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://a8fdjkauw5gbfxdfuhw31r0uuvmromh2xgob9k4gxyaynp3xi04yl11v7kpflujnejgkx5r4lmn8gpzm0qk3bn4f9r95iawy4k4ftbtg92mmhcjs1lfbf9c6xo7ot6wz/lr1e-3_r64_lora_70B/mcq_4_choices/pred_distribution.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 2, 'nrows': 1, 'path': 'media/table/lr1e-3_r64_lora_70B/mcq_4_choices/pred_distribution_4_fb1a923b89a7b362edee.table.json', 'sha256': 'fb1a923b89a7b362edee1d456c322c5553a3ac798795efb696a45e22e094fa11', 'size': 57}, 'lr1e-3_r64_lora_70B/mcq_4_choices/predictions': {'_latest_artifact_path': 'wandb-client-artifact://lpa6zevtq7gq6ntcw3x8xcnq93kkacow1e4h65kh5luwtpmuszov23oisgcslihnbt69shlvdc2g2zopqdkxyqmcmd7gtd9iv3qu1tnzshvy61ejm4xwtgn4xocn243l:latest/lr1e-3_r64_lora_70B/mcq_4_choices/predictions.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://zx5wdfv4yuqbml8kh1okh8mf27o4heq5vzpsmvvob4dh32xl2agz5w9gof4cltci5s4psq7p6hyg6fk1ojtvymr7hzpv27ce2kr0agrvth9mas94imglm483lxi30wyy/lr1e-3_r64_lora_70B/mcq_4_choices/predictions.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 5, 'nrows': 1655, 'path': 'media/table/lr1e-3_r64_lora_70B/mcq_4_choices/predictions_4_1065f7dc4d62a2d3b904.table.json', 'sha256': '1065f7dc4d62a2d3b904b41183b9f2efb6cd6454bb8bbfdebfb5c860cf993964', 'size': 22680728}, 'lr1e-3_r64_lora_70B/mcq_4_choices/total': 1655, 'results_table': {'_latest_artifact_path': 'wandb-client-artifact://8o7nkwq43bpm4510gajsn2lv5yh5p5v36s3qv1fyncslhysj6tf9hi8ih84frv0x5hchrk55280yceuuqovp3j824vrg7hag7ktno76vpinorlkhs850j2qbcnljhne8:latest/results_table.table.json', '_type': 'table-file', 'artifact_path': 'wandb-client-artifact://5osm7wu3tne1d9q1t15rvag0qecp4efwh8h5t8cbf7kku3599osueqr73r0m43jbu9szk5dmjp8uhn49z64af8apl9rgqnn0kzndmc1ki16tmxbsh5rf0viykj72rltv/results_table.table.json', 'log_mode': 'IMMUTABLE', 'ncols': 6, 'nrows': 3, 'path': 'media/table/results_table_6_edb519c2ccec0170eef7.table.json', 'sha256': 'edb519c2ccec0170eef7c7e774be456ad2ad6268b992b6ae022711dd2fa49cc1', 'size': 317}}"
